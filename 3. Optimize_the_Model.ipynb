{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.utils import shuffle\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Optuna and Scikit optmize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install optuna\n",
    "# %pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = get_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2976d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2976d_row0_col0, #T_2976d_row0_col1, #T_2976d_row0_col2, #T_2976d_row0_col3, #T_2976d_row0_col4, #T_2976d_row0_col5, #T_2976d_row0_col6, #T_2976d_row0_col7, #T_2976d_row1_col0, #T_2976d_row1_col1, #T_2976d_row1_col2, #T_2976d_row1_col3, #T_2976d_row1_col4, #T_2976d_row1_col5, #T_2976d_row1_col6, #T_2976d_row1_col7, #T_2976d_row1_col8, #T_2976d_row2_col0, #T_2976d_row2_col3, #T_2976d_row2_col8, #T_2976d_row3_col0, #T_2976d_row3_col1, #T_2976d_row3_col2, #T_2976d_row3_col3, #T_2976d_row3_col4, #T_2976d_row3_col5, #T_2976d_row3_col6, #T_2976d_row3_col7, #T_2976d_row3_col8, #T_2976d_row4_col0, #T_2976d_row4_col1, #T_2976d_row4_col2, #T_2976d_row4_col4, #T_2976d_row4_col5, #T_2976d_row4_col6, #T_2976d_row4_col7, #T_2976d_row4_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_2976d_row0_col8, #T_2976d_row2_col1, #T_2976d_row2_col2, #T_2976d_row2_col4, #T_2976d_row2_col5, #T_2976d_row2_col6, #T_2976d_row2_col7, #T_2976d_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_2976d_row0_col9, #T_2976d_row1_col9, #T_2976d_row2_col9, #T_2976d_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_2976d_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2976d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2976d_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_2976d_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_2976d_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_2976d_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_2976d_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_2976d_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_2976d_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_2976d_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_2976d_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "      <th id=\"T_2976d_level0_col9\" class=\"col_heading level0 col9\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2976d_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_2976d_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_2976d_row0_col1\" class=\"data row0 col1\" >0.9751</td>\n",
       "      <td id=\"T_2976d_row0_col2\" class=\"data row0 col2\" >0.9782</td>\n",
       "      <td id=\"T_2976d_row0_col3\" class=\"data row0 col3\" >0.8761</td>\n",
       "      <td id=\"T_2976d_row0_col4\" class=\"data row0 col4\" >0.9472</td>\n",
       "      <td id=\"T_2976d_row0_col5\" class=\"data row0 col5\" >0.9097</td>\n",
       "      <td id=\"T_2976d_row0_col6\" class=\"data row0 col6\" >0.8953</td>\n",
       "      <td id=\"T_2976d_row0_col7\" class=\"data row0 col7\" >0.8966</td>\n",
       "      <td id=\"T_2976d_row0_col8\" class=\"data row0 col8\" >0.9509</td>\n",
       "      <td id=\"T_2976d_row0_col9\" class=\"data row0 col9\" >1.9780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2976d_level0_row1\" class=\"row_heading level0 row1\" >et</th>\n",
       "      <td id=\"T_2976d_row1_col0\" class=\"data row1 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_2976d_row1_col1\" class=\"data row1 col1\" >0.9764</td>\n",
       "      <td id=\"T_2976d_row1_col2\" class=\"data row1 col2\" >0.9777</td>\n",
       "      <td id=\"T_2976d_row1_col3\" class=\"data row1 col3\" >0.8583</td>\n",
       "      <td id=\"T_2976d_row1_col4\" class=\"data row1 col4\" >0.9761</td>\n",
       "      <td id=\"T_2976d_row1_col5\" class=\"data row1 col5\" >0.9118</td>\n",
       "      <td id=\"T_2976d_row1_col6\" class=\"data row1 col6\" >0.8983</td>\n",
       "      <td id=\"T_2976d_row1_col7\" class=\"data row1 col7\" >0.9018</td>\n",
       "      <td id=\"T_2976d_row1_col8\" class=\"data row1 col8\" >0.9506</td>\n",
       "      <td id=\"T_2976d_row1_col9\" class=\"data row1 col9\" >0.2920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2976d_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_2976d_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_2976d_row2_col1\" class=\"data row2 col1\" >0.9777</td>\n",
       "      <td id=\"T_2976d_row2_col2\" class=\"data row2 col2\" >0.9785</td>\n",
       "      <td id=\"T_2976d_row2_col3\" class=\"data row2 col3\" >0.8672</td>\n",
       "      <td id=\"T_2976d_row2_col4\" class=\"data row2 col4\" >0.9773</td>\n",
       "      <td id=\"T_2976d_row2_col5\" class=\"data row2 col5\" >0.9173</td>\n",
       "      <td id=\"T_2976d_row2_col6\" class=\"data row2 col6\" >0.9045</td>\n",
       "      <td id=\"T_2976d_row2_col7\" class=\"data row2 col7\" >0.9077</td>\n",
       "      <td id=\"T_2976d_row2_col8\" class=\"data row2 col8\" >0.9505</td>\n",
       "      <td id=\"T_2976d_row2_col9\" class=\"data row2 col9\" >0.5590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2976d_level0_row3\" class=\"row_heading level0 row3\" >gbc</th>\n",
       "      <td id=\"T_2976d_row3_col0\" class=\"data row3 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_2976d_row3_col1\" class=\"data row3 col1\" >0.9681</td>\n",
       "      <td id=\"T_2976d_row3_col2\" class=\"data row3 col2\" >0.9741</td>\n",
       "      <td id=\"T_2976d_row3_col3\" class=\"data row3 col3\" >0.8717</td>\n",
       "      <td id=\"T_2976d_row3_col4\" class=\"data row3 col4\" >0.9078</td>\n",
       "      <td id=\"T_2976d_row3_col5\" class=\"data row3 col5\" >0.8865</td>\n",
       "      <td id=\"T_2976d_row3_col6\" class=\"data row3 col6\" >0.8679</td>\n",
       "      <td id=\"T_2976d_row3_col7\" class=\"data row3 col7\" >0.8701</td>\n",
       "      <td id=\"T_2976d_row3_col8\" class=\"data row3 col8\" >0.9461</td>\n",
       "      <td id=\"T_2976d_row3_col9\" class=\"data row3 col9\" >1.4110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2976d_level0_row4\" class=\"row_heading level0 row4\" >lr</th>\n",
       "      <td id=\"T_2976d_row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_2976d_row4_col1\" class=\"data row4 col1\" >0.9572</td>\n",
       "      <td id=\"T_2976d_row4_col2\" class=\"data row4 col2\" >0.9720</td>\n",
       "      <td id=\"T_2976d_row4_col3\" class=\"data row4 col3\" >0.8984</td>\n",
       "      <td id=\"T_2976d_row4_col4\" class=\"data row4 col4\" >0.8266</td>\n",
       "      <td id=\"T_2976d_row4_col5\" class=\"data row4 col5\" >0.8583</td>\n",
       "      <td id=\"T_2976d_row4_col6\" class=\"data row4 col6\" >0.8333</td>\n",
       "      <td id=\"T_2976d_row4_col7\" class=\"data row4 col7\" >0.8361</td>\n",
       "      <td id=\"T_2976d_row4_col8\" class=\"data row4 col8\" >0.9429</td>\n",
       "      <td id=\"T_2976d_row4_col9\" class=\"data row4 col9\" >0.0410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d128880d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf1 = setup(data = df_train, \n",
    "             target = 'target',\n",
    "             numeric_features=df_train.columns[0:-1].to_list(),\n",
    "             silent=True,\n",
    "             log_experiment = True,\n",
    "             use_gpu=False,\n",
    "             experiment_name = 'selected_model',\n",
    "             fix_imbalance = True, \n",
    "             transformation = True, \n",
    "             polynomial_features = True,\n",
    "             feature_selection = True, feature_selection_threshold = 0.5,\n",
    "             remove_multicollinearity = True, multicollinearity_threshold = 0.6,\n",
    "            )\n",
    "add_metric('apc', 'APC', average_precision_score, target = 'pred_proba')\n",
    "best = compare_models(sort=\"APC\", \n",
    "                      include=[\"lightgbm\", \"et\", \"rf\", \"lr\", \"gbc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " '5316',\n",
       " Pipeline(memory=None,\n",
       "          steps=[('fix_imbalance',\n",
       "                  SMOTE(k_neighbors=5, n_jobs=None, random_state=8364,\n",
       "                        sampling_strategy='auto'))],\n",
       "          verbose=False),\n",
       " <pycaret.loggers.DashboardLogger at 0x19d124c51f0>,\n",
       " False,\n",
       " 10,\n",
       " True,\n",
       " True,\n",
       " 'lightgbm',\n",
       " [<pandas.io.formats.style.Styler at 0x19d124c1c70>,\n",
       "                                      Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "  lightgbm  Light Gradient Boosting Machine    0.9751  0.9782  0.8761  0.9472   \n",
       "  et                 Extra Trees Classifier    0.9764  0.9777  0.8583  0.9761   \n",
       "  rf               Random Forest Classifier    0.9777  0.9785  0.8672  0.9773   \n",
       "  gbc          Gradient Boosting Classifier    0.9681  0.9741  0.8717  0.9078   \n",
       "  lr                    Logistic Regression    0.9572  0.9720  0.8984  0.8266   \n",
       "  \n",
       "                F1   Kappa     MCC     APC  TT (Sec)  \n",
       "  lightgbm  0.9097  0.8953  0.8966  0.9509     1.978  \n",
       "  et        0.9118  0.8983  0.9018  0.9506     0.292  \n",
       "  rf        0.9173  0.9045  0.9077  0.9505     0.559  \n",
       "  gbc       0.8865  0.8679  0.8701  0.9461     1.411  \n",
       "  lr        0.8583  0.8333  0.8361  0.9429     0.041  ],\n",
       "               V7        V1       V12        V9    Amount       V17        V4  \\\n",
       " 51670  -1.042358 -1.745049  0.942504 -0.098668 -0.518882  0.620247  1.218280   \n",
       " 66175  -0.036413 -0.544365  0.087105  0.883469  0.911233  0.822070 -0.550699   \n",
       " 113159 -1.212042 -1.834489  0.795447 -1.109661 -0.326789  0.292396  1.225302   \n",
       " 210547 -0.112151  1.752757 -0.330445 -0.238356 -1.425592  0.180040 -0.624390   \n",
       " 270254  0.717721  0.053379 -0.061528 -0.028816 -1.428831 -0.067595 -0.106909   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 87334  -0.258220 -0.398866 -0.503293 -1.202358  0.005953  0.501608 -1.033235   \n",
       " 152253  0.322402 -0.472910 -1.035483  1.299917  0.265404  0.390669 -0.520730   \n",
       " 254989 -0.221172  1.781998 -0.656234  0.070773 -0.115800  0.080840 -0.710225   \n",
       " 156384  0.294121  1.703203 -0.993238  2.599416 -0.429166  0.482461 -1.053397   \n",
       " 88361   0.090327  0.552147  0.339183  0.054169  0.735704 -0.140939  0.398194   \n",
       " \n",
       "              V16       V14       V21  ...       V28        V5       V11  \\\n",
       " 51670   1.149102 -0.435985 -0.133460  ... -5.843214  4.140999 -0.497436   \n",
       " 66175  -0.681298  0.304617  0.137938  ... -0.068111 -0.857219 -0.217033   \n",
       " 113159  2.897117  3.328629 -2.341840  ... -6.153236  0.137084 -1.155708   \n",
       " 210547  0.960844  0.076061  0.269136  ... -0.267111 -0.261522 -0.579523   \n",
       " 270254 -0.252509  0.251776 -0.175616  ...  0.778614  0.472762 -1.802018   \n",
       " ...          ...       ...       ...  ...       ...       ...       ...   \n",
       " 87334  -0.565093 -0.333405 -0.170782  ... -0.351783 -0.092893 -0.375287   \n",
       " 152253 -0.171756  2.772873 -0.003233  ...  0.394167  0.118871  0.398856   \n",
       " 254989  1.162745 -0.024937  0.260746  ... -0.299487 -0.130329 -2.228486   \n",
       " 156384 -0.684634  2.428023 -0.217762  ... -0.339687  0.336242 -0.645956   \n",
       " 88361   0.101757  0.854568  0.038167  ... -0.008843  0.011479  0.585586   \n",
       " \n",
       "               V6        V2        V3  V14_Power2  V11_Power2       V19  \\\n",
       " 51670  -2.872826 -4.003747  0.602403    0.469018   -0.803861 -3.184730   \n",
       " 66175  -0.174107  0.102257  1.702004   -0.858698   -1.292665  2.160887   \n",
       " 113159  2.950521 -1.152532 -1.110854    1.558762    0.320268  0.787304   \n",
       " 210547 -0.867236 -0.419287 -0.553602   -1.044050   -0.639113  0.410598   \n",
       " 270254 -0.123513  0.267897 -0.089785   -0.936406    0.925738  1.298282   \n",
       " ...          ...       ...       ...         ...         ...       ...   \n",
       " 87334  -0.702469 -0.617959  1.294736    0.071120   -1.041868  0.585560   \n",
       " 152253 -0.043740  0.294914  0.068608    1.447548   -0.325292  0.279526   \n",
       " 254989 -0.199835 -0.559086 -0.644641   -0.945317    1.164119  0.890920   \n",
       " 156384 -0.624523 -0.242260 -0.812214    1.351448   -0.507689  1.139145   \n",
       " 88361   0.289999 -0.122635 -0.004399    0.149740    0.323971 -0.375316   \n",
       " \n",
       "              V10  \n",
       " 51670  -0.160948  \n",
       " 66175  -0.462807  \n",
       " 113159 -0.253957  \n",
       " 210547  0.709910  \n",
       " 270254  0.043369  \n",
       " ...          ...  \n",
       " 87334   1.252828  \n",
       " 152253 -0.375478  \n",
       " 254989  0.672212  \n",
       " 156384 -0.390660  \n",
       " 88361   0.242950  \n",
       " \n",
       " [1565 rows x 26 columns],\n",
       " 51670     0\n",
       " 66175     0\n",
       " 113159    0\n",
       " 210547    0\n",
       " 270254    0\n",
       "          ..\n",
       " 87334     0\n",
       " 152253    0\n",
       " 254989    0\n",
       " 156384    0\n",
       " 88361     0\n",
       " Name: target, Length: 1565, dtype: int64,\n",
       " 5,\n",
       " 169876    0\n",
       " 37964     0\n",
       " 205802    0\n",
       " 161873    0\n",
       " 62316     0\n",
       "          ..\n",
       " 68076     0\n",
       " 280272    0\n",
       " 40085     1\n",
       " 244833    0\n",
       " 149522    1\n",
       " Name: target, Length: 672, dtype: int64,\n",
       "             Time        V1        V2        V3        V4        V5        V6  \\\n",
       " 138220   82547.0 -0.072469  0.182870  0.858739  3.172125 -0.365100  1.492411   \n",
       " 219598  141795.0 -2.208719 -0.668035 -0.461423 -0.308953  1.282194 -1.241089   \n",
       " 241429  151020.0  2.065196 -2.014240 -0.270485 -1.488031 -1.870384  0.121320   \n",
       " 144299   86012.0 -2.009109  0.193185  0.823146  0.498421  1.111732 -0.308950   \n",
       " 76929    56806.0  0.016828  2.400826 -4.220360  3.462217 -0.624142 -1.294303   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 46488    42808.0 -0.252029  0.719147  0.865137  0.228747  1.223430  1.264775   \n",
       " 88728    62264.0  0.337925 -1.573980  0.363131  0.626949 -1.301546 -0.315424   \n",
       " 178254  123550.0  2.249899 -0.507002 -2.527011 -1.046284  0.387458 -1.235181   \n",
       " 83440    59852.0 -1.799860  0.984038  2.140605  3.432020 -1.299208  1.391437   \n",
       " 214662  139767.0  0.467992  1.100118 -5.607145  2.204714 -0.578539 -0.174200   \n",
       " \n",
       "               V7        V8        V9  ...       V21       V22       V23  \\\n",
       " 138220  0.329592 -0.625508 -0.732202  ...  0.645181 -0.910310  0.123923   \n",
       " 219598  0.209025  0.585629 -0.061194  ...  0.038849 -0.569782  0.019844   \n",
       " 241429 -1.784255  0.120833 -0.439954  ... -0.118057 -0.078715  0.265937   \n",
       " 144299  0.877830 -0.523337  0.321440  ... -0.249736  0.509603  0.468865   \n",
       " 76929  -2.986028  0.751883 -1.606672  ...  0.285832 -0.771508 -0.265200   \n",
       " ...          ...       ...       ...  ...       ...       ...       ...   \n",
       " 46488   0.686275  0.125512 -0.038421  ... -0.140985 -0.151006 -0.452425   \n",
       " 88728   0.168679 -0.084803  0.579173  ...  0.242159 -0.132307 -0.310793   \n",
       " 178254  0.340354 -0.472276 -1.294944  ...  0.526978  1.513483 -0.203936   \n",
       " 83440  -0.933519  1.399936 -0.201363  ... -0.180183 -0.317036 -0.132857   \n",
       " 214662 -3.454201  1.102823 -1.065016  ...  0.983481  0.899876 -0.285103   \n",
       " \n",
       "              V24       V25       V26       V27       V28  Amount  target  \n",
       " 138220 -0.797330  0.843522  0.303166  0.112604  0.223590  241.69       0  \n",
       " 219598 -0.549747  0.158114 -0.079326  0.207143 -0.098502  127.48       0  \n",
       " 241429  0.425693 -0.552003 -0.270830  0.037184 -0.009668  116.00       0  \n",
       " 144299 -0.460245  0.370437 -0.391734 -0.966729 -0.905033    5.98       0  \n",
       " 76929  -0.873077  0.939776 -0.219085  0.874494  0.470434    1.00       1  \n",
       " ...          ...       ...       ...       ...       ...     ...     ...  \n",
       " 46488  -1.725310  0.354752 -0.300604 -0.244400 -0.235820    4.96       0  \n",
       " 88728   0.497702 -0.015247  0.977195 -0.124123  0.084371  444.50       0  \n",
       " 178254  0.860588  0.738657  0.244375 -0.106816 -0.095186   18.00       0  \n",
       " 83440   0.095067  0.083421  0.265569  0.097067 -0.082868   75.69       0  \n",
       " 214662 -1.929717  0.319869  0.170636  0.851798  0.372098  120.54       1  \n",
       " \n",
       " [2237 rows x 31 columns],\n",
       " -1,\n",
       " None,\n",
       " 'selected_model',\n",
       " 'lightgbm',\n",
       " False,\n",
       " 138220    0\n",
       " 219598    0\n",
       " 241429    0\n",
       " 144299    0\n",
       " 76929     1\n",
       "          ..\n",
       " 46488     0\n",
       " 88728     0\n",
       " 178254    0\n",
       " 83440     0\n",
       " 214662    1\n",
       " Name: target, Length: 2237, dtype: int64,\n",
       " True,\n",
       " False,\n",
       " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x19d1264d5e0>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x19d1264d730>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x19d1264d790>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x19d1264d970>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x19d1264d9a0>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x19d1264df10>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x19d12643a90>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x19d1264d520>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x19d12670100>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x19d12670280>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x19d12670460>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x19d126707c0>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x19d12670940>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x19d126709a0>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x19d12670e20>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x19d12674400>,\n",
       "  'dummy': <pycaret.containers.models.classification.DummyClassifierContainer at 0x19d12674820>,\n",
       "  'Bagging': <pycaret.containers.models.classification.BaggingClassifierContainer at 0x19d12670e80>,\n",
       "  'Stacking': <pycaret.containers.models.classification.StackingClassifierContainer at 0x19d12674a00>,\n",
       "  'Voting': <pycaret.containers.models.classification.VotingClassifierContainer at 0x19d12674a60>,\n",
       "  'CalibratedCV': <pycaret.containers.models.classification.CalibratedClassifierCVContainer at 0x19d12674ac0>},\n",
       " 8364,\n",
       " None,\n",
       "               V7        V1       V12        V9    Amount       V17        V4  \\\n",
       " 169876  0.239404 -0.429912  0.570213  0.398360 -1.212358 -0.206207 -0.185178   \n",
       " 37964   0.278109 -0.624384  0.355598 -0.268019 -1.282260  0.121239 -0.014800   \n",
       " 205802  0.222540  1.542694  1.379407  0.396846 -1.170585 -0.089985  0.156778   \n",
       " 161873 -0.460189  1.608439  0.204192  0.021522  0.382782 -0.110914 -0.804278   \n",
       " 62316   0.033836 -0.597324 -0.479081 -0.520379  0.779341 -0.210325 -0.221523   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 68076   0.707235 -0.602003 -0.148099 -0.210911  1.353492  0.211146  0.465149   \n",
       " 280272  0.947303 -0.426112 -0.260639 -1.319097  0.480079  0.309879 -0.754421   \n",
       " 40085   0.197298  0.589202  0.291248  0.025008 -1.425592  4.403200  0.800472   \n",
       " 244833  0.117423 -0.577063 -0.050353  0.127227  0.069985 -0.274863 -0.455619   \n",
       " 149522 -1.135169 -1.264444 -2.044236  0.722909  0.531255 -1.696545  0.948255   \n",
       " \n",
       "              V16       V14       V21  ...       V28        V5       V11  \\\n",
       " 169876 -0.205905  0.029632 -0.109607  ...  0.658695  1.405770 -0.897001   \n",
       " 37964  -0.144443  0.456138  0.111694  ...  0.462185  0.137805 -0.377356   \n",
       " 205802 -0.117397  0.125412 -0.264724  ... -0.235815  0.002212 -0.540636   \n",
       " 161873  1.998889 -0.173264  0.210513  ... -0.217745 -0.261824  0.195431   \n",
       " 62316  -0.536912  0.056460 -0.125231  ...  0.877319 -0.139395 -1.130199   \n",
       " ...          ...       ...       ...  ...       ...       ...       ...   \n",
       " 68076  -0.309568  0.806930  0.032185  ...  0.375991 -0.144955 -0.369181   \n",
       " 280272 -1.183034  1.026950  0.451977  ... -0.066395  0.418638  0.145636   \n",
       " 40085   1.155644 -1.419832 -0.294174  ...  0.314733  0.513295  1.280502   \n",
       " 244833  0.478936  0.036763  0.089374  ... -0.011682  0.313140 -0.120738   \n",
       " 149522 -1.741737 -1.999042  0.966797  ...  4.568128 -0.562776  1.895110   \n",
       " \n",
       "               V6        V2        V3  V14_Power2  V11_Power2       V19  \\\n",
       " 169876 -1.371256 -0.505706 -0.112031   -1.016077   -0.054666 -0.232329   \n",
       " 37964  -0.245491  0.303634  0.505460   -0.583017   -1.038029 -0.421268   \n",
       " 205802 -0.650459 -0.083013 -0.472299   -1.044232   -0.717087  0.121094   \n",
       " 161873  0.456605 -0.687245 -0.412623   -0.552164   -1.012635  0.941660   \n",
       " 62316  -0.375018 -0.344236  1.479688   -1.035717    0.287377 -2.279547   \n",
       " ...          ...       ...       ...         ...         ...       ...   \n",
       " 68076   1.147087  0.114491  0.113090    0.072588   -1.053147  1.334583   \n",
       " 280272 -0.206125  0.253490 -0.157778    0.399347   -1.141596  0.848449   \n",
       " 40085  -0.307518  0.416952 -0.571817    1.867187    1.597794 -1.001552   \n",
       " 244833  0.761824 -0.004141  1.315756   -1.022249   -1.377658  0.803640   \n",
       " 149522 -1.463308  1.056323 -1.558136    1.956734    1.909019  0.162418   \n",
       " \n",
       "              V10  \n",
       " 169876  0.207365  \n",
       " 37964  -0.066104  \n",
       " 205802  0.189505  \n",
       " 161873  0.709436  \n",
       " 62316   0.370569  \n",
       " ...          ...  \n",
       " 68076  -0.001347  \n",
       " 280272  0.521386  \n",
       " 40085  -0.654945  \n",
       " 244833 -0.099948  \n",
       " 149522 -1.496696  \n",
       " \n",
       " [672 rows x 26 columns],\n",
       " <MLUsecase.CLASSIFICATION: 1>,\n",
       " [('Setup Config',\n",
       "                                  Description            Value\n",
       "   0                               session_id             8364\n",
       "   1                                   Target           target\n",
       "   2                              Target Type           Binary\n",
       "   3                            Label Encoded             None\n",
       "   4                            Original Data       (2237, 31)\n",
       "   5                           Missing Values            False\n",
       "   6                         Numeric Features               30\n",
       "   7                     Categorical Features                0\n",
       "   8                         Ordinal Features            False\n",
       "   9                High Cardinality Features            False\n",
       "   10                 High Cardinality Method             None\n",
       "   11                   Transformed Train Set       (1565, 26)\n",
       "   12                    Transformed Test Set        (672, 26)\n",
       "   13                      Shuffle Train-Test             True\n",
       "   14                     Stratify Train-Test            False\n",
       "   15                          Fold Generator  StratifiedKFold\n",
       "   16                             Fold Number               10\n",
       "   17                                CPU Jobs               -1\n",
       "   18                                 Use GPU            False\n",
       "   19                          Log Experiment             True\n",
       "   20                         Experiment Name   selected_model\n",
       "   21                                     USI             5316\n",
       "   22                         Imputation Type           simple\n",
       "   23          Iterative Imputation Iteration             None\n",
       "   24                         Numeric Imputer             mean\n",
       "   25      Iterative Imputation Numeric Model             None\n",
       "   26                     Categorical Imputer         constant\n",
       "   27  Iterative Imputation Categorical Model             None\n",
       "   28           Unknown Categoricals Handling   least_frequent\n",
       "   29                               Normalize            False\n",
       "   30                        Normalize Method             None\n",
       "   31                          Transformation             True\n",
       "   32                   Transformation Method      yeo-johnson\n",
       "   33                                     PCA            False\n",
       "   34                              PCA Method             None\n",
       "   35                          PCA Components             None\n",
       "   36                     Ignore Low Variance            False\n",
       "   37                     Combine Rare Levels            False\n",
       "   38                    Rare Level Threshold             None\n",
       "   39                         Numeric Binning            False\n",
       "   40                         Remove Outliers            False\n",
       "   41                      Outliers Threshold             None\n",
       "   42                Remove Multicollinearity             True\n",
       "   43             Multicollinearity Threshold              0.6\n",
       "   44             Remove Perfect Collinearity             True\n",
       "   45                              Clustering            False\n",
       "   46                    Clustering Iteration             None\n",
       "   47                     Polynomial Features             True\n",
       "   48                       Polynomial Degree                2\n",
       "   49                    Trignometry Features            False\n",
       "   50                    Polynomial Threshold              0.1\n",
       "   51                          Group Features            False\n",
       "   52                       Feature Selection             True\n",
       "   53                Feature Selection Method          classic\n",
       "   54            Features Selection Threshold              0.5\n",
       "   55                     Feature Interaction            False\n",
       "   56                           Feature Ratio            False\n",
       "   57                   Interaction Threshold             None\n",
       "   58                           Fix Imbalance             True\n",
       "   59                    Fix Imbalance Method            SMOTE),\n",
       "  ('X_training Set',\n",
       "                 V7        V1       V12        V9    Amount       V17        V4  \\\n",
       "   51670  -1.042358 -1.745049  0.942504 -0.098668 -0.518882  0.620247  1.218280   \n",
       "   66175  -0.036413 -0.544365  0.087105  0.883469  0.911233  0.822070 -0.550699   \n",
       "   113159 -1.212042 -1.834489  0.795447 -1.109661 -0.326789  0.292396  1.225302   \n",
       "   210547 -0.112151  1.752757 -0.330445 -0.238356 -1.425592  0.180040 -0.624390   \n",
       "   270254  0.717721  0.053379 -0.061528 -0.028816 -1.428831 -0.067595 -0.106909   \n",
       "   ...          ...       ...       ...       ...       ...       ...       ...   \n",
       "   87334  -0.258220 -0.398866 -0.503293 -1.202358  0.005953  0.501608 -1.033235   \n",
       "   152253  0.322402 -0.472910 -1.035483  1.299917  0.265404  0.390669 -0.520730   \n",
       "   254989 -0.221172  1.781998 -0.656234  0.070773 -0.115800  0.080840 -0.710225   \n",
       "   156384  0.294121  1.703203 -0.993238  2.599416 -0.429166  0.482461 -1.053397   \n",
       "   88361   0.090327  0.552147  0.339183  0.054169  0.735704 -0.140939  0.398194   \n",
       "   \n",
       "                V16       V14       V21  ...       V28        V5       V11  \\\n",
       "   51670   1.149102 -0.435985 -0.133460  ... -5.843214  4.140999 -0.497436   \n",
       "   66175  -0.681298  0.304617  0.137938  ... -0.068111 -0.857219 -0.217033   \n",
       "   113159  2.897117  3.328629 -2.341840  ... -6.153236  0.137084 -1.155708   \n",
       "   210547  0.960844  0.076061  0.269136  ... -0.267111 -0.261522 -0.579523   \n",
       "   270254 -0.252509  0.251776 -0.175616  ...  0.778614  0.472762 -1.802018   \n",
       "   ...          ...       ...       ...  ...       ...       ...       ...   \n",
       "   87334  -0.565093 -0.333405 -0.170782  ... -0.351783 -0.092893 -0.375287   \n",
       "   152253 -0.171756  2.772873 -0.003233  ...  0.394167  0.118871  0.398856   \n",
       "   254989  1.162745 -0.024937  0.260746  ... -0.299487 -0.130329 -2.228486   \n",
       "   156384 -0.684634  2.428023 -0.217762  ... -0.339687  0.336242 -0.645956   \n",
       "   88361   0.101757  0.854568  0.038167  ... -0.008843  0.011479  0.585586   \n",
       "   \n",
       "                 V6        V2        V3  V14_Power2  V11_Power2       V19  \\\n",
       "   51670  -2.872826 -4.003747  0.602403    0.469018   -0.803861 -3.184730   \n",
       "   66175  -0.174107  0.102257  1.702004   -0.858698   -1.292665  2.160887   \n",
       "   113159  2.950521 -1.152532 -1.110854    1.558762    0.320268  0.787304   \n",
       "   210547 -0.867236 -0.419287 -0.553602   -1.044050   -0.639113  0.410598   \n",
       "   270254 -0.123513  0.267897 -0.089785   -0.936406    0.925738  1.298282   \n",
       "   ...          ...       ...       ...         ...         ...       ...   \n",
       "   87334  -0.702469 -0.617959  1.294736    0.071120   -1.041868  0.585560   \n",
       "   152253 -0.043740  0.294914  0.068608    1.447548   -0.325292  0.279526   \n",
       "   254989 -0.199835 -0.559086 -0.644641   -0.945317    1.164119  0.890920   \n",
       "   156384 -0.624523 -0.242260 -0.812214    1.351448   -0.507689  1.139145   \n",
       "   88361   0.289999 -0.122635 -0.004399    0.149740    0.323971 -0.375316   \n",
       "   \n",
       "                V10  \n",
       "   51670  -0.160948  \n",
       "   66175  -0.462807  \n",
       "   113159 -0.253957  \n",
       "   210547  0.709910  \n",
       "   270254  0.043369  \n",
       "   ...          ...  \n",
       "   87334   1.252828  \n",
       "   152253 -0.375478  \n",
       "   254989  0.672212  \n",
       "   156384 -0.390660  \n",
       "   88361   0.242950  \n",
       "   \n",
       "   [1565 rows x 26 columns]),\n",
       "  ('y_training Set',\n",
       "   51670     0\n",
       "   66175     0\n",
       "   113159    0\n",
       "   210547    0\n",
       "   270254    0\n",
       "            ..\n",
       "   87334     0\n",
       "   152253    0\n",
       "   254989    0\n",
       "   156384    0\n",
       "   88361     0\n",
       "   Name: target, Length: 1565, dtype: int64),\n",
       "  ('X_test Set',\n",
       "                 V7        V1       V12        V9    Amount       V17        V4  \\\n",
       "   169876  0.239404 -0.429912  0.570213  0.398360 -1.212358 -0.206207 -0.185178   \n",
       "   37964   0.278109 -0.624384  0.355598 -0.268019 -1.282260  0.121239 -0.014800   \n",
       "   205802  0.222540  1.542694  1.379407  0.396846 -1.170585 -0.089985  0.156778   \n",
       "   161873 -0.460189  1.608439  0.204192  0.021522  0.382782 -0.110914 -0.804278   \n",
       "   62316   0.033836 -0.597324 -0.479081 -0.520379  0.779341 -0.210325 -0.221523   \n",
       "   ...          ...       ...       ...       ...       ...       ...       ...   \n",
       "   68076   0.707235 -0.602003 -0.148099 -0.210911  1.353492  0.211146  0.465149   \n",
       "   280272  0.947303 -0.426112 -0.260639 -1.319097  0.480079  0.309879 -0.754421   \n",
       "   40085   0.197298  0.589202  0.291248  0.025008 -1.425592  4.403200  0.800472   \n",
       "   244833  0.117423 -0.577063 -0.050353  0.127227  0.069985 -0.274863 -0.455619   \n",
       "   149522 -1.135169 -1.264444 -2.044236  0.722909  0.531255 -1.696545  0.948255   \n",
       "   \n",
       "                V16       V14       V21  ...       V28        V5       V11  \\\n",
       "   169876 -0.205905  0.029632 -0.109607  ...  0.658695  1.405770 -0.897001   \n",
       "   37964  -0.144443  0.456138  0.111694  ...  0.462185  0.137805 -0.377356   \n",
       "   205802 -0.117397  0.125412 -0.264724  ... -0.235815  0.002212 -0.540636   \n",
       "   161873  1.998889 -0.173264  0.210513  ... -0.217745 -0.261824  0.195431   \n",
       "   62316  -0.536912  0.056460 -0.125231  ...  0.877319 -0.139395 -1.130199   \n",
       "   ...          ...       ...       ...  ...       ...       ...       ...   \n",
       "   68076  -0.309568  0.806930  0.032185  ...  0.375991 -0.144955 -0.369181   \n",
       "   280272 -1.183034  1.026950  0.451977  ... -0.066395  0.418638  0.145636   \n",
       "   40085   1.155644 -1.419832 -0.294174  ...  0.314733  0.513295  1.280502   \n",
       "   244833  0.478936  0.036763  0.089374  ... -0.011682  0.313140 -0.120738   \n",
       "   149522 -1.741737 -1.999042  0.966797  ...  4.568128 -0.562776  1.895110   \n",
       "   \n",
       "                 V6        V2        V3  V14_Power2  V11_Power2       V19  \\\n",
       "   169876 -1.371256 -0.505706 -0.112031   -1.016077   -0.054666 -0.232329   \n",
       "   37964  -0.245491  0.303634  0.505460   -0.583017   -1.038029 -0.421268   \n",
       "   205802 -0.650459 -0.083013 -0.472299   -1.044232   -0.717087  0.121094   \n",
       "   161873  0.456605 -0.687245 -0.412623   -0.552164   -1.012635  0.941660   \n",
       "   62316  -0.375018 -0.344236  1.479688   -1.035717    0.287377 -2.279547   \n",
       "   ...          ...       ...       ...         ...         ...       ...   \n",
       "   68076   1.147087  0.114491  0.113090    0.072588   -1.053147  1.334583   \n",
       "   280272 -0.206125  0.253490 -0.157778    0.399347   -1.141596  0.848449   \n",
       "   40085  -0.307518  0.416952 -0.571817    1.867187    1.597794 -1.001552   \n",
       "   244833  0.761824 -0.004141  1.315756   -1.022249   -1.377658  0.803640   \n",
       "   149522 -1.463308  1.056323 -1.558136    1.956734    1.909019  0.162418   \n",
       "   \n",
       "                V10  \n",
       "   169876  0.207365  \n",
       "   37964  -0.066104  \n",
       "   205802  0.189505  \n",
       "   161873  0.709436  \n",
       "   62316   0.370569  \n",
       "   ...          ...  \n",
       "   68076  -0.001347  \n",
       "   280272  0.521386  \n",
       "   40085  -0.654945  \n",
       "   244833 -0.099948  \n",
       "   149522 -1.496696  \n",
       "   \n",
       "   [672 rows x 26 columns]),\n",
       "  ('y_test Set',\n",
       "   169876    0\n",
       "   37964     0\n",
       "   205802    0\n",
       "   161873    0\n",
       "   62316     0\n",
       "            ..\n",
       "   68076     0\n",
       "   280272    0\n",
       "   40085     1\n",
       "   244833    0\n",
       "   149522    1\n",
       "   Name: target, Length: 672, dtype: int64),\n",
       "  ('Transformation Pipeline',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('dtypes',\n",
       "                    DataTypes_Auto_infer(categorical_features=[],\n",
       "                                         display_types=False, features_todrop=[],\n",
       "                                         id_columns=[],\n",
       "                                         ml_usecase='classification',\n",
       "                                         numerical_features=['Time', 'V1', 'V2',\n",
       "                                                             'V3', 'V4', 'V5',\n",
       "                                                             'V6', 'V7', 'V8',\n",
       "                                                             'V9', 'V10', 'V11',\n",
       "                                                             'V12', 'V13', 'V14',\n",
       "                                                             'V15', 'V16', 'V17',\n",
       "                                                             'V18', 'V19', 'V20',\n",
       "                                                             'V21', 'V22', 'V23',\n",
       "                                                             'V24', 'V25', 'V26',\n",
       "                                                             'V27', 'V28',...\n",
       "                    Advanced_Feature_Selection_Classic(ml_usecase='classification',\n",
       "                                                       n_jobs=-1,\n",
       "                                                       random_state=8364,\n",
       "                                                       subclass='binary',\n",
       "                                                       target='target',\n",
       "                                                       top_features_to_pick=0.5)),\n",
       "                   ('fix_multi',\n",
       "                    Fix_multicollinearity(correlation_with_target_preference=None,\n",
       "                                          correlation_with_target_threshold=0.0,\n",
       "                                          target_variable='target',\n",
       "                                          threshold=0.6)),\n",
       "                   ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "            verbose=False))],\n",
       " [      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9682  0.9896  0.8261  0.9500  0.8837  0.8654  0.8682  0.9596\n",
       "  1       0.9554  0.9591  0.8261  0.8636  0.8444  0.8184  0.8187  0.9098\n",
       "  2       0.9936  0.9981  0.9565  1.0000  0.9778  0.9741  0.9744  0.9910\n",
       "  3       0.9554  0.9390  0.7826  0.9000  0.8372  0.8115  0.8142  0.9003\n",
       "  4       0.9745  0.9948  0.8696  0.9524  0.9091  0.8943  0.8956  0.9756\n",
       "  5       0.9872  0.9756  0.9091  1.0000  0.9524  0.9450  0.9464  0.9518\n",
       "  6       0.9744  0.9712  0.8636  0.9500  0.9048  0.8900  0.8913  0.9283\n",
       "  7       0.9872  0.9885  0.9545  0.9545  0.9545  0.9471  0.9471  0.9707\n",
       "  8       0.9679  0.9674  0.8182  0.9474  0.8780  0.8597  0.8628  0.9292\n",
       "  9       0.9872  0.9986  0.9545  0.9545  0.9545  0.9471  0.9471  0.9925\n",
       "  Mean    0.9751  0.9782  0.8761  0.9472  0.9097  0.8953  0.8966  0.9509\n",
       "  Std     0.0129  0.0184  0.0610  0.0386  0.0466  0.0540  0.0534  0.0311,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9618  0.9792  0.7391  1.0000  0.8500  0.8287  0.8411  0.9386\n",
       "  1       0.9618  0.9335  0.8261  0.9048  0.8636  0.8415  0.8426  0.8904\n",
       "  2       0.9873  0.9997  0.9565  0.9565  0.9565  0.9491  0.9491  0.9982\n",
       "  3       0.9682  0.9643  0.7826  1.0000  0.8780  0.8600  0.8686  0.9045\n",
       "  4       0.9745  0.9745  0.8696  0.9524  0.9091  0.8943  0.8956  0.9485\n",
       "  5       0.9808  0.9886  0.8636  1.0000  0.9268  0.9158  0.9191  0.9700\n",
       "  6       0.9808  0.9790  0.8636  1.0000  0.9268  0.9158  0.9191  0.9443\n",
       "  7       0.9936  0.9976  0.9545  1.0000  0.9767  0.9730  0.9734  0.9890\n",
       "  8       0.9679  0.9629  0.8182  0.9474  0.8780  0.8597  0.8628  0.9370\n",
       "  9       0.9872  0.9975  0.9091  1.0000  0.9524  0.9450  0.9464  0.9857\n",
       "  Mean    0.9764  0.9777  0.8583  0.9761  0.9118  0.8983  0.9018  0.9506\n",
       "  Std     0.0107  0.0194  0.0665  0.0321  0.0409  0.0469  0.0445  0.0339,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9682  0.9916  0.7826  1.0000  0.8780  0.8600  0.8686  0.9627\n",
       "  1       0.9554  0.9515  0.8261  0.8636  0.8444  0.8184  0.8187  0.9013\n",
       "  2       0.9873  0.9987  0.9565  0.9565  0.9565  0.9491  0.9491  0.9922\n",
       "  3       0.9682  0.9590  0.7826  1.0000  0.8780  0.8600  0.8686  0.8956\n",
       "  4       0.9809  0.9836  0.8696  1.0000  0.9302  0.9192  0.9222  0.9628\n",
       "  5       0.9872  0.9751  0.9091  1.0000  0.9524  0.9450  0.9464  0.9560\n",
       "  6       0.9808  0.9800  0.8636  1.0000  0.9268  0.9158  0.9191  0.9350\n",
       "  7       0.9936  0.9964  0.9545  1.0000  0.9767  0.9730  0.9734  0.9831\n",
       "  8       0.9744  0.9517  0.8182  1.0000  0.9000  0.8855  0.8913  0.9269\n",
       "  9       0.9808  0.9980  0.9091  0.9524  0.9302  0.9191  0.9194  0.9891\n",
       "  Mean    0.9777  0.9785  0.8672  0.9773  0.9173  0.9045  0.9077  0.9505\n",
       "  Std     0.0107  0.0178  0.0613  0.0419  0.0393  0.0454  0.0439  0.0329,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9427  0.9809  0.7826  0.8182  0.8000  0.7666  0.7668  0.9311\n",
       "  1       0.9363  0.9559  0.8261  0.7600  0.7917  0.7541  0.7551  0.8966\n",
       "  2       0.9682  0.9948  0.9565  0.8462  0.8980  0.8792  0.8815  0.9822\n",
       "  3       0.9363  0.9299  0.8261  0.7600  0.7917  0.7541  0.7551  0.8742\n",
       "  4       0.9682  0.9825  0.9565  0.8462  0.8980  0.8792  0.8815  0.9628\n",
       "  5       0.9808  0.9281  0.9091  0.9524  0.9302  0.9191  0.9194  0.9246\n",
       "  6       0.9744  0.9783  0.8636  0.9500  0.9048  0.8900  0.8913  0.9496\n",
       "  7       0.9679  0.9976  1.0000  0.8148  0.8980  0.8792  0.8857  0.9876\n",
       "  8       0.9423  0.9735  0.8636  0.7600  0.8085  0.7747  0.7769  0.9280\n",
       "  9       0.9551  0.9986  1.0000  0.7586  0.8627  0.8365  0.8479  0.9925\n",
       "  Mean    0.9572  0.9720  0.8984  0.8266  0.8583  0.8333  0.8361  0.9429\n",
       "  Std     0.0159  0.0247  0.0733  0.0707  0.0518  0.0611  0.0618  0.0374,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9682  0.9848  0.8261  0.9500  0.8837  0.8654  0.8682  0.9482\n",
       "  1       0.9554  0.9380  0.8261  0.8636  0.8444  0.8184  0.8187  0.8941\n",
       "  2       0.9745  0.9990  0.9565  0.8800  0.9167  0.9017  0.9028  0.9950\n",
       "  3       0.9490  0.9351  0.7391  0.8947  0.8095  0.7804  0.7852  0.8769\n",
       "  4       0.9809  0.9883  0.8696  1.0000  0.9302  0.9192  0.9222  0.9673\n",
       "  5       0.9744  0.9817  0.9091  0.9091  0.9091  0.8942  0.8942  0.9599\n",
       "  6       0.9744  0.9627  0.8636  0.9500  0.9048  0.8900  0.8913  0.9293\n",
       "  7       0.9744  0.9959  0.9545  0.8750  0.9130  0.8980  0.8992  0.9840\n",
       "  8       0.9679  0.9579  0.8182  0.9474  0.8780  0.8597  0.8628  0.9179\n",
       "  9       0.9615  0.9976  0.9545  0.8077  0.8750  0.8525  0.8566  0.9882\n",
       "  Mean    0.9681  0.9741  0.8717  0.9078  0.8865  0.8679  0.8701  0.9461\n",
       "  Std     0.0094  0.0229  0.0685  0.0526  0.0350  0.0403  0.0397  0.0385],\n",
       " StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       " Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=False, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=['Time', 'V1', 'V2',\n",
       "                                                           'V3', 'V4', 'V5',\n",
       "                                                           'V6', 'V7', 'V8',\n",
       "                                                           'V9', 'V10', 'V11',\n",
       "                                                           'V12', 'V13', 'V14',\n",
       "                                                           'V15', 'V16', 'V17',\n",
       "                                                           'V18', 'V19', 'V20',\n",
       "                                                           'V21', 'V22', 'V23',\n",
       "                                                           'V24', 'V25', 'V26',\n",
       "                                                           'V27', 'V28',...\n",
       "                  Advanced_Feature_Selection_Classic(ml_usecase='classification',\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=8364,\n",
       "                                                     subclass='binary',\n",
       "                                                     target='target',\n",
       "                                                     top_features_to_pick=0.5)),\n",
       "                 ('fix_multi',\n",
       "                  Fix_multicollinearity(correlation_with_target_preference=None,\n",
       "                                        correlation_with_target_threshold=0.0,\n",
       "                                        target_variable='target',\n",
       "                                        threshold=0.6)),\n",
       "                 ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "          verbose=False),\n",
       " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x19d12558370>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x19d12558d60>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x19d12558430>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x19d12558dc0>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x19d125588e0>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x19d1254a5e0>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x19d1254a910>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x19d1254a490>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x19d1262e4f0>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x19d1262e670>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x19d1262e880>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x19d1262eb50>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x19d12643520>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x19d126435b0>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x19d12643a00>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x19d12643eb0>,\n",
       "  'dummy': <pycaret.containers.models.classification.DummyClassifierContainer at 0x19d1264d2e0>},\n",
       "               V7        V1       V12        V9    Amount       V17        V4  \\\n",
       " 138220  0.265083 -0.196958 -0.487010 -0.332639  1.324569  0.410145  1.181590   \n",
       " 219598  0.183160 -0.904125  0.209379  0.096901  0.997522  0.884877 -0.237116   \n",
       " 241429 -0.712396  1.545956 -0.701428 -0.151951  0.948491  0.246829 -1.099216   \n",
       " 144299  0.690037 -0.855102 -0.334909  0.370678 -0.643328 -0.191720  0.200385   \n",
       " 76929  -1.070908 -0.151242 -1.606471 -0.833041 -1.425592 -1.298216  1.268414   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 46488   0.532223 -0.281750 -0.226939  0.112520 -0.739473 -0.227180  0.068308   \n",
       " 88728   0.156744  0.035133  0.496221  0.567199  1.627174  0.275769  0.259729   \n",
       " 178254  0.272608  1.752395 -0.124000 -0.660407 -0.051550  0.293956 -0.749559   \n",
       " 83440  -0.400768 -0.801337 -0.013514  0.002542  0.724290  1.413233  1.259491   \n",
       " 214662 -1.193611  0.119992 -1.595008 -0.529261  0.968460 -1.588336  0.871428   \n",
       " \n",
       "              V16       V14       V21  ...       V28        V5       V11  \\\n",
       " 138220 -0.278976  0.360936  0.426420  ...  0.666536 -0.158122 -1.688718   \n",
       " 219598  0.414525 -0.413743 -0.022274  ... -0.366546  0.835042  0.275630   \n",
       " 241429  0.065830 -0.346235 -0.142693  ... -0.084743 -0.762272 -1.768187   \n",
       " 144299 -0.166308 -0.098293 -0.245247  ... -2.839484  0.713676 -0.648129   \n",
       " 76929  -1.507659 -2.168672  0.163328  ...  1.477339 -0.275536  1.429732   \n",
       " ...          ...       ...       ...  ...       ...       ...       ...   \n",
       " 46488  -0.114349  0.100918 -0.160456  ... -0.797756  0.792799 -0.630440   \n",
       " 88728  -0.139906  0.116218  0.130825  ...  0.216221 -0.552889 -0.080422   \n",
       " 178254  0.272175  0.713220  0.340673  ... -0.356067  0.241566  0.528108   \n",
       " 83440  -0.589218  0.001224 -0.190917  ... -0.317122 -0.551990 -2.039493   \n",
       " 214662 -1.727785 -1.918868  0.668173  ...  1.152568 -0.255414  1.784829   \n",
       " \n",
       "               V6        V2        V3  V14_Power2  V11_Power2       V19  \\\n",
       " 138220  1.220959 -0.014035  0.575639   -0.762800    0.845331  0.838603   \n",
       " 219598 -0.693308 -0.449336 -0.255767    0.386296   -0.763396  0.251947   \n",
       " 241429  0.361315 -1.250742 -0.170604    0.122687    0.902619 -0.264476   \n",
       " 144299  0.051264 -0.009211  0.545434   -0.784744   -0.503447 -0.206304   \n",
       " 76929  -0.738203  0.884058 -1.219764    1.967253    1.708536  0.065229   \n",
       " ...          ...       ...       ...         ...         ...       ...   \n",
       " 46488   1.087305  0.225498  0.581112   -1.047703   -0.538098  0.710229   \n",
       " 88728   0.046408 -0.976716  0.192816   -1.046322   -1.390696 -0.560701   \n",
       " 178254 -0.688338 -0.361735 -0.882586   -0.089367    0.134726  1.002351   \n",
       " 83440   1.162012  0.336973  1.919488   -0.984480    1.069376  1.214871   \n",
       " 214662  0.151121  0.384686 -1.442357    1.950260    1.875208 -0.202743   \n",
       " \n",
       "              V10  \n",
       " 138220  0.464974  \n",
       " 219598 -0.550381  \n",
       " 241429  1.119493  \n",
       " 144299  0.616749  \n",
       " 76929  -1.822439  \n",
       " ...          ...  \n",
       " 46488   0.154105  \n",
       " 88728  -0.070809  \n",
       " 178254  0.872222  \n",
       " 83440   0.150695  \n",
       " 214662 -1.680108  \n",
       " \n",
       " [2237 rows x 26 columns],\n",
       " {'parameter': 'Hyperparameters',\n",
       "  'auc': 'AUC',\n",
       "  'confusion_matrix': 'Confusion Matrix',\n",
       "  'threshold': 'Threshold',\n",
       "  'pr': 'Precision Recall',\n",
       "  'error': 'Prediction Error',\n",
       "  'class_report': 'Class Report',\n",
       "  'rfe': 'Feature Selection',\n",
       "  'learning': 'Learning Curve',\n",
       "  'manifold': 'Manifold Learning',\n",
       "  'calibration': 'Calibration Curve',\n",
       "  'vc': 'Validation Curve',\n",
       "  'dimension': 'Dimensions',\n",
       "  'feature': 'Feature Importance',\n",
       "  'feature_all': 'Feature Importance (All)',\n",
       "  'boundary': 'Decision Boundary',\n",
       "  'lift': 'Lift Chart',\n",
       "  'gain': 'Gain Chart',\n",
       "  'tree': 'Decision Tree',\n",
       "  'ks': 'KS Statistic Plot'},\n",
       " [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=8364, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=8364, verbose=0,\n",
       "                       warm_start=False),\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=8364, verbose=0,\n",
       "                         warm_start=False),\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                     random_state=8364, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False),\n",
       "  GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=8364, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False)],\n",
       " False,\n",
       " None,\n",
       " {'USI',\n",
       "  'X',\n",
       "  'X_test',\n",
       "  'X_train',\n",
       "  '_all_metrics',\n",
       "  '_all_models',\n",
       "  '_all_models_internal',\n",
       "  '_available_plots',\n",
       "  '_gpu_n_jobs_param',\n",
       "  '_internal_pipeline',\n",
       "  '_ml_usecase',\n",
       "  'create_model_container',\n",
       "  'dashboard_logger',\n",
       "  'data_before_preprocess',\n",
       "  'display_container',\n",
       "  'exp_name_log',\n",
       "  'experiment__',\n",
       "  'fix_imbalance_method_param',\n",
       "  'fix_imbalance_param',\n",
       "  'fold_generator',\n",
       "  'fold_groups_param',\n",
       "  'fold_groups_param_full',\n",
       "  'fold_param',\n",
       "  'fold_shuffle_param',\n",
       "  'gpu_param',\n",
       "  'html_param',\n",
       "  'imputation_classifier',\n",
       "  'imputation_regressor',\n",
       "  'iterative_imputation_iters_param',\n",
       "  'log_plots_param',\n",
       "  'logging_param',\n",
       "  'master_model_container',\n",
       "  'n_jobs_param',\n",
       "  'prep_pipe',\n",
       "  'pycaret_globals',\n",
       "  'seed',\n",
       "  'stratify_param',\n",
       "  'target_param',\n",
       "  'transform_target_method_param',\n",
       "  'transform_target_param',\n",
       "  'y',\n",
       "  'y_test',\n",
       "  'y_train'},\n",
       " 'target',\n",
       " -1,\n",
       " 'box-cox',\n",
       " {'acc': <pycaret.containers.metrics.classification.AccuracyMetricContainer at 0x19d12674b20>,\n",
       "  'auc': <pycaret.containers.metrics.classification.ROCAUCMetricContainer at 0x19d12674b80>,\n",
       "  'recall': <pycaret.containers.metrics.classification.RecallMetricContainer at 0x19d12674c10>,\n",
       "  'precision': <pycaret.containers.metrics.classification.PrecisionMetricContainer at 0x19d12674d60>,\n",
       "  'f1': <pycaret.containers.metrics.classification.F1MetricContainer at 0x19d12674eb0>,\n",
       "  'kappa': <pycaret.containers.metrics.classification.KappaMetricContainer at 0x19d1265e040>,\n",
       "  'mcc': <pycaret.containers.metrics.classification.MCCMetricContainer at 0x19d1265e0d0>,\n",
       "  'apc': <pycaret.containers.metrics.classification.ClassificationMetricContainer at 0x19d1246ceb0>})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=8364, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e30bd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e30bd_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e30bd_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e30bd_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_e30bd_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_e30bd_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_e30bd_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_e30bd_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_e30bd_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_e30bd_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e30bd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e30bd_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_e30bd_row0_col1\" class=\"data row0 col1\" >0.9746</td>\n",
       "      <td id=\"T_e30bd_row0_col2\" class=\"data row0 col2\" >0.9840</td>\n",
       "      <td id=\"T_e30bd_row0_col3\" class=\"data row0 col3\" >0.9006</td>\n",
       "      <td id=\"T_e30bd_row0_col4\" class=\"data row0 col4\" >0.9333</td>\n",
       "      <td id=\"T_e30bd_row0_col5\" class=\"data row0 col5\" >0.9167</td>\n",
       "      <td id=\"T_e30bd_row0_col6\" class=\"data row0 col6\" >0.9017</td>\n",
       "      <td id=\"T_e30bd_row0_col7\" class=\"data row0 col7\" >0.9019</td>\n",
       "      <td id=\"T_e30bd_row0_col8\" class=\"data row0 col8\" >0.9630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d12a22a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = predict_model(best, raw_score=True,data = df_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "Define search space for hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4bbed_row10_col0, #T_4bbed_row10_col1, #T_4bbed_row10_col2, #T_4bbed_row10_col3, #T_4bbed_row10_col4, #T_4bbed_row10_col5, #T_4bbed_row10_col6, #T_4bbed_row10_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4bbed\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4bbed_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_4bbed_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_4bbed_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_4bbed_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_4bbed_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_4bbed_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_4bbed_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_4bbed_level0_col7\" class=\"col_heading level0 col7\" >APC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4bbed_row0_col0\" class=\"data row0 col0\" >0.9745</td>\n",
       "      <td id=\"T_4bbed_row0_col1\" class=\"data row0 col1\" >0.9705</td>\n",
       "      <td id=\"T_4bbed_row0_col2\" class=\"data row0 col2\" >0.8261</td>\n",
       "      <td id=\"T_4bbed_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_4bbed_row0_col4\" class=\"data row0 col4\" >0.9048</td>\n",
       "      <td id=\"T_4bbed_row0_col5\" class=\"data row0 col5\" >0.8902</td>\n",
       "      <td id=\"T_4bbed_row0_col6\" class=\"data row0 col6\" >0.8956</td>\n",
       "      <td id=\"T_4bbed_row0_col7\" class=\"data row0 col7\" >0.9414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_4bbed_row1_col0\" class=\"data row1 col0\" >0.9618</td>\n",
       "      <td id=\"T_4bbed_row1_col1\" class=\"data row1 col1\" >0.9491</td>\n",
       "      <td id=\"T_4bbed_row1_col2\" class=\"data row1 col2\" >0.8261</td>\n",
       "      <td id=\"T_4bbed_row1_col3\" class=\"data row1 col3\" >0.9048</td>\n",
       "      <td id=\"T_4bbed_row1_col4\" class=\"data row1 col4\" >0.8636</td>\n",
       "      <td id=\"T_4bbed_row1_col5\" class=\"data row1 col5\" >0.8415</td>\n",
       "      <td id=\"T_4bbed_row1_col6\" class=\"data row1 col6\" >0.8426</td>\n",
       "      <td id=\"T_4bbed_row1_col7\" class=\"data row1 col7\" >0.9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_4bbed_row2_col0\" class=\"data row2 col0\" >0.9936</td>\n",
       "      <td id=\"T_4bbed_row2_col1\" class=\"data row2 col1\" >0.9990</td>\n",
       "      <td id=\"T_4bbed_row2_col2\" class=\"data row2 col2\" >0.9565</td>\n",
       "      <td id=\"T_4bbed_row2_col3\" class=\"data row2 col3\" >1.0000</td>\n",
       "      <td id=\"T_4bbed_row2_col4\" class=\"data row2 col4\" >0.9778</td>\n",
       "      <td id=\"T_4bbed_row2_col5\" class=\"data row2 col5\" >0.9741</td>\n",
       "      <td id=\"T_4bbed_row2_col6\" class=\"data row2 col6\" >0.9744</td>\n",
       "      <td id=\"T_4bbed_row2_col7\" class=\"data row2 col7\" >0.9950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_4bbed_row3_col0\" class=\"data row3 col0\" >0.9554</td>\n",
       "      <td id=\"T_4bbed_row3_col1\" class=\"data row3 col1\" >0.9721</td>\n",
       "      <td id=\"T_4bbed_row3_col2\" class=\"data row3 col2\" >0.7826</td>\n",
       "      <td id=\"T_4bbed_row3_col3\" class=\"data row3 col3\" >0.9000</td>\n",
       "      <td id=\"T_4bbed_row3_col4\" class=\"data row3 col4\" >0.8372</td>\n",
       "      <td id=\"T_4bbed_row3_col5\" class=\"data row3 col5\" >0.8115</td>\n",
       "      <td id=\"T_4bbed_row3_col6\" class=\"data row3 col6\" >0.8142</td>\n",
       "      <td id=\"T_4bbed_row3_col7\" class=\"data row3 col7\" >0.9171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_4bbed_row4_col0\" class=\"data row4 col0\" >0.9745</td>\n",
       "      <td id=\"T_4bbed_row4_col1\" class=\"data row4 col1\" >0.9912</td>\n",
       "      <td id=\"T_4bbed_row4_col2\" class=\"data row4 col2\" >0.8696</td>\n",
       "      <td id=\"T_4bbed_row4_col3\" class=\"data row4 col3\" >0.9524</td>\n",
       "      <td id=\"T_4bbed_row4_col4\" class=\"data row4 col4\" >0.9091</td>\n",
       "      <td id=\"T_4bbed_row4_col5\" class=\"data row4 col5\" >0.8943</td>\n",
       "      <td id=\"T_4bbed_row4_col6\" class=\"data row4 col6\" >0.8956</td>\n",
       "      <td id=\"T_4bbed_row4_col7\" class=\"data row4 col7\" >0.9722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_4bbed_row5_col0\" class=\"data row5 col0\" >0.9872</td>\n",
       "      <td id=\"T_4bbed_row5_col1\" class=\"data row5 col1\" >0.9824</td>\n",
       "      <td id=\"T_4bbed_row5_col2\" class=\"data row5 col2\" >0.9091</td>\n",
       "      <td id=\"T_4bbed_row5_col3\" class=\"data row5 col3\" >1.0000</td>\n",
       "      <td id=\"T_4bbed_row5_col4\" class=\"data row5 col4\" >0.9524</td>\n",
       "      <td id=\"T_4bbed_row5_col5\" class=\"data row5 col5\" >0.9450</td>\n",
       "      <td id=\"T_4bbed_row5_col6\" class=\"data row5 col6\" >0.9464</td>\n",
       "      <td id=\"T_4bbed_row5_col7\" class=\"data row5 col7\" >0.9530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_4bbed_row6_col0\" class=\"data row6 col0\" >0.9744</td>\n",
       "      <td id=\"T_4bbed_row6_col1\" class=\"data row6 col1\" >0.9634</td>\n",
       "      <td id=\"T_4bbed_row6_col2\" class=\"data row6 col2\" >0.8636</td>\n",
       "      <td id=\"T_4bbed_row6_col3\" class=\"data row6 col3\" >0.9500</td>\n",
       "      <td id=\"T_4bbed_row6_col4\" class=\"data row6 col4\" >0.9048</td>\n",
       "      <td id=\"T_4bbed_row6_col5\" class=\"data row6 col5\" >0.8900</td>\n",
       "      <td id=\"T_4bbed_row6_col6\" class=\"data row6 col6\" >0.8913</td>\n",
       "      <td id=\"T_4bbed_row6_col7\" class=\"data row6 col7\" >0.9155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_4bbed_row7_col0\" class=\"data row7 col0\" >0.9872</td>\n",
       "      <td id=\"T_4bbed_row7_col1\" class=\"data row7 col1\" >0.9898</td>\n",
       "      <td id=\"T_4bbed_row7_col2\" class=\"data row7 col2\" >0.9545</td>\n",
       "      <td id=\"T_4bbed_row7_col3\" class=\"data row7 col3\" >0.9545</td>\n",
       "      <td id=\"T_4bbed_row7_col4\" class=\"data row7 col4\" >0.9545</td>\n",
       "      <td id=\"T_4bbed_row7_col5\" class=\"data row7 col5\" >0.9471</td>\n",
       "      <td id=\"T_4bbed_row7_col6\" class=\"data row7 col6\" >0.9471</td>\n",
       "      <td id=\"T_4bbed_row7_col7\" class=\"data row7 col7\" >0.9738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_4bbed_row8_col0\" class=\"data row8 col0\" >0.9808</td>\n",
       "      <td id=\"T_4bbed_row8_col1\" class=\"data row8 col1\" >0.9593</td>\n",
       "      <td id=\"T_4bbed_row8_col2\" class=\"data row8 col2\" >0.8636</td>\n",
       "      <td id=\"T_4bbed_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_4bbed_row8_col4\" class=\"data row8 col4\" >0.9268</td>\n",
       "      <td id=\"T_4bbed_row8_col5\" class=\"data row8 col5\" >0.9158</td>\n",
       "      <td id=\"T_4bbed_row8_col6\" class=\"data row8 col6\" >0.9191</td>\n",
       "      <td id=\"T_4bbed_row8_col7\" class=\"data row8 col7\" >0.9190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_4bbed_row9_col0\" class=\"data row9 col0\" >0.9872</td>\n",
       "      <td id=\"T_4bbed_row9_col1\" class=\"data row9 col1\" >0.9973</td>\n",
       "      <td id=\"T_4bbed_row9_col2\" class=\"data row9 col2\" >0.9545</td>\n",
       "      <td id=\"T_4bbed_row9_col3\" class=\"data row9 col3\" >0.9545</td>\n",
       "      <td id=\"T_4bbed_row9_col4\" class=\"data row9 col4\" >0.9545</td>\n",
       "      <td id=\"T_4bbed_row9_col5\" class=\"data row9 col5\" >0.9471</td>\n",
       "      <td id=\"T_4bbed_row9_col6\" class=\"data row9 col6\" >0.9471</td>\n",
       "      <td id=\"T_4bbed_row9_col7\" class=\"data row9 col7\" >0.9870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_4bbed_row10_col0\" class=\"data row10 col0\" >0.9777</td>\n",
       "      <td id=\"T_4bbed_row10_col1\" class=\"data row10 col1\" >0.9774</td>\n",
       "      <td id=\"T_4bbed_row10_col2\" class=\"data row10 col2\" >0.8806</td>\n",
       "      <td id=\"T_4bbed_row10_col3\" class=\"data row10 col3\" >0.9616</td>\n",
       "      <td id=\"T_4bbed_row10_col4\" class=\"data row10 col4\" >0.9186</td>\n",
       "      <td id=\"T_4bbed_row10_col5\" class=\"data row10 col5\" >0.9057</td>\n",
       "      <td id=\"T_4bbed_row10_col6\" class=\"data row10 col6\" >0.9073</td>\n",
       "      <td id=\"T_4bbed_row10_col7\" class=\"data row10 col7\" >0.9476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4bbed_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_4bbed_row11_col0\" class=\"data row11 col0\" >0.0115</td>\n",
       "      <td id=\"T_4bbed_row11_col1\" class=\"data row11 col1\" >0.0162</td>\n",
       "      <td id=\"T_4bbed_row11_col2\" class=\"data row11 col2\" >0.0581</td>\n",
       "      <td id=\"T_4bbed_row11_col3\" class=\"data row11 col3\" >0.0364</td>\n",
       "      <td id=\"T_4bbed_row11_col4\" class=\"data row11 col4\" >0.0417</td>\n",
       "      <td id=\"T_4bbed_row11_col5\" class=\"data row11 col5\" >0.0483</td>\n",
       "      <td id=\"T_4bbed_row11_col6\" class=\"data row11 col6\" >0.0477</td>\n",
       "      <td id=\"T_4bbed_row11_col7\" class=\"data row11 col7\" >0.0316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d0636ebb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\"max_depth\": np.random.randint(1, 40, 10),\n",
    "          \"n_estimators\": np.random.randint(2, 1000, 10)}\n",
    "          \n",
    "# tune model\n",
    "tuned_dt = tune_model(best, custom_grid = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=4,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=691, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=8364, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_e6b53\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e6b53_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e6b53_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e6b53_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_e6b53_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_e6b53_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_e6b53_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_e6b53_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_e6b53_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_e6b53_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e6b53_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e6b53_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_e6b53_row0_col1\" class=\"data row0 col1\" >0.9773</td>\n",
       "      <td id=\"T_e6b53_row0_col2\" class=\"data row0 col2\" >0.9849</td>\n",
       "      <td id=\"T_e6b53_row0_col3\" class=\"data row0 col3\" >0.9064</td>\n",
       "      <td id=\"T_e6b53_row0_col4\" class=\"data row0 col4\" >0.9451</td>\n",
       "      <td id=\"T_e6b53_row0_col5\" class=\"data row0 col5\" >0.9254</td>\n",
       "      <td id=\"T_e6b53_row0_col6\" class=\"data row0 col6\" >0.9120</td>\n",
       "      <td id=\"T_e6b53_row0_col7\" class=\"data row0 col7\" >0.9123</td>\n",
       "      <td id=\"T_e6b53_row0_col8\" class=\"data row0 col8\" >0.9658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d1241a130>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = predict_model(tuned_dt, data=df_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f52dc th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f52dc_row0_col0, #T_f52dc_row0_col1, #T_f52dc_row0_col2, #T_f52dc_row0_col3, #T_f52dc_row0_col4, #T_f52dc_row0_col5, #T_f52dc_row0_col6, #T_f52dc_row0_col7, #T_f52dc_row1_col0, #T_f52dc_row1_col1, #T_f52dc_row1_col2, #T_f52dc_row1_col3, #T_f52dc_row1_col4, #T_f52dc_row1_col5, #T_f52dc_row1_col6, #T_f52dc_row1_col7, #T_f52dc_row1_col8, #T_f52dc_row2_col0, #T_f52dc_row2_col3, #T_f52dc_row2_col8, #T_f52dc_row3_col0, #T_f52dc_row3_col1, #T_f52dc_row3_col2, #T_f52dc_row3_col3, #T_f52dc_row3_col4, #T_f52dc_row3_col5, #T_f52dc_row3_col6, #T_f52dc_row3_col7, #T_f52dc_row3_col8, #T_f52dc_row4_col0, #T_f52dc_row4_col1, #T_f52dc_row4_col2, #T_f52dc_row4_col4, #T_f52dc_row4_col5, #T_f52dc_row4_col6, #T_f52dc_row4_col7, #T_f52dc_row4_col8, #T_f52dc_row5_col0, #T_f52dc_row5_col1, #T_f52dc_row5_col2, #T_f52dc_row5_col3, #T_f52dc_row5_col4, #T_f52dc_row5_col5, #T_f52dc_row5_col6, #T_f52dc_row5_col7, #T_f52dc_row5_col8, #T_f52dc_row6_col0, #T_f52dc_row6_col1, #T_f52dc_row6_col2, #T_f52dc_row6_col3, #T_f52dc_row6_col4, #T_f52dc_row6_col5, #T_f52dc_row6_col6, #T_f52dc_row6_col7, #T_f52dc_row6_col8, #T_f52dc_row7_col0, #T_f52dc_row7_col1, #T_f52dc_row7_col2, #T_f52dc_row7_col3, #T_f52dc_row7_col4, #T_f52dc_row7_col5, #T_f52dc_row7_col6, #T_f52dc_row7_col7, #T_f52dc_row7_col8, #T_f52dc_row8_col0, #T_f52dc_row8_col1, #T_f52dc_row8_col2, #T_f52dc_row8_col3, #T_f52dc_row8_col4, #T_f52dc_row8_col5, #T_f52dc_row8_col6, #T_f52dc_row8_col7, #T_f52dc_row8_col8, #T_f52dc_row9_col0, #T_f52dc_row9_col1, #T_f52dc_row9_col2, #T_f52dc_row9_col3, #T_f52dc_row9_col4, #T_f52dc_row9_col5, #T_f52dc_row9_col6, #T_f52dc_row9_col7, #T_f52dc_row9_col8, #T_f52dc_row10_col0, #T_f52dc_row10_col1, #T_f52dc_row10_col2, #T_f52dc_row10_col3, #T_f52dc_row10_col4, #T_f52dc_row10_col5, #T_f52dc_row10_col6, #T_f52dc_row10_col7, #T_f52dc_row10_col8, #T_f52dc_row11_col0, #T_f52dc_row11_col1, #T_f52dc_row11_col2, #T_f52dc_row11_col3, #T_f52dc_row11_col4, #T_f52dc_row11_col5, #T_f52dc_row11_col6, #T_f52dc_row11_col7, #T_f52dc_row11_col8, #T_f52dc_row12_col0, #T_f52dc_row12_col1, #T_f52dc_row12_col2, #T_f52dc_row12_col3, #T_f52dc_row12_col4, #T_f52dc_row12_col5, #T_f52dc_row12_col6, #T_f52dc_row12_col7, #T_f52dc_row12_col8, #T_f52dc_row13_col0, #T_f52dc_row13_col1, #T_f52dc_row13_col2, #T_f52dc_row13_col3, #T_f52dc_row13_col4, #T_f52dc_row13_col5, #T_f52dc_row13_col6, #T_f52dc_row13_col7, #T_f52dc_row13_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f52dc_row0_col8, #T_f52dc_row2_col1, #T_f52dc_row2_col2, #T_f52dc_row2_col4, #T_f52dc_row2_col5, #T_f52dc_row2_col6, #T_f52dc_row2_col7, #T_f52dc_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_f52dc_row0_col9, #T_f52dc_row1_col9, #T_f52dc_row2_col9, #T_f52dc_row3_col9, #T_f52dc_row4_col9, #T_f52dc_row5_col9, #T_f52dc_row6_col9, #T_f52dc_row7_col9, #T_f52dc_row8_col9, #T_f52dc_row9_col9, #T_f52dc_row10_col9, #T_f52dc_row12_col9, #T_f52dc_row13_col9 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_f52dc_row11_col9 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f52dc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f52dc_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_f52dc_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_f52dc_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_f52dc_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_f52dc_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_f52dc_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_f52dc_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_f52dc_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_f52dc_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "      <th id=\"T_f52dc_level0_col9\" class=\"col_heading level0 col9\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_f52dc_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_f52dc_row0_col1\" class=\"data row0 col1\" >0.9751</td>\n",
       "      <td id=\"T_f52dc_row0_col2\" class=\"data row0 col2\" >0.9782</td>\n",
       "      <td id=\"T_f52dc_row0_col3\" class=\"data row0 col3\" >0.8761</td>\n",
       "      <td id=\"T_f52dc_row0_col4\" class=\"data row0 col4\" >0.9472</td>\n",
       "      <td id=\"T_f52dc_row0_col5\" class=\"data row0 col5\" >0.9097</td>\n",
       "      <td id=\"T_f52dc_row0_col6\" class=\"data row0 col6\" >0.8953</td>\n",
       "      <td id=\"T_f52dc_row0_col7\" class=\"data row0 col7\" >0.8966</td>\n",
       "      <td id=\"T_f52dc_row0_col8\" class=\"data row0 col8\" >0.9509</td>\n",
       "      <td id=\"T_f52dc_row0_col9\" class=\"data row0 col9\" >0.3330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row1\" class=\"row_heading level0 row1\" >et</th>\n",
       "      <td id=\"T_f52dc_row1_col0\" class=\"data row1 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_f52dc_row1_col1\" class=\"data row1 col1\" >0.9764</td>\n",
       "      <td id=\"T_f52dc_row1_col2\" class=\"data row1 col2\" >0.9777</td>\n",
       "      <td id=\"T_f52dc_row1_col3\" class=\"data row1 col3\" >0.8583</td>\n",
       "      <td id=\"T_f52dc_row1_col4\" class=\"data row1 col4\" >0.9761</td>\n",
       "      <td id=\"T_f52dc_row1_col5\" class=\"data row1 col5\" >0.9118</td>\n",
       "      <td id=\"T_f52dc_row1_col6\" class=\"data row1 col6\" >0.8983</td>\n",
       "      <td id=\"T_f52dc_row1_col7\" class=\"data row1 col7\" >0.9018</td>\n",
       "      <td id=\"T_f52dc_row1_col8\" class=\"data row1 col8\" >0.9506</td>\n",
       "      <td id=\"T_f52dc_row1_col9\" class=\"data row1 col9\" >0.3740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_f52dc_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_f52dc_row2_col1\" class=\"data row2 col1\" >0.9777</td>\n",
       "      <td id=\"T_f52dc_row2_col2\" class=\"data row2 col2\" >0.9785</td>\n",
       "      <td id=\"T_f52dc_row2_col3\" class=\"data row2 col3\" >0.8672</td>\n",
       "      <td id=\"T_f52dc_row2_col4\" class=\"data row2 col4\" >0.9773</td>\n",
       "      <td id=\"T_f52dc_row2_col5\" class=\"data row2 col5\" >0.9173</td>\n",
       "      <td id=\"T_f52dc_row2_col6\" class=\"data row2 col6\" >0.9045</td>\n",
       "      <td id=\"T_f52dc_row2_col7\" class=\"data row2 col7\" >0.9077</td>\n",
       "      <td id=\"T_f52dc_row2_col8\" class=\"data row2 col8\" >0.9505</td>\n",
       "      <td id=\"T_f52dc_row2_col9\" class=\"data row2 col9\" >0.6270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row3\" class=\"row_heading level0 row3\" >gbc</th>\n",
       "      <td id=\"T_f52dc_row3_col0\" class=\"data row3 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_f52dc_row3_col1\" class=\"data row3 col1\" >0.9681</td>\n",
       "      <td id=\"T_f52dc_row3_col2\" class=\"data row3 col2\" >0.9741</td>\n",
       "      <td id=\"T_f52dc_row3_col3\" class=\"data row3 col3\" >0.8717</td>\n",
       "      <td id=\"T_f52dc_row3_col4\" class=\"data row3 col4\" >0.9078</td>\n",
       "      <td id=\"T_f52dc_row3_col5\" class=\"data row3 col5\" >0.8865</td>\n",
       "      <td id=\"T_f52dc_row3_col6\" class=\"data row3 col6\" >0.8679</td>\n",
       "      <td id=\"T_f52dc_row3_col7\" class=\"data row3 col7\" >0.8701</td>\n",
       "      <td id=\"T_f52dc_row3_col8\" class=\"data row3 col8\" >0.9461</td>\n",
       "      <td id=\"T_f52dc_row3_col9\" class=\"data row3 col9\" >1.4040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row4\" class=\"row_heading level0 row4\" >lr</th>\n",
       "      <td id=\"T_f52dc_row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_f52dc_row4_col1\" class=\"data row4 col1\" >0.9572</td>\n",
       "      <td id=\"T_f52dc_row4_col2\" class=\"data row4 col2\" >0.9720</td>\n",
       "      <td id=\"T_f52dc_row4_col3\" class=\"data row4 col3\" >0.8984</td>\n",
       "      <td id=\"T_f52dc_row4_col4\" class=\"data row4 col4\" >0.8266</td>\n",
       "      <td id=\"T_f52dc_row4_col5\" class=\"data row4 col5\" >0.8583</td>\n",
       "      <td id=\"T_f52dc_row4_col6\" class=\"data row4 col6\" >0.8333</td>\n",
       "      <td id=\"T_f52dc_row4_col7\" class=\"data row4 col7\" >0.8361</td>\n",
       "      <td id=\"T_f52dc_row4_col8\" class=\"data row4 col8\" >0.9429</td>\n",
       "      <td id=\"T_f52dc_row4_col9\" class=\"data row4 col9\" >1.6660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row5\" class=\"row_heading level0 row5\" >lda</th>\n",
       "      <td id=\"T_f52dc_row5_col0\" class=\"data row5 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_f52dc_row5_col1\" class=\"data row5 col1\" >0.9706</td>\n",
       "      <td id=\"T_f52dc_row5_col2\" class=\"data row5 col2\" >0.9734</td>\n",
       "      <td id=\"T_f52dc_row5_col3\" class=\"data row5 col3\" >0.8850</td>\n",
       "      <td id=\"T_f52dc_row5_col4\" class=\"data row5 col4\" >0.9141</td>\n",
       "      <td id=\"T_f52dc_row5_col5\" class=\"data row5 col5\" >0.8966</td>\n",
       "      <td id=\"T_f52dc_row5_col6\" class=\"data row5 col6\" >0.8795</td>\n",
       "      <td id=\"T_f52dc_row5_col7\" class=\"data row5 col7\" >0.8815</td>\n",
       "      <td id=\"T_f52dc_row5_col8\" class=\"data row5 col8\" >0.9410</td>\n",
       "      <td id=\"T_f52dc_row5_col9\" class=\"data row5 col9\" >0.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row6\" class=\"row_heading level0 row6\" >ada</th>\n",
       "      <td id=\"T_f52dc_row6_col0\" class=\"data row6 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_f52dc_row6_col1\" class=\"data row6 col1\" >0.9623</td>\n",
       "      <td id=\"T_f52dc_row6_col2\" class=\"data row6 col2\" >0.9615</td>\n",
       "      <td id=\"T_f52dc_row6_col3\" class=\"data row6 col3\" >0.8846</td>\n",
       "      <td id=\"T_f52dc_row6_col4\" class=\"data row6 col4\" >0.8619</td>\n",
       "      <td id=\"T_f52dc_row6_col5\" class=\"data row6 col5\" >0.8715</td>\n",
       "      <td id=\"T_f52dc_row6_col6\" class=\"data row6 col6\" >0.8495</td>\n",
       "      <td id=\"T_f52dc_row6_col7\" class=\"data row6 col7\" >0.8506</td>\n",
       "      <td id=\"T_f52dc_row6_col8\" class=\"data row6 col8\" >0.9293</td>\n",
       "      <td id=\"T_f52dc_row6_col9\" class=\"data row6 col9\" >0.4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row7\" class=\"row_heading level0 row7\" >knn</th>\n",
       "      <td id=\"T_f52dc_row7_col0\" class=\"data row7 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_f52dc_row7_col1\" class=\"data row7 col1\" >0.9566</td>\n",
       "      <td id=\"T_f52dc_row7_col2\" class=\"data row7 col2\" >0.9657</td>\n",
       "      <td id=\"T_f52dc_row7_col3\" class=\"data row7 col3\" >0.8893</td>\n",
       "      <td id=\"T_f52dc_row7_col4\" class=\"data row7 col4\" >0.8253</td>\n",
       "      <td id=\"T_f52dc_row7_col5\" class=\"data row7 col5\" >0.8549</td>\n",
       "      <td id=\"T_f52dc_row7_col6\" class=\"data row7 col6\" >0.8294</td>\n",
       "      <td id=\"T_f52dc_row7_col7\" class=\"data row7 col7\" >0.8311</td>\n",
       "      <td id=\"T_f52dc_row7_col8\" class=\"data row7 col8\" >0.8968</td>\n",
       "      <td id=\"T_f52dc_row7_col9\" class=\"data row7 col9\" >0.0710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row8\" class=\"row_heading level0 row8\" >qda</th>\n",
       "      <td id=\"T_f52dc_row8_col0\" class=\"data row8 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_f52dc_row8_col1\" class=\"data row8 col1\" >0.9681</td>\n",
       "      <td id=\"T_f52dc_row8_col2\" class=\"data row8 col2\" >0.9467</td>\n",
       "      <td id=\"T_f52dc_row8_col3\" class=\"data row8 col3\" >0.8628</td>\n",
       "      <td id=\"T_f52dc_row8_col4\" class=\"data row8 col4\" >0.9150</td>\n",
       "      <td id=\"T_f52dc_row8_col5\" class=\"data row8 col5\" >0.8852</td>\n",
       "      <td id=\"T_f52dc_row8_col6\" class=\"data row8 col6\" >0.8668</td>\n",
       "      <td id=\"T_f52dc_row8_col7\" class=\"data row8 col7\" >0.8692</td>\n",
       "      <td id=\"T_f52dc_row8_col8\" class=\"data row8 col8\" >0.8910</td>\n",
       "      <td id=\"T_f52dc_row8_col9\" class=\"data row8 col9\" >0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row9\" class=\"row_heading level0 row9\" >nb</th>\n",
       "      <td id=\"T_f52dc_row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_f52dc_row9_col1\" class=\"data row9 col1\" >0.9636</td>\n",
       "      <td id=\"T_f52dc_row9_col2\" class=\"data row9 col2\" >0.9648</td>\n",
       "      <td id=\"T_f52dc_row9_col3\" class=\"data row9 col3\" >0.8806</td>\n",
       "      <td id=\"T_f52dc_row9_col4\" class=\"data row9 col4\" >0.8710</td>\n",
       "      <td id=\"T_f52dc_row9_col5\" class=\"data row9 col5\" >0.8748</td>\n",
       "      <td id=\"T_f52dc_row9_col6\" class=\"data row9 col6\" >0.8536</td>\n",
       "      <td id=\"T_f52dc_row9_col7\" class=\"data row9 col7\" >0.8542</td>\n",
       "      <td id=\"T_f52dc_row9_col8\" class=\"data row9 col8\" >0.8549</td>\n",
       "      <td id=\"T_f52dc_row9_col9\" class=\"data row9 col9\" >0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_f52dc_row10_col0\" class=\"data row10 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_f52dc_row10_col1\" class=\"data row10 col1\" >0.9483</td>\n",
       "      <td id=\"T_f52dc_row10_col2\" class=\"data row10 col2\" >0.9221</td>\n",
       "      <td id=\"T_f52dc_row10_col3\" class=\"data row10 col3\" >0.8852</td>\n",
       "      <td id=\"T_f52dc_row10_col4\" class=\"data row10 col4\" >0.7864</td>\n",
       "      <td id=\"T_f52dc_row10_col5\" class=\"data row10 col5\" >0.8315</td>\n",
       "      <td id=\"T_f52dc_row10_col6\" class=\"data row10 col6\" >0.8012</td>\n",
       "      <td id=\"T_f52dc_row10_col7\" class=\"data row10 col7\" >0.8041</td>\n",
       "      <td id=\"T_f52dc_row10_col8\" class=\"data row10 col8\" >0.7143</td>\n",
       "      <td id=\"T_f52dc_row10_col9\" class=\"data row10 col9\" >0.0520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row11\" class=\"row_heading level0 row11\" >dummy</th>\n",
       "      <td id=\"T_f52dc_row11_col0\" class=\"data row11 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_f52dc_row11_col1\" class=\"data row11 col1\" >0.8562</td>\n",
       "      <td id=\"T_f52dc_row11_col2\" class=\"data row11 col2\" >0.5000</td>\n",
       "      <td id=\"T_f52dc_row11_col3\" class=\"data row11 col3\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row11_col4\" class=\"data row11 col4\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row11_col5\" class=\"data row11 col5\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row11_col8\" class=\"data row11 col8\" >0.1438</td>\n",
       "      <td id=\"T_f52dc_row11_col9\" class=\"data row11 col9\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n",
       "      <td id=\"T_f52dc_row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_f52dc_row12_col1\" class=\"data row12 col1\" >0.9457</td>\n",
       "      <td id=\"T_f52dc_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row12_col3\" class=\"data row12 col3\" >0.8897</td>\n",
       "      <td id=\"T_f52dc_row12_col4\" class=\"data row12 col4\" >0.7865</td>\n",
       "      <td id=\"T_f52dc_row12_col5\" class=\"data row12 col5\" >0.8277</td>\n",
       "      <td id=\"T_f52dc_row12_col6\" class=\"data row12 col6\" >0.7962</td>\n",
       "      <td id=\"T_f52dc_row12_col7\" class=\"data row12 col7\" >0.8033</td>\n",
       "      <td id=\"T_f52dc_row12_col8\" class=\"data row12 col8\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row12_col9\" class=\"data row12 col9\" >0.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f52dc_level0_row13\" class=\"row_heading level0 row13\" >ridge</th>\n",
       "      <td id=\"T_f52dc_row13_col0\" class=\"data row13 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_f52dc_row13_col1\" class=\"data row13 col1\" >0.9706</td>\n",
       "      <td id=\"T_f52dc_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row13_col3\" class=\"data row13 col3\" >0.8850</td>\n",
       "      <td id=\"T_f52dc_row13_col4\" class=\"data row13 col4\" >0.9141</td>\n",
       "      <td id=\"T_f52dc_row13_col5\" class=\"data row13 col5\" >0.8966</td>\n",
       "      <td id=\"T_f52dc_row13_col6\" class=\"data row13 col6\" >0.8795</td>\n",
       "      <td id=\"T_f52dc_row13_col7\" class=\"data row13 col7\" >0.8815</td>\n",
       "      <td id=\"T_f52dc_row13_col8\" class=\"data row13 col8\" >0.0000</td>\n",
       "      <td id=\"T_f52dc_row13_col9\" class=\"data row13 col9\" >0.0240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d128d7f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                random_state=8364, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "                subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       " ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                      criterion='gini', max_depth=None, max_features='auto',\n",
       "                      max_leaf_nodes=None, max_samples=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                      oob_score=False, random_state=8364, verbose=0,\n",
       "                      warm_start=False),\n",
       " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=-1, oob_score=False, random_state=8364, verbose=0,\n",
       "                        warm_start=False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops= compare_models(n_select = 3, sort=\"APC\")\n",
    "tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=8364, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_abf8f_row10_col0, #T_abf8f_row10_col1, #T_abf8f_row10_col2, #T_abf8f_row10_col3, #T_abf8f_row10_col4, #T_abf8f_row10_col5, #T_abf8f_row10_col6, #T_abf8f_row10_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_abf8f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_abf8f_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_abf8f_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_abf8f_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_abf8f_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_abf8f_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_abf8f_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_abf8f_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_abf8f_level0_col7\" class=\"col_heading level0 col7\" >APC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_abf8f_row0_col0\" class=\"data row0 col0\" >0.9745</td>\n",
       "      <td id=\"T_abf8f_row0_col1\" class=\"data row0 col1\" >0.9883</td>\n",
       "      <td id=\"T_abf8f_row0_col2\" class=\"data row0 col2\" >0.8261</td>\n",
       "      <td id=\"T_abf8f_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_abf8f_row0_col4\" class=\"data row0 col4\" >0.9048</td>\n",
       "      <td id=\"T_abf8f_row0_col5\" class=\"data row0 col5\" >0.8902</td>\n",
       "      <td id=\"T_abf8f_row0_col6\" class=\"data row0 col6\" >0.8956</td>\n",
       "      <td id=\"T_abf8f_row0_col7\" class=\"data row0 col7\" >0.9571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_abf8f_row1_col0\" class=\"data row1 col0\" >0.9554</td>\n",
       "      <td id=\"T_abf8f_row1_col1\" class=\"data row1 col1\" >0.9471</td>\n",
       "      <td id=\"T_abf8f_row1_col2\" class=\"data row1 col2\" >0.8261</td>\n",
       "      <td id=\"T_abf8f_row1_col3\" class=\"data row1 col3\" >0.8636</td>\n",
       "      <td id=\"T_abf8f_row1_col4\" class=\"data row1 col4\" >0.8444</td>\n",
       "      <td id=\"T_abf8f_row1_col5\" class=\"data row1 col5\" >0.8184</td>\n",
       "      <td id=\"T_abf8f_row1_col6\" class=\"data row1 col6\" >0.8187</td>\n",
       "      <td id=\"T_abf8f_row1_col7\" class=\"data row1 col7\" >0.8997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_abf8f_row2_col0\" class=\"data row2 col0\" >0.9936</td>\n",
       "      <td id=\"T_abf8f_row2_col1\" class=\"data row2 col1\" >0.9990</td>\n",
       "      <td id=\"T_abf8f_row2_col2\" class=\"data row2 col2\" >0.9565</td>\n",
       "      <td id=\"T_abf8f_row2_col3\" class=\"data row2 col3\" >1.0000</td>\n",
       "      <td id=\"T_abf8f_row2_col4\" class=\"data row2 col4\" >0.9778</td>\n",
       "      <td id=\"T_abf8f_row2_col5\" class=\"data row2 col5\" >0.9741</td>\n",
       "      <td id=\"T_abf8f_row2_col6\" class=\"data row2 col6\" >0.9744</td>\n",
       "      <td id=\"T_abf8f_row2_col7\" class=\"data row2 col7\" >0.9950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_abf8f_row3_col0\" class=\"data row3 col0\" >0.9682</td>\n",
       "      <td id=\"T_abf8f_row3_col1\" class=\"data row3 col1\" >0.9650</td>\n",
       "      <td id=\"T_abf8f_row3_col2\" class=\"data row3 col2\" >0.7826</td>\n",
       "      <td id=\"T_abf8f_row3_col3\" class=\"data row3 col3\" >1.0000</td>\n",
       "      <td id=\"T_abf8f_row3_col4\" class=\"data row3 col4\" >0.8780</td>\n",
       "      <td id=\"T_abf8f_row3_col5\" class=\"data row3 col5\" >0.8600</td>\n",
       "      <td id=\"T_abf8f_row3_col6\" class=\"data row3 col6\" >0.8686</td>\n",
       "      <td id=\"T_abf8f_row3_col7\" class=\"data row3 col7\" >0.9043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_abf8f_row4_col0\" class=\"data row4 col0\" >0.9745</td>\n",
       "      <td id=\"T_abf8f_row4_col1\" class=\"data row4 col1\" >0.9818</td>\n",
       "      <td id=\"T_abf8f_row4_col2\" class=\"data row4 col2\" >0.8696</td>\n",
       "      <td id=\"T_abf8f_row4_col3\" class=\"data row4 col3\" >0.9524</td>\n",
       "      <td id=\"T_abf8f_row4_col4\" class=\"data row4 col4\" >0.9091</td>\n",
       "      <td id=\"T_abf8f_row4_col5\" class=\"data row4 col5\" >0.8943</td>\n",
       "      <td id=\"T_abf8f_row4_col6\" class=\"data row4 col6\" >0.8956</td>\n",
       "      <td id=\"T_abf8f_row4_col7\" class=\"data row4 col7\" >0.9596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_abf8f_row5_col0\" class=\"data row5 col0\" >0.9872</td>\n",
       "      <td id=\"T_abf8f_row5_col1\" class=\"data row5 col1\" >0.9827</td>\n",
       "      <td id=\"T_abf8f_row5_col2\" class=\"data row5 col2\" >0.9091</td>\n",
       "      <td id=\"T_abf8f_row5_col3\" class=\"data row5 col3\" >1.0000</td>\n",
       "      <td id=\"T_abf8f_row5_col4\" class=\"data row5 col4\" >0.9524</td>\n",
       "      <td id=\"T_abf8f_row5_col5\" class=\"data row5 col5\" >0.9450</td>\n",
       "      <td id=\"T_abf8f_row5_col6\" class=\"data row5 col6\" >0.9464</td>\n",
       "      <td id=\"T_abf8f_row5_col7\" class=\"data row5 col7\" >0.9631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_abf8f_row6_col0\" class=\"data row6 col0\" >0.9808</td>\n",
       "      <td id=\"T_abf8f_row6_col1\" class=\"data row6 col1\" >0.9813</td>\n",
       "      <td id=\"T_abf8f_row6_col2\" class=\"data row6 col2\" >0.8636</td>\n",
       "      <td id=\"T_abf8f_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_abf8f_row6_col4\" class=\"data row6 col4\" >0.9268</td>\n",
       "      <td id=\"T_abf8f_row6_col5\" class=\"data row6 col5\" >0.9158</td>\n",
       "      <td id=\"T_abf8f_row6_col6\" class=\"data row6 col6\" >0.9191</td>\n",
       "      <td id=\"T_abf8f_row6_col7\" class=\"data row6 col7\" >0.9439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_abf8f_row7_col0\" class=\"data row7 col0\" >0.9936</td>\n",
       "      <td id=\"T_abf8f_row7_col1\" class=\"data row7 col1\" >0.9969</td>\n",
       "      <td id=\"T_abf8f_row7_col2\" class=\"data row7 col2\" >0.9545</td>\n",
       "      <td id=\"T_abf8f_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_abf8f_row7_col4\" class=\"data row7 col4\" >0.9767</td>\n",
       "      <td id=\"T_abf8f_row7_col5\" class=\"data row7 col5\" >0.9730</td>\n",
       "      <td id=\"T_abf8f_row7_col6\" class=\"data row7 col6\" >0.9734</td>\n",
       "      <td id=\"T_abf8f_row7_col7\" class=\"data row7 col7\" >0.9868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_abf8f_row8_col0\" class=\"data row8 col0\" >0.9744</td>\n",
       "      <td id=\"T_abf8f_row8_col1\" class=\"data row8 col1\" >0.9583</td>\n",
       "      <td id=\"T_abf8f_row8_col2\" class=\"data row8 col2\" >0.8182</td>\n",
       "      <td id=\"T_abf8f_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_abf8f_row8_col4\" class=\"data row8 col4\" >0.9000</td>\n",
       "      <td id=\"T_abf8f_row8_col5\" class=\"data row8 col5\" >0.8855</td>\n",
       "      <td id=\"T_abf8f_row8_col6\" class=\"data row8 col6\" >0.8913</td>\n",
       "      <td id=\"T_abf8f_row8_col7\" class=\"data row8 col7\" >0.9338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_abf8f_row9_col0\" class=\"data row9 col0\" >0.9808</td>\n",
       "      <td id=\"T_abf8f_row9_col1\" class=\"data row9 col1\" >0.9986</td>\n",
       "      <td id=\"T_abf8f_row9_col2\" class=\"data row9 col2\" >0.9091</td>\n",
       "      <td id=\"T_abf8f_row9_col3\" class=\"data row9 col3\" >0.9524</td>\n",
       "      <td id=\"T_abf8f_row9_col4\" class=\"data row9 col4\" >0.9302</td>\n",
       "      <td id=\"T_abf8f_row9_col5\" class=\"data row9 col5\" >0.9191</td>\n",
       "      <td id=\"T_abf8f_row9_col6\" class=\"data row9 col6\" >0.9194</td>\n",
       "      <td id=\"T_abf8f_row9_col7\" class=\"data row9 col7\" >0.9925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_abf8f_row10_col0\" class=\"data row10 col0\" >0.9783</td>\n",
       "      <td id=\"T_abf8f_row10_col1\" class=\"data row10 col1\" >0.9799</td>\n",
       "      <td id=\"T_abf8f_row10_col2\" class=\"data row10 col2\" >0.8715</td>\n",
       "      <td id=\"T_abf8f_row10_col3\" class=\"data row10 col3\" >0.9768</td>\n",
       "      <td id=\"T_abf8f_row10_col4\" class=\"data row10 col4\" >0.9200</td>\n",
       "      <td id=\"T_abf8f_row10_col5\" class=\"data row10 col5\" >0.9075</td>\n",
       "      <td id=\"T_abf8f_row10_col6\" class=\"data row10 col6\" >0.9103</td>\n",
       "      <td id=\"T_abf8f_row10_col7\" class=\"data row10 col7\" >0.9536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_abf8f_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_abf8f_row11_col0\" class=\"data row11 col0\" >0.0111</td>\n",
       "      <td id=\"T_abf8f_row11_col1\" class=\"data row11 col1\" >0.0169</td>\n",
       "      <td id=\"T_abf8f_row11_col2\" class=\"data row11 col2\" >0.0565</td>\n",
       "      <td id=\"T_abf8f_row11_col3\" class=\"data row11 col3\" >0.0422</td>\n",
       "      <td id=\"T_abf8f_row11_col4\" class=\"data row11 col4\" >0.0400</td>\n",
       "      <td id=\"T_abf8f_row11_col5\" class=\"data row11 col5\" >0.0463</td>\n",
       "      <td id=\"T_abf8f_row11_col6\" class=\"data row11 col6\" >0.0452</td>\n",
       "      <td id=\"T_abf8f_row11_col7\" class=\"data row11 col7\" >0.0321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d1292bd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blender_weighted = blend_models([tops[0],tops[1],tops[2]], weights = [0.5,0.3,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ca9f1_row10_col0, #T_ca9f1_row10_col1, #T_ca9f1_row10_col2, #T_ca9f1_row10_col3, #T_ca9f1_row10_col4, #T_ca9f1_row10_col5, #T_ca9f1_row10_col6, #T_ca9f1_row10_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ca9f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ca9f1_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_ca9f1_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_ca9f1_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_ca9f1_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_ca9f1_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_ca9f1_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_ca9f1_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_ca9f1_level0_col7\" class=\"col_heading level0 col7\" >APC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ca9f1_row0_col0\" class=\"data row0 col0\" >0.9682</td>\n",
       "      <td id=\"T_ca9f1_row0_col1\" class=\"data row0 col1\" >0.9886</td>\n",
       "      <td id=\"T_ca9f1_row0_col2\" class=\"data row0 col2\" >0.7826</td>\n",
       "      <td id=\"T_ca9f1_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_ca9f1_row0_col4\" class=\"data row0 col4\" >0.8780</td>\n",
       "      <td id=\"T_ca9f1_row0_col5\" class=\"data row0 col5\" >0.8600</td>\n",
       "      <td id=\"T_ca9f1_row0_col6\" class=\"data row0 col6\" >0.8686</td>\n",
       "      <td id=\"T_ca9f1_row0_col7\" class=\"data row0 col7\" >0.9585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ca9f1_row1_col0\" class=\"data row1 col0\" >0.9554</td>\n",
       "      <td id=\"T_ca9f1_row1_col1\" class=\"data row1 col1\" >0.9447</td>\n",
       "      <td id=\"T_ca9f1_row1_col2\" class=\"data row1 col2\" >0.8261</td>\n",
       "      <td id=\"T_ca9f1_row1_col3\" class=\"data row1 col3\" >0.8636</td>\n",
       "      <td id=\"T_ca9f1_row1_col4\" class=\"data row1 col4\" >0.8444</td>\n",
       "      <td id=\"T_ca9f1_row1_col5\" class=\"data row1 col5\" >0.8184</td>\n",
       "      <td id=\"T_ca9f1_row1_col6\" class=\"data row1 col6\" >0.8187</td>\n",
       "      <td id=\"T_ca9f1_row1_col7\" class=\"data row1 col7\" >0.8979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ca9f1_row2_col0\" class=\"data row2 col0\" >0.9873</td>\n",
       "      <td id=\"T_ca9f1_row2_col1\" class=\"data row2 col1\" >0.9994</td>\n",
       "      <td id=\"T_ca9f1_row2_col2\" class=\"data row2 col2\" >0.9565</td>\n",
       "      <td id=\"T_ca9f1_row2_col3\" class=\"data row2 col3\" >0.9565</td>\n",
       "      <td id=\"T_ca9f1_row2_col4\" class=\"data row2 col4\" >0.9565</td>\n",
       "      <td id=\"T_ca9f1_row2_col5\" class=\"data row2 col5\" >0.9491</td>\n",
       "      <td id=\"T_ca9f1_row2_col6\" class=\"data row2 col6\" >0.9491</td>\n",
       "      <td id=\"T_ca9f1_row2_col7\" class=\"data row2 col7\" >0.9965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ca9f1_row3_col0\" class=\"data row3 col0\" >0.9682</td>\n",
       "      <td id=\"T_ca9f1_row3_col1\" class=\"data row3 col1\" >0.9627</td>\n",
       "      <td id=\"T_ca9f1_row3_col2\" class=\"data row3 col2\" >0.7826</td>\n",
       "      <td id=\"T_ca9f1_row3_col3\" class=\"data row3 col3\" >1.0000</td>\n",
       "      <td id=\"T_ca9f1_row3_col4\" class=\"data row3 col4\" >0.8780</td>\n",
       "      <td id=\"T_ca9f1_row3_col5\" class=\"data row3 col5\" >0.8600</td>\n",
       "      <td id=\"T_ca9f1_row3_col6\" class=\"data row3 col6\" >0.8686</td>\n",
       "      <td id=\"T_ca9f1_row3_col7\" class=\"data row3 col7\" >0.9022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ca9f1_row4_col0\" class=\"data row4 col0\" >0.9809</td>\n",
       "      <td id=\"T_ca9f1_row4_col1\" class=\"data row4 col1\" >0.9818</td>\n",
       "      <td id=\"T_ca9f1_row4_col2\" class=\"data row4 col2\" >0.8696</td>\n",
       "      <td id=\"T_ca9f1_row4_col3\" class=\"data row4 col3\" >1.0000</td>\n",
       "      <td id=\"T_ca9f1_row4_col4\" class=\"data row4 col4\" >0.9302</td>\n",
       "      <td id=\"T_ca9f1_row4_col5\" class=\"data row4 col5\" >0.9192</td>\n",
       "      <td id=\"T_ca9f1_row4_col6\" class=\"data row4 col6\" >0.9222</td>\n",
       "      <td id=\"T_ca9f1_row4_col7\" class=\"data row4 col7\" >0.9598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ca9f1_row5_col0\" class=\"data row5 col0\" >0.9872</td>\n",
       "      <td id=\"T_ca9f1_row5_col1\" class=\"data row5 col1\" >0.9829</td>\n",
       "      <td id=\"T_ca9f1_row5_col2\" class=\"data row5 col2\" >0.9091</td>\n",
       "      <td id=\"T_ca9f1_row5_col3\" class=\"data row5 col3\" >1.0000</td>\n",
       "      <td id=\"T_ca9f1_row5_col4\" class=\"data row5 col4\" >0.9524</td>\n",
       "      <td id=\"T_ca9f1_row5_col5\" class=\"data row5 col5\" >0.9450</td>\n",
       "      <td id=\"T_ca9f1_row5_col6\" class=\"data row5 col6\" >0.9464</td>\n",
       "      <td id=\"T_ca9f1_row5_col7\" class=\"data row5 col7\" >0.9631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ca9f1_row6_col0\" class=\"data row6 col0\" >0.9808</td>\n",
       "      <td id=\"T_ca9f1_row6_col1\" class=\"data row6 col1\" >0.9815</td>\n",
       "      <td id=\"T_ca9f1_row6_col2\" class=\"data row6 col2\" >0.8636</td>\n",
       "      <td id=\"T_ca9f1_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_ca9f1_row6_col4\" class=\"data row6 col4\" >0.9268</td>\n",
       "      <td id=\"T_ca9f1_row6_col5\" class=\"data row6 col5\" >0.9158</td>\n",
       "      <td id=\"T_ca9f1_row6_col6\" class=\"data row6 col6\" >0.9191</td>\n",
       "      <td id=\"T_ca9f1_row6_col7\" class=\"data row6 col7\" >0.9431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ca9f1_row7_col0\" class=\"data row7 col0\" >0.9936</td>\n",
       "      <td id=\"T_ca9f1_row7_col1\" class=\"data row7 col1\" >0.9973</td>\n",
       "      <td id=\"T_ca9f1_row7_col2\" class=\"data row7 col2\" >0.9545</td>\n",
       "      <td id=\"T_ca9f1_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_ca9f1_row7_col4\" class=\"data row7 col4\" >0.9767</td>\n",
       "      <td id=\"T_ca9f1_row7_col5\" class=\"data row7 col5\" >0.9730</td>\n",
       "      <td id=\"T_ca9f1_row7_col6\" class=\"data row7 col6\" >0.9734</td>\n",
       "      <td id=\"T_ca9f1_row7_col7\" class=\"data row7 col7\" >0.9879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ca9f1_row8_col0\" class=\"data row8 col0\" >0.9744</td>\n",
       "      <td id=\"T_ca9f1_row8_col1\" class=\"data row8 col1\" >0.9573</td>\n",
       "      <td id=\"T_ca9f1_row8_col2\" class=\"data row8 col2\" >0.8182</td>\n",
       "      <td id=\"T_ca9f1_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_ca9f1_row8_col4\" class=\"data row8 col4\" >0.9000</td>\n",
       "      <td id=\"T_ca9f1_row8_col5\" class=\"data row8 col5\" >0.8855</td>\n",
       "      <td id=\"T_ca9f1_row8_col6\" class=\"data row8 col6\" >0.8913</td>\n",
       "      <td id=\"T_ca9f1_row8_col7\" class=\"data row8 col7\" >0.9346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ca9f1_row9_col0\" class=\"data row9 col0\" >0.9872</td>\n",
       "      <td id=\"T_ca9f1_row9_col1\" class=\"data row9 col1\" >0.9976</td>\n",
       "      <td id=\"T_ca9f1_row9_col2\" class=\"data row9 col2\" >0.9091</td>\n",
       "      <td id=\"T_ca9f1_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_ca9f1_row9_col4\" class=\"data row9 col4\" >0.9524</td>\n",
       "      <td id=\"T_ca9f1_row9_col5\" class=\"data row9 col5\" >0.9450</td>\n",
       "      <td id=\"T_ca9f1_row9_col6\" class=\"data row9 col6\" >0.9464</td>\n",
       "      <td id=\"T_ca9f1_row9_col7\" class=\"data row9 col7\" >0.9873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_ca9f1_row10_col0\" class=\"data row10 col0\" >0.9783</td>\n",
       "      <td id=\"T_ca9f1_row10_col1\" class=\"data row10 col1\" >0.9794</td>\n",
       "      <td id=\"T_ca9f1_row10_col2\" class=\"data row10 col2\" >0.8672</td>\n",
       "      <td id=\"T_ca9f1_row10_col3\" class=\"data row10 col3\" >0.9820</td>\n",
       "      <td id=\"T_ca9f1_row10_col4\" class=\"data row10 col4\" >0.9196</td>\n",
       "      <td id=\"T_ca9f1_row10_col5\" class=\"data row10 col5\" >0.9071</td>\n",
       "      <td id=\"T_ca9f1_row10_col6\" class=\"data row10 col6\" >0.9104</td>\n",
       "      <td id=\"T_ca9f1_row10_col7\" class=\"data row10 col7\" >0.9531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca9f1_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_ca9f1_row11_col0\" class=\"data row11 col0\" >0.0111</td>\n",
       "      <td id=\"T_ca9f1_row11_col1\" class=\"data row11 col1\" >0.0177</td>\n",
       "      <td id=\"T_ca9f1_row11_col2\" class=\"data row11 col2\" >0.0613</td>\n",
       "      <td id=\"T_ca9f1_row11_col3\" class=\"data row11 col3\" >0.0415</td>\n",
       "      <td id=\"T_ca9f1_row11_col4\" class=\"data row11 col4\" >0.0405</td>\n",
       "      <td id=\"T_ca9f1_row11_col5\" class=\"data row11 col5\" >0.0469</td>\n",
       "      <td id=\"T_ca9f1_row11_col6\" class=\"data row11 col6\" >0.0453</td>\n",
       "      <td id=\"T_ca9f1_row11_col7\" class=\"data row11 col7\" >0.0324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d12ab7940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tops= compare_models(n_select = 2)\n",
    "blender = blend_models(tops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning with scikit-optimize on voting model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyCaret integrates seamlessly with many different libraries for hyperparameter tuning. This gives you access to many different types of search algorithms including random, bayesian, optuna, TPE, and a few others. All of this just by changing a parameter. By default, PyCaret using RandomGridSearch from the sklearn and you can change that by using search_library and search_algorithm parameter in the tune_model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_76c56_row10_col0, #T_76c56_row10_col1, #T_76c56_row10_col2, #T_76c56_row10_col3, #T_76c56_row10_col4, #T_76c56_row10_col5, #T_76c56_row10_col6, #T_76c56_row10_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_76c56\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_76c56_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_76c56_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_76c56_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_76c56_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_76c56_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_76c56_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_76c56_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_76c56_level0_col7\" class=\"col_heading level0 col7\" >APC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_76c56_row0_col0\" class=\"data row0 col0\" >0.9618</td>\n",
       "      <td id=\"T_76c56_row0_col1\" class=\"data row0 col1\" >0.9870</td>\n",
       "      <td id=\"T_76c56_row0_col2\" class=\"data row0 col2\" >0.7391</td>\n",
       "      <td id=\"T_76c56_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_76c56_row0_col4\" class=\"data row0 col4\" >0.8500</td>\n",
       "      <td id=\"T_76c56_row0_col5\" class=\"data row0 col5\" >0.8287</td>\n",
       "      <td id=\"T_76c56_row0_col6\" class=\"data row0 col6\" >0.8411</td>\n",
       "      <td id=\"T_76c56_row0_col7\" class=\"data row0 col7\" >0.9562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_76c56_row1_col0\" class=\"data row1 col0\" >0.9554</td>\n",
       "      <td id=\"T_76c56_row1_col1\" class=\"data row1 col1\" >0.9409</td>\n",
       "      <td id=\"T_76c56_row1_col2\" class=\"data row1 col2\" >0.8261</td>\n",
       "      <td id=\"T_76c56_row1_col3\" class=\"data row1 col3\" >0.8636</td>\n",
       "      <td id=\"T_76c56_row1_col4\" class=\"data row1 col4\" >0.8444</td>\n",
       "      <td id=\"T_76c56_row1_col5\" class=\"data row1 col5\" >0.8184</td>\n",
       "      <td id=\"T_76c56_row1_col6\" class=\"data row1 col6\" >0.8187</td>\n",
       "      <td id=\"T_76c56_row1_col7\" class=\"data row1 col7\" >0.8967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_76c56_row2_col0\" class=\"data row2 col0\" >0.9873</td>\n",
       "      <td id=\"T_76c56_row2_col1\" class=\"data row2 col1\" >0.9997</td>\n",
       "      <td id=\"T_76c56_row2_col2\" class=\"data row2 col2\" >0.9565</td>\n",
       "      <td id=\"T_76c56_row2_col3\" class=\"data row2 col3\" >0.9565</td>\n",
       "      <td id=\"T_76c56_row2_col4\" class=\"data row2 col4\" >0.9565</td>\n",
       "      <td id=\"T_76c56_row2_col5\" class=\"data row2 col5\" >0.9491</td>\n",
       "      <td id=\"T_76c56_row2_col6\" class=\"data row2 col6\" >0.9491</td>\n",
       "      <td id=\"T_76c56_row2_col7\" class=\"data row2 col7\" >0.9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_76c56_row3_col0\" class=\"data row3 col0\" >0.9682</td>\n",
       "      <td id=\"T_76c56_row3_col1\" class=\"data row3 col1\" >0.9640</td>\n",
       "      <td id=\"T_76c56_row3_col2\" class=\"data row3 col2\" >0.7826</td>\n",
       "      <td id=\"T_76c56_row3_col3\" class=\"data row3 col3\" >1.0000</td>\n",
       "      <td id=\"T_76c56_row3_col4\" class=\"data row3 col4\" >0.8780</td>\n",
       "      <td id=\"T_76c56_row3_col5\" class=\"data row3 col5\" >0.8600</td>\n",
       "      <td id=\"T_76c56_row3_col6\" class=\"data row3 col6\" >0.8686</td>\n",
       "      <td id=\"T_76c56_row3_col7\" class=\"data row3 col7\" >0.9072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_76c56_row4_col0\" class=\"data row4 col0\" >0.9809</td>\n",
       "      <td id=\"T_76c56_row4_col1\" class=\"data row4 col1\" >0.9789</td>\n",
       "      <td id=\"T_76c56_row4_col2\" class=\"data row4 col2\" >0.8696</td>\n",
       "      <td id=\"T_76c56_row4_col3\" class=\"data row4 col3\" >1.0000</td>\n",
       "      <td id=\"T_76c56_row4_col4\" class=\"data row4 col4\" >0.9302</td>\n",
       "      <td id=\"T_76c56_row4_col5\" class=\"data row4 col5\" >0.9192</td>\n",
       "      <td id=\"T_76c56_row4_col6\" class=\"data row4 col6\" >0.9222</td>\n",
       "      <td id=\"T_76c56_row4_col7\" class=\"data row4 col7\" >0.9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_76c56_row5_col0\" class=\"data row5 col0\" >0.9872</td>\n",
       "      <td id=\"T_76c56_row5_col1\" class=\"data row5 col1\" >0.9854</td>\n",
       "      <td id=\"T_76c56_row5_col2\" class=\"data row5 col2\" >0.9091</td>\n",
       "      <td id=\"T_76c56_row5_col3\" class=\"data row5 col3\" >1.0000</td>\n",
       "      <td id=\"T_76c56_row5_col4\" class=\"data row5 col4\" >0.9524</td>\n",
       "      <td id=\"T_76c56_row5_col5\" class=\"data row5 col5\" >0.9450</td>\n",
       "      <td id=\"T_76c56_row5_col6\" class=\"data row5 col6\" >0.9464</td>\n",
       "      <td id=\"T_76c56_row5_col7\" class=\"data row5 col7\" >0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_76c56_row6_col0\" class=\"data row6 col0\" >0.9808</td>\n",
       "      <td id=\"T_76c56_row6_col1\" class=\"data row6 col1\" >0.9810</td>\n",
       "      <td id=\"T_76c56_row6_col2\" class=\"data row6 col2\" >0.8636</td>\n",
       "      <td id=\"T_76c56_row6_col3\" class=\"data row6 col3\" >1.0000</td>\n",
       "      <td id=\"T_76c56_row6_col4\" class=\"data row6 col4\" >0.9268</td>\n",
       "      <td id=\"T_76c56_row6_col5\" class=\"data row6 col5\" >0.9158</td>\n",
       "      <td id=\"T_76c56_row6_col6\" class=\"data row6 col6\" >0.9191</td>\n",
       "      <td id=\"T_76c56_row6_col7\" class=\"data row6 col7\" >0.9461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_76c56_row7_col0\" class=\"data row7 col0\" >0.9936</td>\n",
       "      <td id=\"T_76c56_row7_col1\" class=\"data row7 col1\" >0.9976</td>\n",
       "      <td id=\"T_76c56_row7_col2\" class=\"data row7 col2\" >0.9545</td>\n",
       "      <td id=\"T_76c56_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_76c56_row7_col4\" class=\"data row7 col4\" >0.9767</td>\n",
       "      <td id=\"T_76c56_row7_col5\" class=\"data row7 col5\" >0.9730</td>\n",
       "      <td id=\"T_76c56_row7_col6\" class=\"data row7 col6\" >0.9734</td>\n",
       "      <td id=\"T_76c56_row7_col7\" class=\"data row7 col7\" >0.9890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_76c56_row8_col0\" class=\"data row8 col0\" >0.9679</td>\n",
       "      <td id=\"T_76c56_row8_col1\" class=\"data row8 col1\" >0.9617</td>\n",
       "      <td id=\"T_76c56_row8_col2\" class=\"data row8 col2\" >0.8182</td>\n",
       "      <td id=\"T_76c56_row8_col3\" class=\"data row8 col3\" >0.9474</td>\n",
       "      <td id=\"T_76c56_row8_col4\" class=\"data row8 col4\" >0.8780</td>\n",
       "      <td id=\"T_76c56_row8_col5\" class=\"data row8 col5\" >0.8597</td>\n",
       "      <td id=\"T_76c56_row8_col6\" class=\"data row8 col6\" >0.8628</td>\n",
       "      <td id=\"T_76c56_row8_col7\" class=\"data row8 col7\" >0.9384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_76c56_row9_col0\" class=\"data row9 col0\" >0.9872</td>\n",
       "      <td id=\"T_76c56_row9_col1\" class=\"data row9 col1\" >0.9976</td>\n",
       "      <td id=\"T_76c56_row9_col2\" class=\"data row9 col2\" >0.9091</td>\n",
       "      <td id=\"T_76c56_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_76c56_row9_col4\" class=\"data row9 col4\" >0.9524</td>\n",
       "      <td id=\"T_76c56_row9_col5\" class=\"data row9 col5\" >0.9450</td>\n",
       "      <td id=\"T_76c56_row9_col6\" class=\"data row9 col6\" >0.9464</td>\n",
       "      <td id=\"T_76c56_row9_col7\" class=\"data row9 col7\" >0.9873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_76c56_row10_col0\" class=\"data row10 col0\" >0.9770</td>\n",
       "      <td id=\"T_76c56_row10_col1\" class=\"data row10 col1\" >0.9794</td>\n",
       "      <td id=\"T_76c56_row10_col2\" class=\"data row10 col2\" >0.8628</td>\n",
       "      <td id=\"T_76c56_row10_col3\" class=\"data row10 col3\" >0.9768</td>\n",
       "      <td id=\"T_76c56_row10_col4\" class=\"data row10 col4\" >0.9146</td>\n",
       "      <td id=\"T_76c56_row10_col5\" class=\"data row10 col5\" >0.9014</td>\n",
       "      <td id=\"T_76c56_row10_col6\" class=\"data row10 col6\" >0.9048</td>\n",
       "      <td id=\"T_76c56_row10_col7\" class=\"data row10 col7\" >0.9544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_76c56_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_76c56_row11_col0\" class=\"data row11 col0\" >0.0121</td>\n",
       "      <td id=\"T_76c56_row11_col1\" class=\"data row11 col1\" >0.0179</td>\n",
       "      <td id=\"T_76c56_row11_col2\" class=\"data row11 col2\" >0.0683</td>\n",
       "      <td id=\"T_76c56_row11_col3\" class=\"data row11 col3\" >0.0423</td>\n",
       "      <td id=\"T_76c56_row11_col4\" class=\"data row11 col4\" >0.0454</td>\n",
       "      <td id=\"T_76c56_row11_col5\" class=\"data row11 col5\" >0.0523</td>\n",
       "      <td id=\"T_76c56_row11_col6\" class=\"data row11 col6\" >0.0502</td>\n",
       "      <td id=\"T_76c56_row11_col7\" class=\"data row11 col7\" >0.0320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d12c5b7c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_dt = tune_model(blender_weighted, search_library = 'scikit-optimize', optimize=\"APC\", n_iter = 50) # https://pycaret.readthedocs.io/en/stable/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ce47c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ce47c_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_ce47c_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_ce47c_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_ce47c_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_ce47c_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_ce47c_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_ce47c_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_ce47c_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_ce47c_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ce47c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ce47c_row0_col0\" class=\"data row0 col0\" >Voting Classifier</td>\n",
       "      <td id=\"T_ce47c_row0_col1\" class=\"data row0 col1\" >0.9755</td>\n",
       "      <td id=\"T_ce47c_row0_col2\" class=\"data row0 col2\" >0.9806</td>\n",
       "      <td id=\"T_ce47c_row0_col3\" class=\"data row0 col3\" >0.8772</td>\n",
       "      <td id=\"T_ce47c_row0_col4\" class=\"data row0 col4\" >0.9615</td>\n",
       "      <td id=\"T_ce47c_row0_col5\" class=\"data row0 col5\" >0.9174</td>\n",
       "      <td id=\"T_ce47c_row0_col6\" class=\"data row0 col6\" >0.9031</td>\n",
       "      <td id=\"T_ce47c_row0_col7\" class=\"data row0 col7\" >0.9044</td>\n",
       "      <td id=\"T_ce47c_row0_col8\" class=\"data row0 col8\" >0.9606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x19d129288b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = predict_model(tuned_dt, raw_score=True, data=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=False, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=['Time', 'V1', 'V2',\n",
       "                                                           'V3', 'V4', 'V5',\n",
       "                                                           'V6', 'V7', 'V8',\n",
       "                                                           'V9', 'V10', 'V11',\n",
       "                                                           'V12', 'V13', 'V14',\n",
       "                                                           'V15', 'V16', 'V17',\n",
       "                                                           'V18', 'V19', 'V20',\n",
       "                                                           'V21', 'V22', 'V23',\n",
       "                                                           'V24', 'V25', 'V26',\n",
       "                                                           'V27', 'V28',...\n",
       "                                                                       max_leaf_nodes=None,\n",
       "                                                                       max_samples=None,\n",
       "                                                                       min_impurity_decrease=0.0,\n",
       "                                                                       min_impurity_split=None,\n",
       "                                                                       min_samples_leaf=1,\n",
       "                                                                       min_samples_split=2,\n",
       "                                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                                       n_estimators=100,\n",
       "                                                                       n_jobs=-1,\n",
       "                                                                       oob_score=False,\n",
       "                                                                       random_state=8364,\n",
       "                                                                       verbose=0,\n",
       "                                                                       warm_start=False))],\n",
       "                                   flatten_transform=True, n_jobs=-1,\n",
       "                                   verbose=False, voting='soft',\n",
       "                                   weights=[1e-09, 1.0, 0.4152925166569753])]],\n",
       "          verbose=False),\n",
       " 'tuned_dt.pkl')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(tuned_dt, 'tuned_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefb543795a346b6865140a667313d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Hyperparameters', 'param…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(tuned_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(tuned_dt, plot = 'pr')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install fastapi\n",
    "# %pip install uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "API sucessfully created. This function only creates a POST API, it doesn't run it automatically.\n",
      "\n",
      "To run your API, please run this command --> !python fraud_voting_model_api.py\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "create_api(tuned_dt, 'fraud_voting_model_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      41991.000000\n",
       "V1           -4.566342\n",
       "V2            3.353451\n",
       "V3           -4.572028\n",
       "V4            3.616119\n",
       "V5           -2.493138\n",
       "V6           -1.090000\n",
       "V7           -5.551433\n",
       "V8            0.447783\n",
       "V9           -2.424414\n",
       "V10          -5.699922\n",
       "V11           3.586824\n",
       "V12          -6.636229\n",
       "V13          -1.128176\n",
       "V14          -7.245550\n",
       "V15           0.638326\n",
       "V16          -6.856810\n",
       "V17          -8.851879\n",
       "V18          -4.591883\n",
       "V19           0.936940\n",
       "V20          -0.249128\n",
       "V21           2.674466\n",
       "V22          -0.020880\n",
       "V23          -0.302447\n",
       "V24          -0.086396\n",
       "V25          -0.516060\n",
       "V26          -0.295102\n",
       "V27           0.195985\n",
       "V28           0.141115\n",
       "Amount        1.000000\n",
       "target        1.000000\n",
       "Name: 44556, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n",
      "Writing Dockerfile\n",
      "Dockerfile and requirements.txt successfully created.\n",
      "To build image you have to run --> !docker image build -f \"Dockerfile\" -t IMAGE_NAME:IMAGE_TAG .\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "create_docker('fraud_voting_model_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 sha256:752698380b6c52a095d1b1c921ffead9cacd4aaa74c6ff997fef4ad1760a5b4e\n",
      "#1 transferring dockerfile: 257B 0.1s done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [internal] load .dockerignore\n",
      "#2 sha256:b73c4a17d0600d238eee13d5e75cd3dd5369e77e6104083c1945587da491786a\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/library/python:3.8-slim\n",
      "#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065\n",
      "#3 ...\n",
      "\n",
      "#4 [auth] library/python:pull token for registry-1.docker.io\n",
      "#4 sha256:5cba492fb01746c3dc45d5cabca61d6fe9bcb472e3c686e7dee90534df5e90e7\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/library/python:3.8-slim\n",
      "#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065\n",
      "#3 DONE 3.8s\n",
      "\n",
      "#10 [1/5] FROM docker.io/library/python:3.8-slim@sha256:1222aecd5ea9214a0ca4761e21f9f36d119c55a5a3721cd06da58e7199e79f2e\n",
      "#10 sha256:7a2ab8c8bb7b2edf5e64b18c26918875d8baf851f9ffeb85421198067ec59878\n",
      "#10 DONE 0.0s\n",
      "\n",
      "#6 [internal] load build context\n",
      "#6 sha256:2f1b7d82adec4770b979b03e88d39e736bee144a9752863b775f445889ff165b\n",
      "#6 transferring context: 181.34kB 1.1s\n",
      "#6 transferring context: 35.61MB 6.1s\n",
      "#6 transferring context: 47.59MB 10.7s done\n",
      "#6 DONE 11.2s\n",
      "\n",
      "#5 [2/5] WORKDIR /app\n",
      "#5 sha256:aebedd72848d369b2d6f7156ecd6a5f1925b20a6ad4c08f63147e682174fb3d3\n",
      "#5 CACHED\n",
      "\n",
      "#7 [3/5] ADD . /app\n",
      "#7 sha256:b8bdb1c5e4c1e0fa17d824a2e73cff9973f779863a4b2be8903f3c3336365b63\n",
      "#7 DONE 42.3s\n",
      "\n",
      "#8 [4/5] RUN apt-get update && apt-get install -y libgomp1\n",
      "#8 sha256:1104c2e076c5974abc331cd34ef76d27353da32da31a03b968b6e72683546009\n",
      "#8 2.542 Get:1 http://deb.debian.org/debian bullseye InRelease [116 kB]\n",
      "#8 3.062 Get:2 http://deb.debian.org/debian-security bullseye-security InRelease [48.4 kB]\n",
      "#8 3.498 Get:3 http://deb.debian.org/debian bullseye-updates InRelease [44.1 kB]\n",
      "#8 3.932 Get:4 http://deb.debian.org/debian bullseye/main amd64 Packages [8183 kB]\n",
      "#8 11.45 Get:5 http://deb.debian.org/debian-security bullseye-security/main amd64 Packages [236 kB]\n",
      "#8 12.16 Get:6 http://deb.debian.org/debian bullseye-updates/main amd64 Packages [14.6 kB]\n",
      "#8 13.24 Fetched 8642 kB in 11s (756 kB/s)\n",
      "#8 13.24 Reading package lists...\n",
      "#8 14.52 Reading package lists...\n",
      "#8 15.50 Building dependency tree...\n",
      "#8 15.76 Reading state information...\n",
      "#8 16.16 The following NEW packages will be installed:\n",
      "#8 16.17   libgomp1\n",
      "#8 16.51 0 upgraded, 1 newly installed, 0 to remove and 1 not upgraded.\n",
      "#8 16.51 Need to get 99.9 kB of archives.\n",
      "#8 16.51 After this operation, 285 kB of additional disk space will be used.\n",
      "#8 16.51 Get:1 http://deb.debian.org/debian bullseye/main amd64 libgomp1 amd64 10.2.1-6 [99.9 kB]\n",
      "#8 17.01 debconf: delaying package configuration, since apt-utils is not installed\n",
      "#8 17.06 Fetched 99.9 kB in 1s (190 kB/s)\n",
      "#8 17.11 Selecting previously unselected package libgomp1:amd64.\n",
      "#8 17.11 (Reading database ... \n",
      "(Reading database ... 5%\n",
      "(Reading database ... 10%\n",
      "(Reading database ... 15%\n",
      "(Reading database ... 20%\n",
      "(Reading database ... 25%\n",
      "(Reading database ... 30%\n",
      "(Reading database ... 35%\n",
      "(Reading database ... 40%\n",
      "(Reading database ... 45%\n",
      "(Reading database ... 50%\n",
      "(Reading database ... 55%\n",
      "(Reading database ... 60%\n",
      "(Reading database ... 65%\n",
      "(Reading database ... 70%\n",
      "(Reading database ... 75%\n",
      "(Reading database ... 80%\n",
      "(Reading database ... 85%\n",
      "(Reading database ... 90%\n",
      "(Reading database ... 95%\n",
      "(Reading database ... 100%\n",
      "(Reading database ... 7031 files and directories currently installed.)\n",
      "#8 17.14 Preparing to unpack .../libgomp1_10.2.1-6_amd64.deb ...\n",
      "#8 17.15 Unpacking libgomp1:amd64 (10.2.1-6) ...\n",
      "#8 17.23 Setting up libgomp1:amd64 (10.2.1-6) ...\n",
      "#8 17.26 Processing triggers for libc-bin (2.31-13+deb11u5) ...\n",
      "#8 DONE 17.4s\n",
      "\n",
      "#9 [5/5] RUN pip install -r requirements.txt\n",
      "#9 sha256:cddc7896e46b2575b80119dd90a90e7127de9bf865861b4fb01f2c5df44a44d2\n",
      "#9 6.046 Collecting pycaret\n",
      "#9 6.342   Downloading pycaret-3.0.0-py3-none-any.whl (481 kB)\n",
      "#9 6.778      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 481.8/481.8 KB 1.1 MB/s eta 0:00:00\n",
      "#9 7.396 Collecting fastapi\n",
      "#9 7.447   Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
      "#9 7.508      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.1/57.1 KB 1.0 MB/s eta 0:00:00\n",
      "#9 7.975 Collecting uvicorn\n",
      "#9 8.023   Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "#9 8.101      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.8/57.8 KB 783.1 kB/s eta 0:00:00\n",
      "#9 8.859 Collecting lightgbm>=3.0.0\n",
      "#9 8.912   Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "#9 10.63      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 1.2 MB/s eta 0:00:00\n",
      "#9 11.66 Collecting numba>=0.55.0\n",
      "#9 11.71   Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "#9 14.73      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.5/3.5 MB 1.2 MB/s eta 0:00:00\n",
      "#9 14.86 Collecting category-encoders>=2.4.0\n",
      "#9 14.91   Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
      "#9 15.01      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.2/81.2 KB 903.2 kB/s eta 0:00:00\n",
      "#9 15.52 Collecting markupsafe>=2.0.1\n",
      "#9 15.57   Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "#9 15.73 Collecting schemdraw>=0.14\n",
      "#9 15.77   Downloading schemdraw-0.16-py3-none-any.whl (105 kB)\n",
      "#9 15.88      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 105.8/105.8 KB 1.1 MB/s eta 0:00:00\n",
      "#9 16.12 Collecting requests>=2.27.1\n",
      "#9 16.17   Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "#9 16.24      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 KB 944.5 kB/s eta 0:00:00\n",
      "#9 16.35 Collecting pyod>=1.0.8\n",
      "#9 16.41   Downloading pyod-1.0.9.tar.gz (149 kB)\n",
      "#9 16.56      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.0/150.0 KB 1.0 MB/s eta 0:00:00\n",
      "#9 16.68   Preparing metadata (setup.py): started\n",
      "#9 17.65   Preparing metadata (setup.py): finished with status 'done'\n",
      "#9 18.30 Collecting plotly>=5.0.0\n",
      "#9 18.36   Downloading plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)\n",
      "#9 31.51      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.2/15.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 33.10 Collecting importlib-metadata>=4.12.0\n",
      "#9 33.18   Downloading importlib_metadata-6.1.0-py3-none-any.whl (21 kB)\n",
      "#9 33.84 Collecting plotly-resampler>=0.8.3.1\n",
      "#9 33.90   Downloading plotly_resampler-0.8.3.2.tar.gz (46 kB)\n",
      "#9 33.96      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.4/46.4 KB 661.9 kB/s eta 0:00:00\n",
      "#9 34.52   Installing build dependencies: started\n",
      "#9 69.44   Installing build dependencies: finished with status 'done'\n",
      "#9 69.45   Getting requirements to build wheel: started\n",
      "#9 69.62   Getting requirements to build wheel: finished with status 'done'\n",
      "#9 69.63   Preparing metadata (pyproject.toml): started\n",
      "#9 70.27   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "#9 70.62 Collecting wurlitzer\n",
      "#9 70.67   Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
      "#9 70.81 Collecting nbformat>=4.2.0\n",
      "#9 70.86   Downloading nbformat-5.8.0-py3-none-any.whl (77 kB)\n",
      "#9 70.93      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.4/77.4 KB 1.0 MB/s eta 0:00:00\n",
      "#9 71.48 Collecting xxhash\n",
      "#9 71.53   Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "#9 71.74      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 213.0/213.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 72.09 Collecting ipywidgets>=7.6.5\n",
      "#9 72.14   Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
      "#9 72.27      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.3/138.3 KB 1.1 MB/s eta 0:00:00\n",
      "#9 72.68 Collecting cloudpickle\n",
      "#9 72.73   Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "#9 72.98 Collecting sktime>=0.16.1\n",
      "#9 73.04   Downloading sktime-0.16.1-py3-none-any.whl (16.0 MB)\n",
      "#9 86.82      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.0/16.0 MB 1.2 MB/s eta 0:00:00\n",
      "#9 87.35 Collecting tbats>=1.1.0\n",
      "#9 87.40   Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
      "#9 87.45      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.8/43.8 KB 1.0 MB/s eta 0:00:00\n",
      "#9 88.44 Collecting pandas<1.6.0,>=1.3.0\n",
      "#9 88.49   Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "#9 98.96      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 99.27 Collecting deprecation>=2.1.0\n",
      "#9 99.32   Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 99.70 Collecting ipython>=5.5.0\n",
      "#9 99.75   Downloading ipython-8.11.0-py3-none-any.whl (793 kB)\n",
      "#9 100.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 793.3/793.3 KB 1.2 MB/s eta 0:00:00\n",
      "#9 101.4 Collecting matplotlib>=3.3.0\n",
      "#9 101.5   Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "#9 109.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.2/9.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 109.8 Collecting imbalanced-learn>=0.8.1\n",
      "#9 109.9   Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "#9 110.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 226.0/226.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 110.3 Collecting jinja2>=1.2\n",
      "#9 110.3   Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "#9 110.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 KB 1.1 MB/s eta 0:00:00\n",
      "#9 111.8 Collecting numpy<1.25,>=1.21\n",
      "#9 111.8   Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "#9 126.7      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.3/17.3 MB 1.2 MB/s eta 0:00:00\n",
      "#9 127.5 Collecting psutil>=5.9.0\n",
      "#9 127.6   Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "#9 127.8      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 280.2/280.2 KB 1.1 MB/s eta 0:00:00\n",
      "#9 128.3 Collecting joblib>=1.2.0\n",
      "#9 128.4   Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "#9 128.6      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 KB 1.2 MB/s eta 0:00:00\n",
      "#9 128.8 Collecting kaleido>=0.2.1\n",
      "#9 128.8   Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "#9 197.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.9/79.9 MB 1.1 MB/s eta 0:00:00\n",
      "#9 197.7 Collecting yellowbrick>=1.4\n",
      "#9 197.8   Downloading yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
      "#9 198.0      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 282.6/282.6 KB 1.1 MB/s eta 0:00:00\n",
      "#9 198.7 Collecting scikit-learn>=1.0\n",
      "#9 198.8   Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "#9 207.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.8/9.8 MB 1.2 MB/s eta 0:00:00\n",
      "#9 207.9 Collecting tqdm>=4.62.0\n",
      "#9 207.9   Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "#9 208.0      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 KB 956.6 kB/s eta 0:00:00\n",
      "#9 208.6 Collecting pmdarima!=1.8.1,<3.0.0,>=1.8.0\n",
      "#9 208.7   Downloading pmdarima-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "#9 210.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 1.1 MB/s eta 0:00:00\n",
      "#9 210.7 Collecting scikit-plot>=0.3.7\n",
      "#9 210.7   Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "#9 211.6 Collecting scipy<2.0.0\n",
      "#9 211.7   Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "#9 244.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.5/34.5 MB 854.5 kB/s eta 0:00:00\n",
      "#9 244.8 Collecting statsmodels>=0.12.1\n",
      "#9 244.9   Downloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "#9 253.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 1.2 MB/s eta 0:00:00\n",
      "#9 255.4 Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
      "#9 255.5   Downloading pydantic-1.10.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "#9 258.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.2/3.2 MB 1.1 MB/s eta 0:00:00\n",
      "#9 258.9 Collecting starlette<0.27.0,>=0.26.1\n",
      "#9 259.0   Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "#9 259.0      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 66.9/66.9 KB 809.8 kB/s eta 0:00:00\n",
      "#9 259.4 Collecting click>=7.0\n",
      "#9 259.5   Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "#9 259.6      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 KB 1.1 MB/s eta 0:00:00\n",
      "#9 259.7 Collecting h11>=0.8\n",
      "#9 259.7   Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "#9 259.8      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 KB 879.5 kB/s eta 0:00:00\n",
      "#9 260.1 Collecting patsy>=0.5.1\n",
      "#9 260.1   Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "#9 260.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.8/233.8 KB 1.1 MB/s eta 0:00:00\n",
      "#9 260.6 Collecting packaging\n",
      "#9 260.7   Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "#9 260.8      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.7/42.7 KB 818.2 kB/s eta 0:00:00\n",
      "#9 261.0 Collecting threadpoolctl>=2.0.0\n",
      "#9 261.1   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "#9 261.4 Collecting zipp>=0.5\n",
      "#9 261.5   Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "#9 262.3 Collecting matplotlib-inline\n",
      "#9 262.3   Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "#9 262.8 Collecting stack-data\n",
      "#9 262.9   Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
      "#9 263.5 Collecting pygments>=2.4.0\n",
      "#9 263.5   Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "#9 264.5      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 1.2 MB/s eta 0:00:00\n",
      "#9 264.7 Collecting decorator\n",
      "#9 264.7   Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "#9 265.0 Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
      "#9 265.0   Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
      "#9 265.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 385.8/385.8 KB 1.1 MB/s eta 0:00:00\n",
      "#9 265.5 Collecting backcall\n",
      "#9 265.5   Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 265.9 Collecting traitlets>=5\n",
      "#9 265.9   Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
      "#9 266.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 117.4/117.4 KB 1.0 MB/s eta 0:00:00\n",
      "#9 266.1 Collecting pickleshare\n",
      "#9 266.2   Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "#9 266.3 Collecting pexpect>4.3\n",
      "#9 266.3   Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "#9 266.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.0/59.0 KB 885.2 kB/s eta 0:00:00\n",
      "#9 266.6 Collecting jedi>=0.16\n",
      "#9 266.6   Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "#9 268.0      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 1.1 MB/s eta 0:00:00\n",
      "#9 268.7 Collecting ipykernel>=4.5.1\n",
      "#9 268.7   Downloading ipykernel-6.22.0-py3-none-any.whl (149 kB)\n",
      "#9 268.8      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 150.0/150.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 269.0 Collecting jupyterlab-widgets~=3.0.7\n",
      "#9 269.0   Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
      "#9 269.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 198.2/198.2 KB 1.1 MB/s eta 0:00:00\n",
      "#9 269.5 Collecting widgetsnbextension~=4.0.7\n",
      "#9 269.5   Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
      "#9 271.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 1.2 MB/s eta 0:00:00\n",
      "#9 271.5 Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from lightgbm>=3.0.0->pycaret->-r requirements.txt (line 2)) (0.40.0)\n",
      "#9 271.8 Collecting importlib-resources>=3.2.0\n",
      "#9 271.9   Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "#9 272.0 Collecting python-dateutil>=2.7\n",
      "#9 272.1   Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "#9 272.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 KB 1.1 MB/s eta 0:00:00\n",
      "#9 272.6 Collecting kiwisolver>=1.0.1\n",
      "#9 272.7   Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "#9 273.7      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 274.1 Collecting contourpy>=1.0.1\n",
      "#9 274.1   Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "#9 274.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 300.0/300.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 274.7 Collecting pyparsing>=2.3.1\n",
      "#9 274.7   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "#9 274.8      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 KB 1.2 MB/s eta 0:00:00\n",
      "#9 274.9 Collecting cycler>=0.10\n",
      "#9 274.9   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "#9 275.3 Collecting fonttools>=4.22.0\n",
      "#9 275.3   Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "#9 276.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 1.2 MB/s eta 0:00:00\n",
      "#9 277.7 Collecting pillow>=6.2.0\n",
      "#9 277.7   Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "#9 280.6      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.4/3.4 MB 1.2 MB/s eta 0:00:00\n",
      "#9 280.8 Collecting fastjsonschema\n",
      "#9 280.8   Downloading fastjsonschema-2.16.3-py3-none-any.whl (23 kB)\n",
      "#9 281.0 Collecting jsonschema>=2.6\n",
      "#9 281.1   Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "#9 281.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.4/90.4 KB 989.8 kB/s eta 0:00:00\n",
      "#9 281.4 Collecting jupyter-core\n",
      "#9 281.4   Downloading jupyter_core-5.3.0-py3-none-any.whl (93 kB)\n",
      "#9 281.5      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.2/93.2 KB 905.4 kB/s eta 0:00:00\n",
      "#9 281.6 Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from numba>=0.55.0->pycaret->-r requirements.txt (line 2)) (57.5.0)\n",
      "#9 281.7 Collecting numpy<1.25,>=1.21\n",
      "#9 281.7   Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "#9 296.5      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 1.2 MB/s eta 0:00:00\n",
      "#9 297.7 Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "#9 297.7   Downloading llvmlite-0.39.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "#9 327.5      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 34.6/34.6 MB 1.2 MB/s eta 0:00:00\n",
      "#9 328.0 Collecting pytz>=2020.1\n",
      "#9 328.1   Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "#9 328.5      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 502.3/502.3 KB 1.1 MB/s eta 0:00:00\n",
      "#9 328.8 Collecting tenacity>=6.2.0\n",
      "#9 328.8   Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "#9 329.3 Collecting dash<3.0.0,>=2.2.0\n",
      "#9 329.3   Downloading dash-2.9.1-py3-none-any.whl (10.2 MB)\n",
      "#9 338.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.2/10.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 340.1 Collecting orjson<4.0.0,>=3.8.0\n",
      "#9 340.1   Downloading orjson-3.8.9-cp38-cp38-manylinux_2_28_x86_64.whl (143 kB)\n",
      "#9 340.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 143.9/143.9 KB 1.1 MB/s eta 0:00:00\n",
      "#9 340.3 Collecting trace-updater>=0.0.8\n",
      "#9 340.4   Downloading trace_updater-0.0.9-py3-none-any.whl (185 kB)\n",
      "#9 340.5      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 185.1/185.1 KB 1.1 MB/s eta 0:00:00\n",
      "#9 340.7 Collecting jupyter-dash>=0.4.2\n",
      "#9 340.8   Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
      "#9 341.1 Collecting urllib3\n",
      "#9 341.1   Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "#9 341.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.9/140.9 KB 1.0 MB/s eta 0:00:00\n",
      "#9 343.1 Collecting Cython!=0.29.18,!=0.29.31,>=0.29\n",
      "#9 343.2   Downloading Cython-0.29.33-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "#9 344.9      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.9/1.9 MB 1.2 MB/s eta 0:00:00\n",
      "#9 345.3 Collecting typing-extensions>=4.2.0\n",
      "#9 345.3   Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "#9 345.6 Collecting six\n",
      "#9 345.6   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 345.8 Collecting certifi>=2017.4.17\n",
      "#9 345.9   Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "#9 346.0      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 KB 1.2 MB/s eta 0:00:00\n",
      "#9 346.2 Collecting idna<4,>=2.5\n",
      "#9 346.2   Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "#9 346.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 KB 1.1 MB/s eta 0:00:00\n",
      "#9 347.8 Collecting charset-normalizer<4,>=2\n",
      "#9 347.8   Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
      "#9 348.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 195.9/195.9 KB 561.0 kB/s eta 0:00:00\n",
      "#9 349.9 Collecting deprecated>=1.2.13\n",
      "#9 349.9   Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "#9 350.3 Collecting anyio<5,>=3.4.0\n",
      "#9 350.3   Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "#9 350.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.6/80.6 KB 859.4 kB/s eta 0:00:00\n",
      "#9 351.1 Collecting sniffio>=1.1\n",
      "#9 351.2   Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "#9 351.9 Collecting Flask>=1.0.4\n",
      "#9 351.9   Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
      "#9 352.0      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.8/101.8 KB 1.0 MB/s eta 0:00:00\n",
      "#9 352.4 Collecting dash-html-components==2.0.0\n",
      "#9 352.4   Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "#9 352.9 Collecting dash-core-components==2.0.0\n",
      "#9 352.9   Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "#9 353.3 Collecting dash-table==5.0.0\n",
      "#9 353.3   Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "#9 354.0 Collecting wrapt<2,>=1.10\n",
      "#9 354.0   Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "#9 354.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.5/81.5 KB 1.0 MB/s eta 0:00:00\n",
      "#9 354.7 Collecting jupyter-client>=6.1.12\n",
      "#9 354.8   Downloading jupyter_client-8.1.0-py3-none-any.whl (102 kB)\n",
      "#9 354.9      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.9/102.9 KB 1.2 MB/s eta 0:00:00\n",
      "#9 355.4 Collecting tornado>=6.1\n",
      "#9 355.4   Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "#9 355.8      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 424.0/424.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 358.3 Collecting pyzmq>=20\n",
      "#9 358.4   Downloading pyzmq-25.0.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "#9 359.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 1.1 MB/s eta 0:00:00\n",
      "#9 359.7 Collecting comm>=0.1.1\n",
      "#9 359.8   Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n",
      "#9 360.3 Collecting nest-asyncio\n",
      "#9 360.3   Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "#9 361.4 Collecting debugpy>=1.6.5\n",
      "#9 361.5   Downloading debugpy-1.6.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "#9 364.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 1.2 MB/s eta 0:00:00\n",
      "#9 364.7 Collecting parso<0.9.0,>=0.8.0\n",
      "#9 364.8   Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "#9 364.9      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100.8/100.8 KB 1.0 MB/s eta 0:00:00\n",
      "#9 365.1 Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "#9 365.2   Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "#9 365.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 KB 939.1 kB/s eta 0:00:00\n",
      "#9 365.4 Collecting attrs>=17.4.0\n",
      "#9 365.5   Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "#9 365.5      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 60.0/60.0 KB 970.1 kB/s eta 0:00:00\n",
      "#9 365.9 Collecting pkgutil-resolve-name>=1.3.10\n",
      "#9 365.9   Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "#9 366.3 Collecting platformdirs>=2.5\n",
      "#9 366.4   Downloading platformdirs-3.2.0-py3-none-any.whl (14 kB)\n",
      "#9 366.7 Collecting ansi2html\n",
      "#9 366.8   Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
      "#9 367.1 Collecting retrying\n",
      "#9 367.2   Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "#9 367.6 Collecting ptyprocess>=0.5\n",
      "#9 367.6   Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "#9 367.8 Collecting wcwidth\n",
      "#9 367.9   Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
      "#9 369.0 Collecting asttokens>=2.1.0\n",
      "#9 369.1   Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
      "#9 369.5 Collecting pure-eval\n",
      "#9 369.5   Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "#9 369.9 Collecting executing>=1.2.0\n",
      "#9 370.0   Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "#9 370.5 Collecting Werkzeug>=2.2.2\n",
      "#9 370.6   Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "#9 370.8      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.6/233.6 KB 1.1 MB/s eta 0:00:00\n",
      "#9 371.2 Collecting itsdangerous>=2.0\n",
      "#9 371.2   Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "#9 372.8 Building wheels for collected packages: plotly-resampler, pyod\n",
      "#9 372.8   Building wheel for plotly-resampler (pyproject.toml): started\n",
      "#9 374.7   Building wheel for plotly-resampler (pyproject.toml): finished with status 'done'\n",
      "#9 374.7   Created wheel for plotly-resampler: filename=plotly_resampler-0.8.3.2-cp38-cp38-manylinux_2_31_x86_64.whl size=47922 sha256=54ef491f129a6442f131d7866bd942d398dad699f3aea33107d18ffa70d099a0\n",
      "#9 374.7   Stored in directory: /root/.cache/pip/wheels/63/17/b1/4bc002808e0370594fa673f71ecba27516bed8a83a334170e8\n",
      "#9 374.7   Building wheel for pyod (setup.py): started\n",
      "#9 376.0   Building wheel for pyod (setup.py): finished with status 'done'\n",
      "#9 376.0   Created wheel for pyod: filename=pyod-1.0.9-py3-none-any.whl size=184113 sha256=f7218342da5b310b7737c0e47bf4a1cf8c7d1b6bf7a481af8e25053b80efa59a\n",
      "#9 376.0   Stored in directory: /root/.cache/pip/wheels/1a/ec/04/08882538e197056f24532d6b7a00fd18e9c34d7c44faf3cd0c\n",
      "#9 376.0 Successfully built plotly-resampler pyod\n",
      "#9 379.5 Installing collected packages: wcwidth, trace-updater, pytz, pure-eval, ptyprocess, pickleshare, kaleido, fastjsonschema, executing, dash-table, dash-html-components, dash-core-components, backcall, zipp, xxhash, wurlitzer, wrapt, widgetsnbextension, urllib3, typing-extensions, traitlets, tqdm, tornado, threadpoolctl, tenacity, sniffio, six, schemdraw, pyzmq, pyrsistent, pyparsing, pygments, psutil, prompt-toolkit, platformdirs, pkgutil-resolve-name, pillow, pexpect, parso, packaging, orjson, numpy, nest-asyncio, markupsafe, llvmlite, kiwisolver, jupyterlab-widgets, joblib, itsdangerous, idna, h11, fonttools, decorator, debugpy, Cython, cycler, cloudpickle, click, charset-normalizer, certifi, attrs, ansi2html, Werkzeug, uvicorn, scipy, retrying, requests, python-dateutil, pydantic, plotly, patsy, matplotlib-inline, jupyter-core, jinja2, jedi, importlib-resources, importlib-metadata, deprecation, deprecated, contourpy, comm, asttokens, anyio, starlette, stack-data, scikit-learn, pandas, numba, matplotlib, jupyter-client, jsonschema, Flask, yellowbrick, statsmodels, sktime, scikit-plot, pyod, nbformat, lightgbm, ipython, imbalanced-learn, fastapi, dash, pmdarima, ipykernel, category-encoders, tbats, jupyter-dash, ipywidgets, plotly-resampler, pycaret\n",
      "#9 474.6 Successfully installed Cython-0.29.33 Flask-2.2.3 Werkzeug-2.2.3 ansi2html-1.8.0 anyio-3.6.2 asttokens-2.2.1 attrs-22.2.0 backcall-0.2.0 category-encoders-2.6.0 certifi-2022.12.7 charset-normalizer-3.1.0 click-8.1.3 cloudpickle-2.2.1 comm-0.1.3 contourpy-1.0.7 cycler-0.11.0 dash-2.9.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 debugpy-1.6.6 decorator-5.1.1 deprecated-1.2.13 deprecation-2.1.0 executing-1.2.0 fastapi-0.95.0 fastjsonschema-2.16.3 fonttools-4.39.3 h11-0.14.0 idna-3.4 imbalanced-learn-0.10.1 importlib-metadata-6.1.0 importlib-resources-5.12.0 ipykernel-6.22.0 ipython-8.11.0 ipywidgets-8.0.6 itsdangerous-2.1.2 jedi-0.18.2 jinja2-3.1.2 joblib-1.2.0 jsonschema-4.17.3 jupyter-client-8.1.0 jupyter-core-5.3.0 jupyter-dash-0.4.2 jupyterlab-widgets-3.0.7 kaleido-0.2.1 kiwisolver-1.4.4 lightgbm-3.3.5 llvmlite-0.39.1 markupsafe-2.1.2 matplotlib-3.7.1 matplotlib-inline-0.1.6 nbformat-5.8.0 nest-asyncio-1.5.6 numba-0.56.4 numpy-1.23.5 orjson-3.8.9 packaging-23.0 pandas-1.5.3 parso-0.8.3 patsy-0.5.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.4.0 pkgutil-resolve-name-1.3.10 platformdirs-3.2.0 plotly-5.13.1 plotly-resampler-0.8.3.2 pmdarima-2.0.3 prompt-toolkit-3.0.38 psutil-5.9.4 ptyprocess-0.7.0 pure-eval-0.2.2 pycaret-3.0.0 pydantic-1.10.7 pygments-2.14.0 pyod-1.0.9 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 pytz-2023.3 pyzmq-25.0.2 requests-2.28.2 retrying-1.3.4 schemdraw-0.16 scikit-learn-1.2.2 scikit-plot-0.3.7 scipy-1.10.1 six-1.16.0 sktime-0.16.1 sniffio-1.3.0 stack-data-0.6.2 starlette-0.26.1 statsmodels-0.13.5 tbats-1.1.2 tenacity-8.2.2 threadpoolctl-3.1.0 tornado-6.2 tqdm-4.65.0 trace-updater-0.0.9 traitlets-5.9.0 typing-extensions-4.5.0 urllib3-1.26.15 uvicorn-0.21.1 wcwidth-0.2.6 widgetsnbextension-4.0.7 wrapt-1.15.0 wurlitzer-3.0.3 xxhash-3.2.0 yellowbrick-1.5 zipp-3.15.0\n",
      "#9 474.6 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#9 474.6 WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "#9 474.6 You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "#9 DONE 476.6s\n",
      "\n",
      "#11 exporting to image\n",
      "#11 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00\n",
      "#11 exporting layers\n",
      "#11 exporting layers 23.0s done\n",
      "#11 writing image sha256:a36def49a37e46ce98b3373d9166f9067a20df8f3481e34e3c85591e00cc5182 done\n",
      "#11 naming to docker.io/library/fraud_voting_model_api:latest 0.0s done\n",
      "#11 DONE 23.1s\n"
     ]
    }
   ],
   "source": [
    "# !docker image build -f Dockerfile -t fraud_voting_model_api:latest .\n",
    "!docker image build -f \"Dockerfile\" -t fraud_voting_model_api:latest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140b98eb6e96c9c9bdbd3e83cb4dd6488d32afa0e1f4aba5d6f82510098f9b7\n"
     ]
    }
   ],
   "source": [
    "!docker run -d -p 8000:8000 --name fraud_voting_model_api fraud_voting_model_api:latest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
