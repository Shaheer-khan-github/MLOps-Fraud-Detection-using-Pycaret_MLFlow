{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.classification import *\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.utils import shuffle\n",
    "from model_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Optuna and Scikit optmize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Install Optuna and Scikit-Optimize if not installed already'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Install Optuna and Scikit-Optimize if not installed already'''\n",
    "# %pip install optuna\n",
    "# %pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = get_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e11dc th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e11dc_row0_col0, #T_e11dc_row0_col1, #T_e11dc_row0_col3, #T_e11dc_row0_col5, #T_e11dc_row0_col6, #T_e11dc_row0_col7, #T_e11dc_row1_col0, #T_e11dc_row1_col1, #T_e11dc_row1_col2, #T_e11dc_row1_col3, #T_e11dc_row1_col4, #T_e11dc_row1_col5, #T_e11dc_row1_col6, #T_e11dc_row1_col7, #T_e11dc_row1_col8, #T_e11dc_row2_col0, #T_e11dc_row2_col2, #T_e11dc_row2_col3, #T_e11dc_row2_col4, #T_e11dc_row2_col8, #T_e11dc_row3_col0, #T_e11dc_row3_col1, #T_e11dc_row3_col2, #T_e11dc_row3_col3, #T_e11dc_row3_col4, #T_e11dc_row3_col5, #T_e11dc_row3_col6, #T_e11dc_row3_col7, #T_e11dc_row3_col8, #T_e11dc_row4_col0, #T_e11dc_row4_col1, #T_e11dc_row4_col2, #T_e11dc_row4_col4, #T_e11dc_row4_col5, #T_e11dc_row4_col6, #T_e11dc_row4_col7, #T_e11dc_row4_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_e11dc_row0_col2, #T_e11dc_row0_col4, #T_e11dc_row0_col8, #T_e11dc_row2_col1, #T_e11dc_row2_col5, #T_e11dc_row2_col6, #T_e11dc_row2_col7, #T_e11dc_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_e11dc_row0_col9, #T_e11dc_row1_col9, #T_e11dc_row2_col9, #T_e11dc_row3_col9 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_e11dc_row4_col9 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e11dc\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e11dc_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e11dc_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_e11dc_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_e11dc_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_e11dc_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_e11dc_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_e11dc_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_e11dc_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_e11dc_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "      <th id=\"T_e11dc_level0_col9\" class=\"col_heading level0 col9\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e11dc_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_e11dc_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_e11dc_row0_col1\" class=\"data row0 col1\" >0.9763</td>\n",
       "      <td id=\"T_e11dc_row0_col2\" class=\"data row0 col2\" >0.9836</td>\n",
       "      <td id=\"T_e11dc_row0_col3\" class=\"data row0 col3\" >0.8733</td>\n",
       "      <td id=\"T_e11dc_row0_col4\" class=\"data row0 col4\" >0.9597</td>\n",
       "      <td id=\"T_e11dc_row0_col5\" class=\"data row0 col5\" >0.9122</td>\n",
       "      <td id=\"T_e11dc_row0_col6\" class=\"data row0 col6\" >0.8986</td>\n",
       "      <td id=\"T_e11dc_row0_col7\" class=\"data row0 col7\" >0.9014</td>\n",
       "      <td id=\"T_e11dc_row0_col8\" class=\"data row0 col8\" >0.9547</td>\n",
       "      <td id=\"T_e11dc_row0_col9\" class=\"data row0 col9\" >0.2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e11dc_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_e11dc_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_e11dc_row1_col1\" class=\"data row1 col1\" >0.9712</td>\n",
       "      <td id=\"T_e11dc_row1_col2\" class=\"data row1 col2\" >0.9809</td>\n",
       "      <td id=\"T_e11dc_row1_col3\" class=\"data row1 col3\" >0.8779</td>\n",
       "      <td id=\"T_e11dc_row1_col4\" class=\"data row1 col4\" >0.9191</td>\n",
       "      <td id=\"T_e11dc_row1_col5\" class=\"data row1 col5\" >0.8963</td>\n",
       "      <td id=\"T_e11dc_row1_col6\" class=\"data row1 col6\" >0.8796</td>\n",
       "      <td id=\"T_e11dc_row1_col7\" class=\"data row1 col7\" >0.8810</td>\n",
       "      <td id=\"T_e11dc_row1_col8\" class=\"data row1 col8\" >0.9530</td>\n",
       "      <td id=\"T_e11dc_row1_col9\" class=\"data row1 col9\" >1.3890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e11dc_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_e11dc_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_e11dc_row2_col1\" class=\"data row2 col1\" >0.9764</td>\n",
       "      <td id=\"T_e11dc_row2_col2\" class=\"data row2 col2\" >0.9798</td>\n",
       "      <td id=\"T_e11dc_row2_col3\" class=\"data row2 col3\" >0.8872</td>\n",
       "      <td id=\"T_e11dc_row2_col4\" class=\"data row2 col4\" >0.9457</td>\n",
       "      <td id=\"T_e11dc_row2_col5\" class=\"data row2 col5\" >0.9139</td>\n",
       "      <td id=\"T_e11dc_row2_col6\" class=\"data row2 col6\" >0.9003</td>\n",
       "      <td id=\"T_e11dc_row2_col7\" class=\"data row2 col7\" >0.9019</td>\n",
       "      <td id=\"T_e11dc_row2_col8\" class=\"data row2 col8\" >0.9514</td>\n",
       "      <td id=\"T_e11dc_row2_col9\" class=\"data row2 col9\" >0.5670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e11dc_level0_row3\" class=\"row_heading level0 row3\" >gbc</th>\n",
       "      <td id=\"T_e11dc_row3_col0\" class=\"data row3 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_e11dc_row3_col1\" class=\"data row3 col1\" >0.9668</td>\n",
       "      <td id=\"T_e11dc_row3_col2\" class=\"data row3 col2\" >0.9778</td>\n",
       "      <td id=\"T_e11dc_row3_col3\" class=\"data row3 col3\" >0.8824</td>\n",
       "      <td id=\"T_e11dc_row3_col4\" class=\"data row3 col4\" >0.8884</td>\n",
       "      <td id=\"T_e11dc_row3_col5\" class=\"data row3 col5\" >0.8832</td>\n",
       "      <td id=\"T_e11dc_row3_col6\" class=\"data row3 col6\" >0.8639</td>\n",
       "      <td id=\"T_e11dc_row3_col7\" class=\"data row3 col7\" >0.8653</td>\n",
       "      <td id=\"T_e11dc_row3_col8\" class=\"data row3 col8\" >0.9500</td>\n",
       "      <td id=\"T_e11dc_row3_col9\" class=\"data row3 col9\" >1.7720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e11dc_level0_row4\" class=\"row_heading level0 row4\" >lr</th>\n",
       "      <td id=\"T_e11dc_row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_e11dc_row4_col1\" class=\"data row4 col1\" >0.9533</td>\n",
       "      <td id=\"T_e11dc_row4_col2\" class=\"data row4 col2\" >0.9747</td>\n",
       "      <td id=\"T_e11dc_row4_col3\" class=\"data row4 col3\" >0.9142</td>\n",
       "      <td id=\"T_e11dc_row4_col4\" class=\"data row4 col4\" >0.7941</td>\n",
       "      <td id=\"T_e11dc_row4_col5\" class=\"data row4 col5\" >0.8489</td>\n",
       "      <td id=\"T_e11dc_row4_col6\" class=\"data row4 col6\" >0.8216</td>\n",
       "      <td id=\"T_e11dc_row4_col7\" class=\"data row4 col7\" >0.8251</td>\n",
       "      <td id=\"T_e11dc_row4_col8\" class=\"data row4 col8\" >0.9450</td>\n",
       "      <td id=\"T_e11dc_row4_col9\" class=\"data row4 col9\" >0.0350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11928e34070>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clf1 = setup(data = df_train, \n",
    "             target = 'target',\n",
    "             numeric_features=df_train.columns[0:-1].to_list(),\n",
    "             silent=True,\n",
    "             log_experiment = True,\n",
    "             use_gpu=False,\n",
    "             experiment_name = 'selected_model',\n",
    "             fix_imbalance = True, \n",
    "             transformation = True, \n",
    "             polynomial_features = True,\n",
    "             feature_selection = True, feature_selection_threshold = 0.5,\n",
    "             remove_multicollinearity = True, multicollinearity_threshold = 0.6,\n",
    "            )\n",
    "add_metric('apc', 'APC', average_precision_score, target = 'pred_proba')\n",
    "best = compare_models(sort=\"APC\", \n",
    "                      include=[\"lightgbm\", \"et\", \"rf\", \"lr\", \"gbc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1,\n",
       " 120736    0\n",
       " 161891    0\n",
       " 156656    0\n",
       " 101018    0\n",
       " 38119     0\n",
       "          ..\n",
       " 11507     0\n",
       " 134119    0\n",
       " 98817     0\n",
       " 15852     0\n",
       " 170041    0\n",
       " Name: target, Length: 672, dtype: int64,\n",
       " {'acc': <pycaret.containers.metrics.classification.AccuracyMetricContainer at 0x119296be3d0>,\n",
       "  'auc': <pycaret.containers.metrics.classification.ROCAUCMetricContainer at 0x119296be400>,\n",
       "  'recall': <pycaret.containers.metrics.classification.RecallMetricContainer at 0x119296be490>,\n",
       "  'precision': <pycaret.containers.metrics.classification.PrecisionMetricContainer at 0x119296be5e0>,\n",
       "  'f1': <pycaret.containers.metrics.classification.F1MetricContainer at 0x119296be730>,\n",
       "  'kappa': <pycaret.containers.metrics.classification.KappaMetricContainer at 0x119296be880>,\n",
       "  'mcc': <pycaret.containers.metrics.classification.MCCMetricContainer at 0x119296be910>,\n",
       "  'apc': <pycaret.containers.metrics.classification.ClassificationMetricContainer at 0x1190f9698b0>},\n",
       " None,\n",
       " None,\n",
       "             Time        V1        V2        V3        V4        V5        V6  \\\n",
       " 138220   82547.0 -0.072469  0.182870  0.858739  3.172125 -0.365100  1.492411   \n",
       " 219598  141795.0 -2.208719 -0.668035 -0.461423 -0.308953  1.282194 -1.241089   \n",
       " 241429  151020.0  2.065196 -2.014240 -0.270485 -1.488031 -1.870384  0.121320   \n",
       " 144299   86012.0 -2.009109  0.193185  0.823146  0.498421  1.111732 -0.308950   \n",
       " 76929    56806.0  0.016828  2.400826 -4.220360  3.462217 -0.624142 -1.294303   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 46488    42808.0 -0.252029  0.719147  0.865137  0.228747  1.223430  1.264775   \n",
       " 88728    62264.0  0.337925 -1.573980  0.363131  0.626949 -1.301546 -0.315424   \n",
       " 178254  123550.0  2.249899 -0.507002 -2.527011 -1.046284  0.387458 -1.235181   \n",
       " 83440    59852.0 -1.799860  0.984038  2.140605  3.432020 -1.299208  1.391437   \n",
       " 214662  139767.0  0.467992  1.100118 -5.607145  2.204714 -0.578539 -0.174200   \n",
       " \n",
       "               V7        V8        V9  ...       V21       V22       V23  \\\n",
       " 138220  0.329592 -0.625508 -0.732202  ...  0.645181 -0.910310  0.123923   \n",
       " 219598  0.209025  0.585629 -0.061194  ...  0.038849 -0.569782  0.019844   \n",
       " 241429 -1.784255  0.120833 -0.439954  ... -0.118057 -0.078715  0.265937   \n",
       " 144299  0.877830 -0.523337  0.321440  ... -0.249736  0.509603  0.468865   \n",
       " 76929  -2.986028  0.751883 -1.606672  ...  0.285832 -0.771508 -0.265200   \n",
       " ...          ...       ...       ...  ...       ...       ...       ...   \n",
       " 46488   0.686275  0.125512 -0.038421  ... -0.140985 -0.151006 -0.452425   \n",
       " 88728   0.168679 -0.084803  0.579173  ...  0.242159 -0.132307 -0.310793   \n",
       " 178254  0.340354 -0.472276 -1.294944  ...  0.526978  1.513483 -0.203936   \n",
       " 83440  -0.933519  1.399936 -0.201363  ... -0.180183 -0.317036 -0.132857   \n",
       " 214662 -3.454201  1.102823 -1.065016  ...  0.983481  0.899876 -0.285103   \n",
       " \n",
       "              V24       V25       V26       V27       V28  Amount  target  \n",
       " 138220 -0.797330  0.843522  0.303166  0.112604  0.223590  241.69       0  \n",
       " 219598 -0.549747  0.158114 -0.079326  0.207143 -0.098502  127.48       0  \n",
       " 241429  0.425693 -0.552003 -0.270830  0.037184 -0.009668  116.00       0  \n",
       " 144299 -0.460245  0.370437 -0.391734 -0.966729 -0.905033    5.98       0  \n",
       " 76929  -0.873077  0.939776 -0.219085  0.874494  0.470434    1.00       1  \n",
       " ...          ...       ...       ...       ...       ...     ...     ...  \n",
       " 46488  -1.725310  0.354752 -0.300604 -0.244400 -0.235820    4.96       0  \n",
       " 88728   0.497702 -0.015247  0.977195 -0.124123  0.084371  444.50       0  \n",
       " 178254  0.860588  0.738657  0.244375 -0.106816 -0.095186   18.00       0  \n",
       " 83440   0.095067  0.083421  0.265569  0.097067 -0.082868   75.69       0  \n",
       " 214662 -1.929717  0.319869  0.170636  0.851798  0.372098  120.54       1  \n",
       " \n",
       " [2237 rows x 31 columns],\n",
       " False,\n",
       " {'parameter': 'Hyperparameters',\n",
       "  'auc': 'AUC',\n",
       "  'confusion_matrix': 'Confusion Matrix',\n",
       "  'threshold': 'Threshold',\n",
       "  'pr': 'Precision Recall',\n",
       "  'error': 'Prediction Error',\n",
       "  'class_report': 'Class Report',\n",
       "  'rfe': 'Feature Selection',\n",
       "  'learning': 'Learning Curve',\n",
       "  'manifold': 'Manifold Learning',\n",
       "  'calibration': 'Calibration Curve',\n",
       "  'vc': 'Validation Curve',\n",
       "  'dimension': 'Dimensions',\n",
       "  'feature': 'Feature Importance',\n",
       "  'feature_all': 'Feature Importance (All)',\n",
       "  'boundary': 'Decision Boundary',\n",
       "  'lift': 'Lift Chart',\n",
       "  'gain': 'Gain Chart',\n",
       "  'tree': 'Decision Tree',\n",
       "  'ks': 'KS Statistic Plot'},\n",
       " Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=False, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=['Time', 'V1', 'V2',\n",
       "                                                           'V3', 'V4', 'V5',\n",
       "                                                           'V6', 'V7', 'V8',\n",
       "                                                           'V9', 'V10', 'V11',\n",
       "                                                           'V12', 'V13', 'V14',\n",
       "                                                           'V15', 'V16', 'V17',\n",
       "                                                           'V18', 'V19', 'V20',\n",
       "                                                           'V21', 'V22', 'V23',\n",
       "                                                           'V24', 'V25', 'V26',\n",
       "                                                           'V27', 'V28',...\n",
       "                  Advanced_Feature_Selection_Classic(ml_usecase='classification',\n",
       "                                                     n_jobs=-1,\n",
       "                                                     random_state=1910,\n",
       "                                                     subclass='binary',\n",
       "                                                     target='target',\n",
       "                                                     top_features_to_pick=0.5)),\n",
       "                 ('fix_multi',\n",
       "                  Fix_multicollinearity(correlation_with_target_preference=None,\n",
       "                                        correlation_with_target_threshold=0.0,\n",
       "                                        target_variable='target',\n",
       "                                        threshold=0.6)),\n",
       "                 ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "          verbose=False),\n",
       " [('Setup Config',\n",
       "                                  Description            Value\n",
       "   0                               session_id             1910\n",
       "   1                                   Target           target\n",
       "   2                              Target Type           Binary\n",
       "   3                            Label Encoded             None\n",
       "   4                            Original Data       (2237, 31)\n",
       "   5                           Missing Values            False\n",
       "   6                         Numeric Features               30\n",
       "   7                     Categorical Features                0\n",
       "   8                         Ordinal Features            False\n",
       "   9                High Cardinality Features            False\n",
       "   10                 High Cardinality Method             None\n",
       "   11                   Transformed Train Set       (1565, 25)\n",
       "   12                    Transformed Test Set        (672, 25)\n",
       "   13                      Shuffle Train-Test             True\n",
       "   14                     Stratify Train-Test            False\n",
       "   15                          Fold Generator  StratifiedKFold\n",
       "   16                             Fold Number               10\n",
       "   17                                CPU Jobs               -1\n",
       "   18                                 Use GPU            False\n",
       "   19                          Log Experiment             True\n",
       "   20                         Experiment Name   selected_model\n",
       "   21                                     USI             a2bd\n",
       "   22                         Imputation Type           simple\n",
       "   23          Iterative Imputation Iteration             None\n",
       "   24                         Numeric Imputer             mean\n",
       "   25      Iterative Imputation Numeric Model             None\n",
       "   26                     Categorical Imputer         constant\n",
       "   27  Iterative Imputation Categorical Model             None\n",
       "   28           Unknown Categoricals Handling   least_frequent\n",
       "   29                               Normalize            False\n",
       "   30                        Normalize Method             None\n",
       "   31                          Transformation             True\n",
       "   32                   Transformation Method      yeo-johnson\n",
       "   33                                     PCA            False\n",
       "   34                              PCA Method             None\n",
       "   35                          PCA Components             None\n",
       "   36                     Ignore Low Variance            False\n",
       "   37                     Combine Rare Levels            False\n",
       "   38                    Rare Level Threshold             None\n",
       "   39                         Numeric Binning            False\n",
       "   40                         Remove Outliers            False\n",
       "   41                      Outliers Threshold             None\n",
       "   42                Remove Multicollinearity             True\n",
       "   43             Multicollinearity Threshold              0.6\n",
       "   44             Remove Perfect Collinearity             True\n",
       "   45                              Clustering            False\n",
       "   46                    Clustering Iteration             None\n",
       "   47                     Polynomial Features             True\n",
       "   48                       Polynomial Degree                2\n",
       "   49                    Trignometry Features            False\n",
       "   50                    Polynomial Threshold              0.1\n",
       "   51                          Group Features            False\n",
       "   52                       Feature Selection             True\n",
       "   53                Feature Selection Method          classic\n",
       "   54            Features Selection Threshold              0.5\n",
       "   55                     Feature Interaction            False\n",
       "   56                           Feature Ratio            False\n",
       "   57                   Interaction Threshold             None\n",
       "   58                           Fix Imbalance             True\n",
       "   59                    Fix Imbalance Method            SMOTE),\n",
       "  ('X_training Set',\n",
       "                V20       V23        V8       V14        V3       V10        V9  \\\n",
       "   20269  -0.208863 -0.183147 -0.062652  0.600170  0.175119  0.247616 -0.100259   \n",
       "   107246 -0.172058 -0.234131 -0.025485 -0.060753  1.035881 -0.133372  0.174855   \n",
       "   178041 -0.054410 -0.327583 -0.110911  0.271039  0.218921  0.028638  0.071086   \n",
       "   52521  -0.039494 -0.231920 -0.009785 -0.583487 -0.171334 -0.211528  0.578167   \n",
       "   159983 -0.159835 -0.591597  0.074216  0.821985 -0.267980 -0.787375  0.851071   \n",
       "   ...          ...       ...       ...       ...       ...       ...       ...   \n",
       "   166174 -0.025037 -0.390140  0.069834  1.185237 -0.235529  0.142906 -0.529795   \n",
       "   110124 -0.221276  0.027046  0.005965  0.424866  0.575749  0.174940  0.316462   \n",
       "   263080 -0.326462 -0.411219 -0.331000 -0.598505 -1.083025 -0.300840  0.223286   \n",
       "   74777   0.155910 -0.052707 -0.083311  0.402689  1.339524  0.068067 -0.396670   \n",
       "   77232   1.125128  1.159703  0.260250 -0.172164  3.713325  0.163490  0.207190   \n",
       "   \n",
       "                V17        V6        V2  ...    Amount  V14_Power2  V11_Power2  \\\n",
       "   20269  -0.125097  0.144566  0.017675  ... -0.072259   -0.347077    0.950754   \n",
       "   107246  0.074807  0.597476  0.209815  ...  0.506160   -0.868140    0.702315   \n",
       "   178041  0.108859  0.178330  0.037151  ...  0.711622   -0.946060   -1.204897   \n",
       "   52521   0.891043  0.387834 -0.076968  ...  0.899775    0.946293    0.185052   \n",
       "   159983 -0.437462 -0.549317  0.115176  ... -0.625980    0.054090   -1.063222   \n",
       "   ...          ...       ...       ...  ...       ...         ...         ...   \n",
       "   166174  0.090808 -0.032576  0.468901  ...  0.290871    0.555113   -1.340240   \n",
       "   110124 -0.073984  0.094447 -0.195040  ... -1.408832   -0.688286    1.064760   \n",
       "   263080  1.445891 -1.138154  0.221559  ... -1.408832    0.986079   -1.272017   \n",
       "   74777  -0.051288 -0.415558  0.125435  ... -1.408832   -0.729785    0.941632   \n",
       "   77232  -0.076652 -1.587010 -2.531006  ... -0.623416   -0.537051   -0.616821   \n",
       "   \n",
       "                 V1       V19       V11        V4       V21  V12_Power2  \\\n",
       "   20269   0.608931 -0.500213  0.829616  0.387245  0.046190    0.672036   \n",
       "   107246 -0.414168  0.334019 -1.464377 -0.083416 -0.243981   -1.117248   \n",
       "   178041 -0.323287  1.631490  0.128058 -0.438810  0.103055   -0.890947   \n",
       "   52521   0.496557 -0.339202 -1.016407  0.599794 -0.325794   -0.349094   \n",
       "   159983 -0.628232  0.686212 -0.335808 -3.747080 -0.189400    0.657924   \n",
       "   ...          ...       ...       ...       ...       ...         ...   \n",
       "   166174 -0.453118  1.118496  0.036959  0.345319  0.116394   -0.558869   \n",
       "   110124  0.641416 -0.381960  0.884983 -0.071775  0.081425   -0.043960   \n",
       "   263080  1.603881 -0.254670 -0.204424  0.190743  0.082813   -0.830362   \n",
       "   74777  -0.408386  1.006036  0.825432 -0.158263  0.029642    0.111307   \n",
       "   77232  -1.367826 -3.811057 -0.560600  0.836612  0.245780   -1.039848   \n",
       "   \n",
       "           V4_Power2  \n",
       "   20269   -0.097773  \n",
       "   107246  -1.324874  \n",
       "   178041  -0.692430  \n",
       "   52521    0.555246  \n",
       "   159983   1.614506  \n",
       "   ...           ...  \n",
       "   166174  -0.249713  \n",
       "   110124  -1.326021  \n",
       "   263080  -0.819093  \n",
       "   74777   -1.273301  \n",
       "   77232    1.037569  \n",
       "   \n",
       "   [1565 rows x 25 columns]),\n",
       "  ('y_training Set',\n",
       "   20269     0\n",
       "   107246    0\n",
       "   178041    0\n",
       "   52521     1\n",
       "   159983    0\n",
       "            ..\n",
       "   166174    0\n",
       "   110124    0\n",
       "   263080    1\n",
       "   74777     0\n",
       "   77232     0\n",
       "   Name: target, Length: 1565, dtype: int64),\n",
       "  ('X_test Set',\n",
       "                V20       V23        V8       V14        V3       V10        V9  \\\n",
       "   120736  1.514219 -0.978931 -0.236734  0.675301 -0.248991  0.020839 -0.108833   \n",
       "   161891 -0.508156  0.640954 -0.081921 -0.181691 -0.208219  1.353256 -0.663983   \n",
       "   156656 -0.064965  0.153433 -0.165049  1.223591 -0.181405  0.386924  1.394429   \n",
       "   101018  0.033507 -0.574701  0.269518  0.070457  0.378012  1.056939 -0.499253   \n",
       "   38119  -0.276093 -0.051943  0.207864 -0.017689  1.426170 -0.319710  0.207274   \n",
       "   ...          ...       ...       ...       ...       ...       ...       ...   \n",
       "   11507  -0.157139 -0.016019 -0.094605  1.707485  0.499419  0.370262  0.734282   \n",
       "   134119 -0.031962  0.635664  0.062739  0.776028  0.724254 -0.128776 -0.662371   \n",
       "   98817   2.140370 -0.199197  0.529772  0.197662  1.382354  0.009577 -0.170816   \n",
       "   15852  -0.204722  0.438586 -0.104379  0.601363  0.407632  0.623276 -0.670004   \n",
       "   170041 -0.342775  0.306735 -0.110512  0.609299 -0.595248  0.331965  0.490359   \n",
       "   \n",
       "                V17        V6        V2  ...    Amount  V14_Power2  V11_Power2  \\\n",
       "   120736  0.100924 -0.119124 -1.069155  ...  1.828753   -0.204291   -1.291223   \n",
       "   161891  0.082997  0.027910 -0.911287  ...  0.299639   -0.503091   -0.722304   \n",
       "   156656  0.749174 -0.295758 -0.668637  ...  0.683838    0.597299   -1.364906   \n",
       "   101018 -0.278192  2.389582 -0.047205  ...  0.357506   -1.054188   -1.171843   \n",
       "   38119   0.814463  1.012990 -0.062911  ... -0.320894   -0.955402   -1.349898   \n",
       "   ...          ...       ...       ...  ...       ...         ...         ...   \n",
       "   11507   1.047146 -0.184757 -0.392857  ... -0.359603    1.001019    1.272888   \n",
       "   134119 -0.117768 -0.325506  0.402305  ...  0.683912   -0.023526    0.851269   \n",
       "   98817   0.580963 -1.559301 -4.082267  ...  0.815124   -1.027796   -1.313433   \n",
       "   15852  -0.191888  0.235125 -0.169092  ...  0.936165   -0.344770    0.647680   \n",
       "   170041 -0.321754  0.049384 -0.194020  ... -0.885609   -0.329448   -1.320887   \n",
       "   \n",
       "                 V1       V19       V11        V4       V21  V12_Power2  \\\n",
       "   120736 -0.265070 -1.181996  0.077993  0.721953  0.302147   -0.404971   \n",
       "   161891  1.685159  0.248840  0.299959 -1.239981 -0.345793   -1.128412   \n",
       "   156656  1.506904  0.140650  0.004796 -0.382497  0.116801    1.764516   \n",
       "   101018 -0.568008  0.957225 -0.273150  0.726685  0.044998   -0.075409   \n",
       "   38119  -0.600886 -2.198901 -0.127962 -0.245268  0.068514   -0.355053   \n",
       "   ...          ...       ...       ...       ...       ...         ...   \n",
       "   11507   0.791614  0.930950  1.005058 -0.251173 -0.149076    1.676142   \n",
       "   134119 -0.515003  0.402208  0.785680 -0.079341 -0.227634    0.895959   \n",
       "   98817  -1.530445  0.371908  0.061395 -0.082956  0.505945   -1.085345   \n",
       "   15852  -0.652725 -2.225066  0.705445  0.631660  0.169607   -1.042349   \n",
       "   170041  1.558245  0.826274 -0.161460 -0.040286 -0.310680   -0.765451   \n",
       "   \n",
       "           V4_Power2  \n",
       "   120736   0.832426  \n",
       "   161891   0.686288  \n",
       "   156656  -0.830047  \n",
       "   101018   0.841864  \n",
       "   38119   -1.136806  \n",
       "   ...           ...  \n",
       "   11507   -1.125347  \n",
       "   134119  -1.325503  \n",
       "   98817   -1.324957  \n",
       "   15852    0.634081  \n",
       "   170041  -1.318822  \n",
       "   \n",
       "   [672 rows x 25 columns]),\n",
       "  ('y_test Set',\n",
       "   120736    0\n",
       "   161891    0\n",
       "   156656    0\n",
       "   101018    0\n",
       "   38119     0\n",
       "            ..\n",
       "   11507     0\n",
       "   134119    0\n",
       "   98817     0\n",
       "   15852     0\n",
       "   170041    0\n",
       "   Name: target, Length: 672, dtype: int64),\n",
       "  ('Transformation Pipeline',\n",
       "   Pipeline(memory=None,\n",
       "            steps=[('dtypes',\n",
       "                    DataTypes_Auto_infer(categorical_features=[],\n",
       "                                         display_types=False, features_todrop=[],\n",
       "                                         id_columns=[],\n",
       "                                         ml_usecase='classification',\n",
       "                                         numerical_features=['Time', 'V1', 'V2',\n",
       "                                                             'V3', 'V4', 'V5',\n",
       "                                                             'V6', 'V7', 'V8',\n",
       "                                                             'V9', 'V10', 'V11',\n",
       "                                                             'V12', 'V13', 'V14',\n",
       "                                                             'V15', 'V16', 'V17',\n",
       "                                                             'V18', 'V19', 'V20',\n",
       "                                                             'V21', 'V22', 'V23',\n",
       "                                                             'V24', 'V25', 'V26',\n",
       "                                                             'V27', 'V28',...\n",
       "                    Advanced_Feature_Selection_Classic(ml_usecase='classification',\n",
       "                                                       n_jobs=-1,\n",
       "                                                       random_state=1910,\n",
       "                                                       subclass='binary',\n",
       "                                                       target='target',\n",
       "                                                       top_features_to_pick=0.5)),\n",
       "                   ('fix_multi',\n",
       "                    Fix_multicollinearity(correlation_with_target_preference=None,\n",
       "                                          correlation_with_target_threshold=0.0,\n",
       "                                          target_variable='target',\n",
       "                                          threshold=0.6)),\n",
       "                   ('dfs', 'passthrough'), ('pca', 'passthrough')],\n",
       "            verbose=False))],\n",
       " [<pandas.io.formats.style.Styler at 0x1192957fd30>,\n",
       "                                      Model  Accuracy     AUC  Recall   Prec.  \\\n",
       "  et                 Extra Trees Classifier    0.9763  0.9836  0.8733  0.9597   \n",
       "  lightgbm  Light Gradient Boosting Machine    0.9712  0.9809  0.8779  0.9191   \n",
       "  rf               Random Forest Classifier    0.9764  0.9798  0.8872  0.9457   \n",
       "  gbc          Gradient Boosting Classifier    0.9668  0.9778  0.8824  0.8884   \n",
       "  lr                    Logistic Regression    0.9533  0.9747  0.9142  0.7941   \n",
       "  \n",
       "                F1   Kappa     MCC     APC  TT (Sec)  \n",
       "  et        0.9122  0.8986  0.9014  0.9547     0.232  \n",
       "  lightgbm  0.8963  0.8796  0.8810  0.9530     1.389  \n",
       "  rf        0.9139  0.9003  0.9019  0.9514     0.567  \n",
       "  gbc       0.8832  0.8639  0.8653  0.9500     1.772  \n",
       "  lr        0.8489  0.8216  0.8251  0.9450     0.035  ],\n",
       " 5,\n",
       " False,\n",
       " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x1192957c4c0>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x119295841c0>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x11929584cd0>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x11929584280>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x119295840d0>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x11929584970>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x11929584a00>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x11929584730>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x119295849d0>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x11929584460>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x11929562100>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x11929587370>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x11929587910>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x11929587fa0>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x11929587790>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x11929587cd0>,\n",
       "  'dummy': <pycaret.containers.models.classification.DummyClassifierContainer at 0x1192959ad90>},\n",
       " 'lightgbm',\n",
       " StratifiedKFold(n_splits=10, random_state=None, shuffle=False),\n",
       " 1910,\n",
       " 'box-cox',\n",
       "              V20       V23        V8       V14        V3       V10        V9  \\\n",
       " 120736  1.514219 -0.978931 -0.236734  0.675301 -0.248991  0.020839 -0.108833   \n",
       " 161891 -0.508156  0.640954 -0.081921 -0.181691 -0.208219  1.353256 -0.663983   \n",
       " 156656 -0.064965  0.153433 -0.165049  1.223591 -0.181405  0.386924  1.394429   \n",
       " 101018  0.033507 -0.574701  0.269518  0.070457  0.378012  1.056939 -0.499253   \n",
       " 38119  -0.276093 -0.051943  0.207864 -0.017689  1.426170 -0.319710  0.207274   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 11507  -0.157139 -0.016019 -0.094605  1.707485  0.499419  0.370262  0.734282   \n",
       " 134119 -0.031962  0.635664  0.062739  0.776028  0.724254 -0.128776 -0.662371   \n",
       " 98817   2.140370 -0.199197  0.529772  0.197662  1.382354  0.009577 -0.170816   \n",
       " 15852  -0.204722  0.438586 -0.104379  0.601363  0.407632  0.623276 -0.670004   \n",
       " 170041 -0.342775  0.306735 -0.110512  0.609299 -0.595248  0.331965  0.490359   \n",
       " \n",
       "              V17        V6        V2  ...    Amount  V14_Power2  V11_Power2  \\\n",
       " 120736  0.100924 -0.119124 -1.069155  ...  1.828753   -0.204291   -1.291223   \n",
       " 161891  0.082997  0.027910 -0.911287  ...  0.299639   -0.503091   -0.722304   \n",
       " 156656  0.749174 -0.295758 -0.668637  ...  0.683838    0.597299   -1.364906   \n",
       " 101018 -0.278192  2.389582 -0.047205  ...  0.357506   -1.054188   -1.171843   \n",
       " 38119   0.814463  1.012990 -0.062911  ... -0.320894   -0.955402   -1.349898   \n",
       " ...          ...       ...       ...  ...       ...         ...         ...   \n",
       " 11507   1.047146 -0.184757 -0.392857  ... -0.359603    1.001019    1.272888   \n",
       " 134119 -0.117768 -0.325506  0.402305  ...  0.683912   -0.023526    0.851269   \n",
       " 98817   0.580963 -1.559301 -4.082267  ...  0.815124   -1.027796   -1.313433   \n",
       " 15852  -0.191888  0.235125 -0.169092  ...  0.936165   -0.344770    0.647680   \n",
       " 170041 -0.321754  0.049384 -0.194020  ... -0.885609   -0.329448   -1.320887   \n",
       " \n",
       "               V1       V19       V11        V4       V21  V12_Power2  \\\n",
       " 120736 -0.265070 -1.181996  0.077993  0.721953  0.302147   -0.404971   \n",
       " 161891  1.685159  0.248840  0.299959 -1.239981 -0.345793   -1.128412   \n",
       " 156656  1.506904  0.140650  0.004796 -0.382497  0.116801    1.764516   \n",
       " 101018 -0.568008  0.957225 -0.273150  0.726685  0.044998   -0.075409   \n",
       " 38119  -0.600886 -2.198901 -0.127962 -0.245268  0.068514   -0.355053   \n",
       " ...          ...       ...       ...       ...       ...         ...   \n",
       " 11507   0.791614  0.930950  1.005058 -0.251173 -0.149076    1.676142   \n",
       " 134119 -0.515003  0.402208  0.785680 -0.079341 -0.227634    0.895959   \n",
       " 98817  -1.530445  0.371908  0.061395 -0.082956  0.505945   -1.085345   \n",
       " 15852  -0.652725 -2.225066  0.705445  0.631660  0.169607   -1.042349   \n",
       " 170041  1.558245  0.826274 -0.161460 -0.040286 -0.310680   -0.765451   \n",
       " \n",
       "         V4_Power2  \n",
       " 120736   0.832426  \n",
       " 161891   0.686288  \n",
       " 156656  -0.830047  \n",
       " 101018   0.841864  \n",
       " 38119   -1.136806  \n",
       " ...           ...  \n",
       " 11507   -1.125347  \n",
       " 134119  -1.325503  \n",
       " 98817   -1.324957  \n",
       " 15852    0.634081  \n",
       " 170041  -1.318822  \n",
       " \n",
       " [672 rows x 25 columns],\n",
       " 20269     0\n",
       " 107246    0\n",
       " 178041    0\n",
       " 52521     1\n",
       " 159983    0\n",
       "          ..\n",
       " 166174    0\n",
       " 110124    0\n",
       " 263080    1\n",
       " 74777     0\n",
       " 77232     0\n",
       " Name: target, Length: 1565, dtype: int64,\n",
       " {'USI',\n",
       "  'X',\n",
       "  'X_test',\n",
       "  'X_train',\n",
       "  '_all_metrics',\n",
       "  '_all_models',\n",
       "  '_all_models_internal',\n",
       "  '_available_plots',\n",
       "  '_gpu_n_jobs_param',\n",
       "  '_internal_pipeline',\n",
       "  '_ml_usecase',\n",
       "  'create_model_container',\n",
       "  'dashboard_logger',\n",
       "  'data_before_preprocess',\n",
       "  'display_container',\n",
       "  'exp_name_log',\n",
       "  'experiment__',\n",
       "  'fix_imbalance_method_param',\n",
       "  'fix_imbalance_param',\n",
       "  'fold_generator',\n",
       "  'fold_groups_param',\n",
       "  'fold_groups_param_full',\n",
       "  'fold_param',\n",
       "  'fold_shuffle_param',\n",
       "  'gpu_param',\n",
       "  'html_param',\n",
       "  'imputation_classifier',\n",
       "  'imputation_regressor',\n",
       "  'iterative_imputation_iters_param',\n",
       "  'log_plots_param',\n",
       "  'logging_param',\n",
       "  'master_model_container',\n",
       "  'n_jobs_param',\n",
       "  'prep_pipe',\n",
       "  'pycaret_globals',\n",
       "  'seed',\n",
       "  'stratify_param',\n",
       "  'target_param',\n",
       "  'transform_target_method_param',\n",
       "  'transform_target_param',\n",
       "  'y',\n",
       "  'y_test',\n",
       "  'y_train'},\n",
       "              V20       V23        V8       V14        V3       V10        V9  \\\n",
       " 20269  -0.208863 -0.183147 -0.062652  0.600170  0.175119  0.247616 -0.100259   \n",
       " 107246 -0.172058 -0.234131 -0.025485 -0.060753  1.035881 -0.133372  0.174855   \n",
       " 178041 -0.054410 -0.327583 -0.110911  0.271039  0.218921  0.028638  0.071086   \n",
       " 52521  -0.039494 -0.231920 -0.009785 -0.583487 -0.171334 -0.211528  0.578167   \n",
       " 159983 -0.159835 -0.591597  0.074216  0.821985 -0.267980 -0.787375  0.851071   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 166174 -0.025037 -0.390140  0.069834  1.185237 -0.235529  0.142906 -0.529795   \n",
       " 110124 -0.221276  0.027046  0.005965  0.424866  0.575749  0.174940  0.316462   \n",
       " 263080 -0.326462 -0.411219 -0.331000 -0.598505 -1.083025 -0.300840  0.223286   \n",
       " 74777   0.155910 -0.052707 -0.083311  0.402689  1.339524  0.068067 -0.396670   \n",
       " 77232   1.125128  1.159703  0.260250 -0.172164  3.713325  0.163490  0.207190   \n",
       " \n",
       "              V17        V6        V2  ...    Amount  V14_Power2  V11_Power2  \\\n",
       " 20269  -0.125097  0.144566  0.017675  ... -0.072259   -0.347077    0.950754   \n",
       " 107246  0.074807  0.597476  0.209815  ...  0.506160   -0.868140    0.702315   \n",
       " 178041  0.108859  0.178330  0.037151  ...  0.711622   -0.946060   -1.204897   \n",
       " 52521   0.891043  0.387834 -0.076968  ...  0.899775    0.946293    0.185052   \n",
       " 159983 -0.437462 -0.549317  0.115176  ... -0.625980    0.054090   -1.063222   \n",
       " ...          ...       ...       ...  ...       ...         ...         ...   \n",
       " 166174  0.090808 -0.032576  0.468901  ...  0.290871    0.555113   -1.340240   \n",
       " 110124 -0.073984  0.094447 -0.195040  ... -1.408832   -0.688286    1.064760   \n",
       " 263080  1.445891 -1.138154  0.221559  ... -1.408832    0.986079   -1.272017   \n",
       " 74777  -0.051288 -0.415558  0.125435  ... -1.408832   -0.729785    0.941632   \n",
       " 77232  -0.076652 -1.587010 -2.531006  ... -0.623416   -0.537051   -0.616821   \n",
       " \n",
       "               V1       V19       V11        V4       V21  V12_Power2  \\\n",
       " 20269   0.608931 -0.500213  0.829616  0.387245  0.046190    0.672036   \n",
       " 107246 -0.414168  0.334019 -1.464377 -0.083416 -0.243981   -1.117248   \n",
       " 178041 -0.323287  1.631490  0.128058 -0.438810  0.103055   -0.890947   \n",
       " 52521   0.496557 -0.339202 -1.016407  0.599794 -0.325794   -0.349094   \n",
       " 159983 -0.628232  0.686212 -0.335808 -3.747080 -0.189400    0.657924   \n",
       " ...          ...       ...       ...       ...       ...         ...   \n",
       " 166174 -0.453118  1.118496  0.036959  0.345319  0.116394   -0.558869   \n",
       " 110124  0.641416 -0.381960  0.884983 -0.071775  0.081425   -0.043960   \n",
       " 263080  1.603881 -0.254670 -0.204424  0.190743  0.082813   -0.830362   \n",
       " 74777  -0.408386  1.006036  0.825432 -0.158263  0.029642    0.111307   \n",
       " 77232  -1.367826 -3.811057 -0.560600  0.836612  0.245780   -1.039848   \n",
       " \n",
       "         V4_Power2  \n",
       " 20269   -0.097773  \n",
       " 107246  -1.324874  \n",
       " 178041  -0.692430  \n",
       " 52521    0.555246  \n",
       " 159983   1.614506  \n",
       " ...           ...  \n",
       " 166174  -0.249713  \n",
       " 110124  -1.326021  \n",
       " 263080  -0.819093  \n",
       " 74777   -1.273301  \n",
       " 77232    1.037569  \n",
       " \n",
       " [1565 rows x 25 columns],\n",
       " <pycaret.loggers.DashboardLogger at 0x11929582580>,\n",
       " 'lightgbm',\n",
       " False,\n",
       " {'lr': <pycaret.containers.models.classification.LogisticRegressionClassifierContainer at 0x1192959aaf0>,\n",
       "  'knn': <pycaret.containers.models.classification.KNeighborsClassifierContainer at 0x1192959a3a0>,\n",
       "  'nb': <pycaret.containers.models.classification.GaussianNBClassifierContainer at 0x1192959a130>,\n",
       "  'dt': <pycaret.containers.models.classification.DecisionTreeClassifierContainer at 0x1192959aeb0>,\n",
       "  'svm': <pycaret.containers.models.classification.SGDClassifierContainer at 0x1192959aee0>,\n",
       "  'rbfsvm': <pycaret.containers.models.classification.SVCClassifierContainer at 0x11929582790>,\n",
       "  'gpc': <pycaret.containers.models.classification.GaussianProcessClassifierContainer at 0x119295826d0>,\n",
       "  'mlp': <pycaret.containers.models.classification.MLPClassifierContainer at 0x11929582f10>,\n",
       "  'ridge': <pycaret.containers.models.classification.RidgeClassifierContainer at 0x11929582ee0>,\n",
       "  'rf': <pycaret.containers.models.classification.RandomForestClassifierContainer at 0x119295e30a0>,\n",
       "  'qda': <pycaret.containers.models.classification.QuadraticDiscriminantAnalysisContainer at 0x119295e3280>,\n",
       "  'ada': <pycaret.containers.models.classification.AdaBoostClassifierContainer at 0x119295e3580>,\n",
       "  'gbc': <pycaret.containers.models.classification.GradientBoostingClassifierContainer at 0x119295e3700>,\n",
       "  'lda': <pycaret.containers.models.classification.LinearDiscriminantAnalysisContainer at 0x119295e3760>,\n",
       "  'et': <pycaret.containers.models.classification.ExtraTreesClassifierContainer at 0x119295e3be0>,\n",
       "  'lightgbm': <pycaret.containers.models.classification.LGBMClassifierContainer at 0x1192959adf0>,\n",
       "  'dummy': <pycaret.containers.models.classification.DummyClassifierContainer at 0x119296be0d0>,\n",
       "  'Bagging': <pycaret.containers.models.classification.BaggingClassifierContainer at 0x1192959ad30>,\n",
       "  'Stacking': <pycaret.containers.models.classification.StackingClassifierContainer at 0x119296be2b0>,\n",
       "  'Voting': <pycaret.containers.models.classification.VotingClassifierContainer at 0x119296be310>,\n",
       "  'CalibratedCV': <pycaret.containers.models.classification.CalibratedClassifierCVContainer at 0x119296be370>},\n",
       " Pipeline(memory=None,\n",
       "          steps=[('fix_imbalance',\n",
       "                  SMOTE(k_neighbors=5, n_jobs=None, random_state=1910,\n",
       "                        sampling_strategy='auto'))],\n",
       "          verbose=False),\n",
       " [LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                 importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                 min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                 n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                 random_state=1910, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "                 subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "  ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                       oob_score=False, random_state=1910, verbose=0,\n",
       "                       warm_start=False),\n",
       "  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                         criterion='gini', max_depth=None, max_features='auto',\n",
       "                         max_leaf_nodes=None, max_samples=None,\n",
       "                         min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                         min_samples_leaf=1, min_samples_split=2,\n",
       "                         min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                         n_jobs=-1, oob_score=False, random_state=1910, verbose=0,\n",
       "                         warm_start=False),\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                     multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                     random_state=1910, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                     warm_start=False),\n",
       "  GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                             learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                             max_features=None, max_leaf_nodes=None,\n",
       "                             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                             min_samples_leaf=1, min_samples_split=2,\n",
       "                             min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                             n_iter_no_change=None, presort='deprecated',\n",
       "                             random_state=1910, subsample=1.0, tol=0.0001,\n",
       "                             validation_fraction=0.1, verbose=0,\n",
       "                             warm_start=False)],\n",
       " 10,\n",
       "              V20       V23        V8       V14        V3       V10        V9  \\\n",
       " 138220  0.416189  0.175303 -0.353324  0.374451  0.611200  0.484079 -0.356552   \n",
       " 219598  0.739398  0.003907  0.193090 -0.404883 -0.221149 -0.564757  0.084885   \n",
       " 241429 -0.348185  0.416579 -0.021783 -0.336779 -0.134854  1.167662 -0.171733   \n",
       " 144299 -1.325286  0.774947 -0.308801 -0.086953  0.581237  0.642253  0.370436   \n",
       " 76929   0.691079 -0.441652  0.271251 -2.186143 -1.214971 -1.861533 -0.863173   \n",
       " ...          ...       ...       ...       ...       ...       ...       ...   \n",
       " 46488  -0.174878 -0.718488 -0.019651  0.113405  0.616627  0.161076  0.101084   \n",
       " 88728   0.920370 -0.510093 -0.114774  0.128779  0.230280 -0.071504  0.577146   \n",
       " 178254 -0.107989 -0.348558 -0.286463  0.727561 -0.864119  0.908999 -0.689166   \n",
       " 83440  -0.130026 -0.238823  0.581113  0.013179  1.934801  0.157542 -0.012731   \n",
       " 214662  0.690002 -0.471616  0.438106 -1.931451 -1.448261 -1.717067 -0.556456   \n",
       " \n",
       "              V17        V6        V2  ...    Amount  V14_Power2  V11_Power2  \\\n",
       " 138220  0.377852  1.168685 -0.013239  ...  1.317053   -0.781126    0.851526   \n",
       " 219598  0.820010 -0.718878 -0.440851  ...  0.994615    0.367045   -0.754290   \n",
       " 241429  0.224339  0.341025 -1.208648  ...  0.946233    0.103245    0.908823   \n",
       " 144299 -0.193986  0.034019 -0.008428  ... -0.630279   -0.803014   -0.495135   \n",
       " 76929  -1.287122 -0.764776  0.903586  ... -1.408832    1.960522    1.716417   \n",
       " ...          ...       ...       ...  ...       ...         ...         ...   \n",
       " 46488  -0.228241  1.041746  0.227429  ... -0.725839   -1.065204   -0.529685   \n",
       " 88728   0.251612  0.029172 -0.948013  ...  1.614940   -1.063828   -1.379297   \n",
       " 178254  0.268735 -0.713800 -0.355654  ... -0.042931   -0.108771    0.141557   \n",
       " 83440   1.307377  1.112765  0.340545  ...  0.724857   -1.002181    1.075672   \n",
       " 214662 -1.580703  0.133453  0.389149  ...  0.965941    1.943043    1.884035   \n",
       " \n",
       "               V1       V19       V11        V4       V21  V12_Power2  \\\n",
       " 138220 -0.226300  0.841201 -1.643152  1.164783  0.460451    0.010294   \n",
       " 219598 -0.938266  0.252544  0.290543 -0.254062 -0.017721   -0.968059   \n",
       " 241429  1.529168 -0.265305 -1.721050 -1.114548 -0.145880    0.793325   \n",
       " 144299 -0.888918 -0.206990 -0.621399  0.183075 -0.254968   -0.569910   \n",
       " 76929  -0.180265  0.065269  1.440325  1.251715  0.179964    1.905380   \n",
       " ...          ...       ...       ...       ...       ...         ...   \n",
       " 46488  -0.311681  0.712360 -0.603995  0.051060 -0.164778   -0.889675   \n",
       " 88728   0.007421 -0.562202 -0.061853  0.242404  0.145333   -0.513485   \n",
       " 178254  1.737123  1.005564  0.541166 -0.765639  0.369004   -1.075079   \n",
       " 83440  -0.834795  1.218915 -1.986882  1.242780 -0.197183   -1.139108   \n",
       " 214662  0.092882 -0.203420  1.795978  0.854308  0.718415    1.902244   \n",
       " \n",
       "         V4_Power2  \n",
       " 138220   1.422340  \n",
       " 219598  -1.119659  \n",
       " 241429   0.549511  \n",
       " 144299  -0.845421  \n",
       " 76929    1.490453  \n",
       " ...           ...  \n",
       " 46488   -1.208988  \n",
       " 88728   -0.633663  \n",
       " 178254   0.028040  \n",
       " 83440    1.483925  \n",
       " 214662   1.065211  \n",
       " \n",
       " [2237 rows x 25 columns],\n",
       " <MLUsecase.CLASSIFICATION: 1>,\n",
       " True,\n",
       " False,\n",
       " 'selected_model',\n",
       " None,\n",
       " False,\n",
       " 'target',\n",
       " [      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9809  0.9943  0.8636  1.0000  0.9268  0.9159  0.9192  0.9788\n",
       "  1       0.9809  0.9966  0.9545  0.9130  0.9333  0.9222  0.9225  0.9858\n",
       "  2       0.9682  0.9825  0.8636  0.9048  0.8837  0.8653  0.8656  0.9458\n",
       "  3       0.9745  0.9822  0.9130  0.9130  0.9130  0.8981  0.8981  0.9439\n",
       "  4       0.9873  0.9987  0.9565  0.9565  0.9565  0.9491  0.9491  0.9936\n",
       "  5       0.9679  0.9685  0.9091  0.8696  0.8889  0.8702  0.8705  0.9549\n",
       "  6       0.9487  0.9522  0.8636  0.7917  0.8261  0.7961  0.7971  0.9229\n",
       "  7       0.9808  0.9874  0.8636  1.0000  0.9268  0.9158  0.9191  0.9681\n",
       "  8       0.9423  0.9742  0.7273  0.8421  0.7805  0.7475  0.7501  0.9013\n",
       "  9       0.9808  0.9722  0.8636  1.0000  0.9268  0.9158  0.9191  0.9353\n",
       "  Mean    0.9712  0.9809  0.8779  0.9191  0.8963  0.8796  0.8810  0.9530\n",
       "  Std     0.0141  0.0138  0.0616  0.0678  0.0516  0.0597  0.0596  0.0276,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9745  0.9943  0.8182  1.0000  0.9000  0.8856  0.8914  0.9698\n",
       "  1       0.9936  0.9971  0.9545  1.0000  0.9767  0.9731  0.9734  0.9868\n",
       "  2       0.9618  0.9909  0.9091  0.8333  0.8696  0.8472  0.8483  0.9667\n",
       "  3       0.9682  0.9752  0.8696  0.9091  0.8889  0.8703  0.8706  0.9477\n",
       "  4       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
       "  5       0.9744  0.9681  0.8636  0.9500  0.9048  0.8900  0.8913  0.9481\n",
       "  6       0.9679  0.9674  0.8636  0.9048  0.8837  0.8651  0.8655  0.9203\n",
       "  7       0.9744  0.9937  0.8182  1.0000  0.9000  0.8855  0.8913  0.9784\n",
       "  8       0.9679  0.9691  0.7727  1.0000  0.8718  0.8538  0.8631  0.8918\n",
       "  9       0.9808  0.9798  0.8636  1.0000  0.9268  0.9158  0.9191  0.9379\n",
       "  Mean    0.9763  0.9836  0.8733  0.9597  0.9122  0.8986  0.9014  0.9547\n",
       "  Std     0.0114  0.0123  0.0636  0.0560  0.0415  0.0481  0.0470  0.0309,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9809  0.9869  0.8636  1.0000  0.9268  0.9159  0.9192  0.9602\n",
       "  1       0.9873  0.9968  0.9545  0.9545  0.9545  0.9471  0.9471  0.9858\n",
       "  2       0.9618  0.9761  0.9091  0.8333  0.8696  0.8472  0.8483  0.9478\n",
       "  3       0.9682  0.9695  0.8696  0.9091  0.8889  0.8703  0.8706  0.9406\n",
       "  4       0.9873  0.9994  0.9565  0.9565  0.9565  0.9491  0.9491  0.9965\n",
       "  5       0.9744  0.9722  0.8636  0.9500  0.9048  0.8900  0.8913  0.9545\n",
       "  6       0.9744  0.9669  0.9091  0.9091  0.9091  0.8942  0.8942  0.9302\n",
       "  7       0.9872  0.9902  0.9091  1.0000  0.9524  0.9450  0.9464  0.9734\n",
       "  8       0.9615  0.9588  0.7727  0.9444  0.8500  0.8282  0.8337  0.8777\n",
       "  9       0.9808  0.9817  0.8636  1.0000  0.9268  0.9158  0.9191  0.9476\n",
       "  Mean    0.9764  0.9798  0.8872  0.9457  0.9139  0.9003  0.9019  0.9514\n",
       "  Std     0.0095  0.0127  0.0509  0.0494  0.0347  0.0401  0.0394  0.0313,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9682  0.9714  0.9091  0.8696  0.8889  0.8703  0.8706  0.9264\n",
       "  1       0.9490  0.9549  0.9545  0.7500  0.8400  0.8102  0.8185  0.9610\n",
       "  2       0.9363  0.9838  0.9091  0.7143  0.8000  0.7628  0.7706  0.9502\n",
       "  3       0.9554  0.9708  0.9130  0.8077  0.8571  0.8308  0.8330  0.9325\n",
       "  4       0.9682  0.9981  0.9565  0.8462  0.8980  0.8792  0.8815  0.9910\n",
       "  5       0.9615  0.9732  0.9545  0.8077  0.8750  0.8525  0.8566  0.9506\n",
       "  6       0.9615  0.9559  0.9091  0.8333  0.8696  0.8471  0.8482  0.9252\n",
       "  7       0.9808  0.9983  0.9545  0.9130  0.9333  0.9221  0.9224  0.9909\n",
       "  8       0.9038  0.9681  0.7727  0.6296  0.6939  0.6375  0.6423  0.8821\n",
       "  9       0.9487  0.9729  0.9091  0.7692  0.8333  0.8033  0.8072  0.9402\n",
       "  Mean    0.9533  0.9747  0.9142  0.7941  0.8489  0.8216  0.8251  0.9450\n",
       "  Std     0.0203  0.0142  0.0518  0.0777  0.0625  0.0743  0.0729  0.0307,\n",
       "        Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC     APC\n",
       "  Fold                                                                  \n",
       "  0       0.9809  0.9781  0.8636  1.0000  0.9268  0.9159  0.9192  0.9608\n",
       "  1       0.9682  0.9956  0.9091  0.8696  0.8889  0.8703  0.8706  0.9791\n",
       "  2       0.9618  0.9774  0.9091  0.8333  0.8696  0.8472  0.8483  0.9534\n",
       "  3       0.9745  0.9698  0.9130  0.9130  0.9130  0.8981  0.8981  0.9387\n",
       "  4       0.9745  0.9984  0.9565  0.8800  0.9167  0.9017  0.9028  0.9922\n",
       "  5       0.9615  0.9766  0.9091  0.8333  0.8696  0.8471  0.8482  0.9489\n",
       "  6       0.9423  0.9722  0.8636  0.7600  0.8085  0.7747  0.7769  0.9277\n",
       "  7       0.9744  0.9956  0.8636  0.9500  0.9048  0.8900  0.8913  0.9781\n",
       "  8       0.9551  0.9627  0.7727  0.8947  0.8293  0.8036  0.8065  0.8858\n",
       "  9       0.9744  0.9512  0.8636  0.9500  0.9048  0.8900  0.8913  0.9352\n",
       "  Mean    0.9668  0.9778  0.8824  0.8884  0.8832  0.8639  0.8653  0.9500\n",
       "  Std     0.0111  0.0145  0.0469  0.0661  0.0371  0.0434  0.0432  0.0292],\n",
       " True,\n",
       " 138220    0\n",
       " 219598    0\n",
       " 241429    0\n",
       " 144299    0\n",
       " 76929     1\n",
       "          ..\n",
       " 46488     0\n",
       " 88728     0\n",
       " 178254    0\n",
       " 83440     0\n",
       " 214662    1\n",
       " Name: target, Length: 2237, dtype: int64,\n",
       " -1,\n",
       " 'a2bd',\n",
       " True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                     oob_score=False, random_state=1910, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_209a0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_209a0_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_209a0_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_209a0_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_209a0_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_209a0_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_209a0_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_209a0_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_209a0_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_209a0_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_209a0_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_209a0_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_209a0_row0_col1\" class=\"data row0 col1\" >0.9791</td>\n",
       "      <td id=\"T_209a0_row0_col2\" class=\"data row0 col2\" >0.9796</td>\n",
       "      <td id=\"T_209a0_row0_col3\" class=\"data row0 col3\" >0.8830</td>\n",
       "      <td id=\"T_209a0_row0_col4\" class=\"data row0 col4\" >0.9805</td>\n",
       "      <td id=\"T_209a0_row0_col5\" class=\"data row0 col5\" >0.9292</td>\n",
       "      <td id=\"T_209a0_row0_col6\" class=\"data row0 col6\" >0.9170</td>\n",
       "      <td id=\"T_209a0_row0_col7\" class=\"data row0 col7\" >0.9188</td>\n",
       "      <td id=\"T_209a0_row0_col8\" class=\"data row0 col8\" >0.9578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11928ce5e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = predict_model(best, raw_score=True,data = df_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "Define search space for hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ff34d_row10_col0, #T_ff34d_row10_col1, #T_ff34d_row10_col2, #T_ff34d_row10_col3, #T_ff34d_row10_col4, #T_ff34d_row10_col5, #T_ff34d_row10_col6, #T_ff34d_row10_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ff34d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ff34d_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_ff34d_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_ff34d_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_ff34d_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_ff34d_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_ff34d_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_ff34d_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_ff34d_level0_col7\" class=\"col_heading level0 col7\" >APC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ff34d_row0_col0\" class=\"data row0 col0\" >0.9745</td>\n",
       "      <td id=\"T_ff34d_row0_col1\" class=\"data row0 col1\" >0.9835</td>\n",
       "      <td id=\"T_ff34d_row0_col2\" class=\"data row0 col2\" >0.8182</td>\n",
       "      <td id=\"T_ff34d_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_ff34d_row0_col4\" class=\"data row0 col4\" >0.9000</td>\n",
       "      <td id=\"T_ff34d_row0_col5\" class=\"data row0 col5\" >0.8856</td>\n",
       "      <td id=\"T_ff34d_row0_col6\" class=\"data row0 col6\" >0.8914</td>\n",
       "      <td id=\"T_ff34d_row0_col7\" class=\"data row0 col7\" >0.9526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ff34d_row1_col0\" class=\"data row1 col0\" >0.9873</td>\n",
       "      <td id=\"T_ff34d_row1_col1\" class=\"data row1 col1\" >0.9980</td>\n",
       "      <td id=\"T_ff34d_row1_col2\" class=\"data row1 col2\" >0.9545</td>\n",
       "      <td id=\"T_ff34d_row1_col3\" class=\"data row1 col3\" >0.9545</td>\n",
       "      <td id=\"T_ff34d_row1_col4\" class=\"data row1 col4\" >0.9545</td>\n",
       "      <td id=\"T_ff34d_row1_col5\" class=\"data row1 col5\" >0.9471</td>\n",
       "      <td id=\"T_ff34d_row1_col6\" class=\"data row1 col6\" >0.9471</td>\n",
       "      <td id=\"T_ff34d_row1_col7\" class=\"data row1 col7\" >0.9903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ff34d_row2_col0\" class=\"data row2 col0\" >0.9682</td>\n",
       "      <td id=\"T_ff34d_row2_col1\" class=\"data row2 col1\" >0.9771</td>\n",
       "      <td id=\"T_ff34d_row2_col2\" class=\"data row2 col2\" >0.9091</td>\n",
       "      <td id=\"T_ff34d_row2_col3\" class=\"data row2 col3\" >0.8696</td>\n",
       "      <td id=\"T_ff34d_row2_col4\" class=\"data row2 col4\" >0.8889</td>\n",
       "      <td id=\"T_ff34d_row2_col5\" class=\"data row2 col5\" >0.8703</td>\n",
       "      <td id=\"T_ff34d_row2_col6\" class=\"data row2 col6\" >0.8706</td>\n",
       "      <td id=\"T_ff34d_row2_col7\" class=\"data row2 col7\" >0.9563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ff34d_row3_col0\" class=\"data row3 col0\" >0.9745</td>\n",
       "      <td id=\"T_ff34d_row3_col1\" class=\"data row3 col1\" >0.9796</td>\n",
       "      <td id=\"T_ff34d_row3_col2\" class=\"data row3 col2\" >0.8696</td>\n",
       "      <td id=\"T_ff34d_row3_col3\" class=\"data row3 col3\" >0.9524</td>\n",
       "      <td id=\"T_ff34d_row3_col4\" class=\"data row3 col4\" >0.9091</td>\n",
       "      <td id=\"T_ff34d_row3_col5\" class=\"data row3 col5\" >0.8943</td>\n",
       "      <td id=\"T_ff34d_row3_col6\" class=\"data row3 col6\" >0.8956</td>\n",
       "      <td id=\"T_ff34d_row3_col7\" class=\"data row3 col7\" >0.9524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ff34d_row4_col0\" class=\"data row4 col0\" >0.9936</td>\n",
       "      <td id=\"T_ff34d_row4_col1\" class=\"data row4 col1\" >1.0000</td>\n",
       "      <td id=\"T_ff34d_row4_col2\" class=\"data row4 col2\" >0.9565</td>\n",
       "      <td id=\"T_ff34d_row4_col3\" class=\"data row4 col3\" >1.0000</td>\n",
       "      <td id=\"T_ff34d_row4_col4\" class=\"data row4 col4\" >0.9778</td>\n",
       "      <td id=\"T_ff34d_row4_col5\" class=\"data row4 col5\" >0.9741</td>\n",
       "      <td id=\"T_ff34d_row4_col6\" class=\"data row4 col6\" >0.9744</td>\n",
       "      <td id=\"T_ff34d_row4_col7\" class=\"data row4 col7\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ff34d_row5_col0\" class=\"data row5 col0\" >0.9744</td>\n",
       "      <td id=\"T_ff34d_row5_col1\" class=\"data row5 col1\" >0.9742</td>\n",
       "      <td id=\"T_ff34d_row5_col2\" class=\"data row5 col2\" >0.8636</td>\n",
       "      <td id=\"T_ff34d_row5_col3\" class=\"data row5 col3\" >0.9500</td>\n",
       "      <td id=\"T_ff34d_row5_col4\" class=\"data row5 col4\" >0.9048</td>\n",
       "      <td id=\"T_ff34d_row5_col5\" class=\"data row5 col5\" >0.8900</td>\n",
       "      <td id=\"T_ff34d_row5_col6\" class=\"data row5 col6\" >0.8913</td>\n",
       "      <td id=\"T_ff34d_row5_col7\" class=\"data row5 col7\" >0.9523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ff34d_row6_col0\" class=\"data row6 col0\" >0.9744</td>\n",
       "      <td id=\"T_ff34d_row6_col1\" class=\"data row6 col1\" >0.9657</td>\n",
       "      <td id=\"T_ff34d_row6_col2\" class=\"data row6 col2\" >0.8636</td>\n",
       "      <td id=\"T_ff34d_row6_col3\" class=\"data row6 col3\" >0.9500</td>\n",
       "      <td id=\"T_ff34d_row6_col4\" class=\"data row6 col4\" >0.9048</td>\n",
       "      <td id=\"T_ff34d_row6_col5\" class=\"data row6 col5\" >0.8900</td>\n",
       "      <td id=\"T_ff34d_row6_col6\" class=\"data row6 col6\" >0.8913</td>\n",
       "      <td id=\"T_ff34d_row6_col7\" class=\"data row6 col7\" >0.9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ff34d_row7_col0\" class=\"data row7 col0\" >0.9744</td>\n",
       "      <td id=\"T_ff34d_row7_col1\" class=\"data row7 col1\" >0.9969</td>\n",
       "      <td id=\"T_ff34d_row7_col2\" class=\"data row7 col2\" >0.8182</td>\n",
       "      <td id=\"T_ff34d_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_ff34d_row7_col4\" class=\"data row7 col4\" >0.9000</td>\n",
       "      <td id=\"T_ff34d_row7_col5\" class=\"data row7 col5\" >0.8855</td>\n",
       "      <td id=\"T_ff34d_row7_col6\" class=\"data row7 col6\" >0.8913</td>\n",
       "      <td id=\"T_ff34d_row7_col7\" class=\"data row7 col7\" >0.9838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ff34d_row8_col0\" class=\"data row8 col0\" >0.9679</td>\n",
       "      <td id=\"T_ff34d_row8_col1\" class=\"data row8 col1\" >0.9691</td>\n",
       "      <td id=\"T_ff34d_row8_col2\" class=\"data row8 col2\" >0.7727</td>\n",
       "      <td id=\"T_ff34d_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_ff34d_row8_col4\" class=\"data row8 col4\" >0.8718</td>\n",
       "      <td id=\"T_ff34d_row8_col5\" class=\"data row8 col5\" >0.8538</td>\n",
       "      <td id=\"T_ff34d_row8_col6\" class=\"data row8 col6\" >0.8631</td>\n",
       "      <td id=\"T_ff34d_row8_col7\" class=\"data row8 col7\" >0.8962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ff34d_row9_col0\" class=\"data row9 col0\" >0.9808</td>\n",
       "      <td id=\"T_ff34d_row9_col1\" class=\"data row9 col1\" >0.9763</td>\n",
       "      <td id=\"T_ff34d_row9_col2\" class=\"data row9 col2\" >0.8636</td>\n",
       "      <td id=\"T_ff34d_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_ff34d_row9_col4\" class=\"data row9 col4\" >0.9268</td>\n",
       "      <td id=\"T_ff34d_row9_col5\" class=\"data row9 col5\" >0.9158</td>\n",
       "      <td id=\"T_ff34d_row9_col6\" class=\"data row9 col6\" >0.9191</td>\n",
       "      <td id=\"T_ff34d_row9_col7\" class=\"data row9 col7\" >0.9381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_ff34d_row10_col0\" class=\"data row10 col0\" >0.9770</td>\n",
       "      <td id=\"T_ff34d_row10_col1\" class=\"data row10 col1\" >0.9820</td>\n",
       "      <td id=\"T_ff34d_row10_col2\" class=\"data row10 col2\" >0.8690</td>\n",
       "      <td id=\"T_ff34d_row10_col3\" class=\"data row10 col3\" >0.9676</td>\n",
       "      <td id=\"T_ff34d_row10_col4\" class=\"data row10 col4\" >0.9138</td>\n",
       "      <td id=\"T_ff34d_row10_col5\" class=\"data row10 col5\" >0.9006</td>\n",
       "      <td id=\"T_ff34d_row10_col6\" class=\"data row10 col6\" >0.9035</td>\n",
       "      <td id=\"T_ff34d_row10_col7\" class=\"data row10 col7\" >0.9546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ff34d_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_ff34d_row11_col0\" class=\"data row11 col0\" >0.0077</td>\n",
       "      <td id=\"T_ff34d_row11_col1\" class=\"data row11 col1\" >0.0117</td>\n",
       "      <td id=\"T_ff34d_row11_col2\" class=\"data row11 col2\" >0.0558</td>\n",
       "      <td id=\"T_ff34d_row11_col3\" class=\"data row11 col3\" >0.0399</td>\n",
       "      <td id=\"T_ff34d_row11_col4\" class=\"data row11 col4\" >0.0298</td>\n",
       "      <td id=\"T_ff34d_row11_col5\" class=\"data row11 col5\" >0.0341</td>\n",
       "      <td id=\"T_ff34d_row11_col6\" class=\"data row11 col6\" >0.0325</td>\n",
       "      <td id=\"T_ff34d_row11_col7\" class=\"data row11 col7\" >0.0297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x119259c8070>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {\"max_depth\": np.random.randint(1, 40, 10),\n",
    "          \"n_estimators\": np.random.randint(2, 1000, 10)}\n",
    "          \n",
    "# tune model\n",
    "tuned_dt = tune_model(best, custom_grid = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=8, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=559, n_jobs=-1,\n",
       "                     oob_score=False, random_state=1910, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3a545\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3a545_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_3a545_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_3a545_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_3a545_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_3a545_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_3a545_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_3a545_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_3a545_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_3a545_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3a545_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3a545_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_3a545_row0_col1\" class=\"data row0 col1\" >0.9746</td>\n",
       "      <td id=\"T_3a545_row0_col2\" class=\"data row0 col2\" >0.9783</td>\n",
       "      <td id=\"T_3a545_row0_col3\" class=\"data row0 col3\" >0.8772</td>\n",
       "      <td id=\"T_3a545_row0_col4\" class=\"data row0 col4\" >0.9554</td>\n",
       "      <td id=\"T_3a545_row0_col5\" class=\"data row0 col5\" >0.9146</td>\n",
       "      <td id=\"T_3a545_row0_col6\" class=\"data row0 col6\" >0.8998</td>\n",
       "      <td id=\"T_3a545_row0_col7\" class=\"data row0 col7\" >0.9009</td>\n",
       "      <td id=\"T_3a545_row0_col8\" class=\"data row0 col8\" >0.9544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11924082ac0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = predict_model(tuned_dt, data=df_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c40b8 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c40b8_row0_col0, #T_c40b8_row0_col1, #T_c40b8_row0_col3, #T_c40b8_row0_col5, #T_c40b8_row0_col6, #T_c40b8_row0_col7, #T_c40b8_row1_col0, #T_c40b8_row1_col1, #T_c40b8_row1_col2, #T_c40b8_row1_col3, #T_c40b8_row1_col4, #T_c40b8_row1_col5, #T_c40b8_row1_col6, #T_c40b8_row1_col7, #T_c40b8_row1_col8, #T_c40b8_row2_col0, #T_c40b8_row2_col2, #T_c40b8_row2_col3, #T_c40b8_row2_col4, #T_c40b8_row2_col8, #T_c40b8_row3_col0, #T_c40b8_row3_col1, #T_c40b8_row3_col2, #T_c40b8_row3_col3, #T_c40b8_row3_col4, #T_c40b8_row3_col5, #T_c40b8_row3_col6, #T_c40b8_row3_col7, #T_c40b8_row3_col8, #T_c40b8_row4_col0, #T_c40b8_row4_col1, #T_c40b8_row4_col2, #T_c40b8_row4_col4, #T_c40b8_row4_col5, #T_c40b8_row4_col6, #T_c40b8_row4_col7, #T_c40b8_row4_col8, #T_c40b8_row5_col0, #T_c40b8_row5_col1, #T_c40b8_row5_col2, #T_c40b8_row5_col3, #T_c40b8_row5_col4, #T_c40b8_row5_col5, #T_c40b8_row5_col6, #T_c40b8_row5_col7, #T_c40b8_row5_col8, #T_c40b8_row6_col0, #T_c40b8_row6_col1, #T_c40b8_row6_col2, #T_c40b8_row6_col3, #T_c40b8_row6_col4, #T_c40b8_row6_col5, #T_c40b8_row6_col6, #T_c40b8_row6_col7, #T_c40b8_row6_col8, #T_c40b8_row7_col0, #T_c40b8_row7_col1, #T_c40b8_row7_col2, #T_c40b8_row7_col3, #T_c40b8_row7_col4, #T_c40b8_row7_col5, #T_c40b8_row7_col6, #T_c40b8_row7_col7, #T_c40b8_row7_col8, #T_c40b8_row8_col0, #T_c40b8_row8_col1, #T_c40b8_row8_col2, #T_c40b8_row8_col3, #T_c40b8_row8_col4, #T_c40b8_row8_col5, #T_c40b8_row8_col6, #T_c40b8_row8_col7, #T_c40b8_row8_col8, #T_c40b8_row9_col0, #T_c40b8_row9_col1, #T_c40b8_row9_col2, #T_c40b8_row9_col3, #T_c40b8_row9_col4, #T_c40b8_row9_col5, #T_c40b8_row9_col6, #T_c40b8_row9_col7, #T_c40b8_row9_col8, #T_c40b8_row10_col0, #T_c40b8_row10_col1, #T_c40b8_row10_col2, #T_c40b8_row10_col3, #T_c40b8_row10_col4, #T_c40b8_row10_col5, #T_c40b8_row10_col6, #T_c40b8_row10_col7, #T_c40b8_row10_col8, #T_c40b8_row11_col0, #T_c40b8_row11_col1, #T_c40b8_row11_col2, #T_c40b8_row11_col3, #T_c40b8_row11_col4, #T_c40b8_row11_col5, #T_c40b8_row11_col6, #T_c40b8_row11_col7, #T_c40b8_row11_col8, #T_c40b8_row12_col0, #T_c40b8_row12_col1, #T_c40b8_row12_col2, #T_c40b8_row12_col3, #T_c40b8_row12_col4, #T_c40b8_row12_col5, #T_c40b8_row12_col6, #T_c40b8_row12_col7, #T_c40b8_row12_col8, #T_c40b8_row13_col0, #T_c40b8_row13_col1, #T_c40b8_row13_col2, #T_c40b8_row13_col3, #T_c40b8_row13_col4, #T_c40b8_row13_col5, #T_c40b8_row13_col6, #T_c40b8_row13_col7, #T_c40b8_row13_col8 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_c40b8_row0_col2, #T_c40b8_row0_col4, #T_c40b8_row0_col8, #T_c40b8_row2_col1, #T_c40b8_row2_col5, #T_c40b8_row2_col6, #T_c40b8_row2_col7, #T_c40b8_row4_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_c40b8_row0_col9, #T_c40b8_row1_col9, #T_c40b8_row2_col9, #T_c40b8_row3_col9, #T_c40b8_row4_col9, #T_c40b8_row5_col9, #T_c40b8_row6_col9, #T_c40b8_row7_col9, #T_c40b8_row8_col9, #T_c40b8_row9_col9, #T_c40b8_row10_col9, #T_c40b8_row12_col9, #T_c40b8_row13_col9 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_c40b8_row11_col9 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c40b8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c40b8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_c40b8_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_c40b8_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_c40b8_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_c40b8_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_c40b8_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_c40b8_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_c40b8_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_c40b8_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "      <th id=\"T_c40b8_level0_col9\" class=\"col_heading level0 col9\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row0\" class=\"row_heading level0 row0\" >et</th>\n",
       "      <td id=\"T_c40b8_row0_col0\" class=\"data row0 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_c40b8_row0_col1\" class=\"data row0 col1\" >0.9763</td>\n",
       "      <td id=\"T_c40b8_row0_col2\" class=\"data row0 col2\" >0.9836</td>\n",
       "      <td id=\"T_c40b8_row0_col3\" class=\"data row0 col3\" >0.8733</td>\n",
       "      <td id=\"T_c40b8_row0_col4\" class=\"data row0 col4\" >0.9597</td>\n",
       "      <td id=\"T_c40b8_row0_col5\" class=\"data row0 col5\" >0.9122</td>\n",
       "      <td id=\"T_c40b8_row0_col6\" class=\"data row0 col6\" >0.8986</td>\n",
       "      <td id=\"T_c40b8_row0_col7\" class=\"data row0 col7\" >0.9014</td>\n",
       "      <td id=\"T_c40b8_row0_col8\" class=\"data row0 col8\" >0.9547</td>\n",
       "      <td id=\"T_c40b8_row0_col9\" class=\"data row0 col9\" >0.2950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_c40b8_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_c40b8_row1_col1\" class=\"data row1 col1\" >0.9712</td>\n",
       "      <td id=\"T_c40b8_row1_col2\" class=\"data row1 col2\" >0.9809</td>\n",
       "      <td id=\"T_c40b8_row1_col3\" class=\"data row1 col3\" >0.8779</td>\n",
       "      <td id=\"T_c40b8_row1_col4\" class=\"data row1 col4\" >0.9191</td>\n",
       "      <td id=\"T_c40b8_row1_col5\" class=\"data row1 col5\" >0.8963</td>\n",
       "      <td id=\"T_c40b8_row1_col6\" class=\"data row1 col6\" >0.8796</td>\n",
       "      <td id=\"T_c40b8_row1_col7\" class=\"data row1 col7\" >0.8810</td>\n",
       "      <td id=\"T_c40b8_row1_col8\" class=\"data row1 col8\" >0.9530</td>\n",
       "      <td id=\"T_c40b8_row1_col9\" class=\"data row1 col9\" >0.2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_c40b8_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_c40b8_row2_col1\" class=\"data row2 col1\" >0.9764</td>\n",
       "      <td id=\"T_c40b8_row2_col2\" class=\"data row2 col2\" >0.9798</td>\n",
       "      <td id=\"T_c40b8_row2_col3\" class=\"data row2 col3\" >0.8872</td>\n",
       "      <td id=\"T_c40b8_row2_col4\" class=\"data row2 col4\" >0.9457</td>\n",
       "      <td id=\"T_c40b8_row2_col5\" class=\"data row2 col5\" >0.9139</td>\n",
       "      <td id=\"T_c40b8_row2_col6\" class=\"data row2 col6\" >0.9003</td>\n",
       "      <td id=\"T_c40b8_row2_col7\" class=\"data row2 col7\" >0.9019</td>\n",
       "      <td id=\"T_c40b8_row2_col8\" class=\"data row2 col8\" >0.9514</td>\n",
       "      <td id=\"T_c40b8_row2_col9\" class=\"data row2 col9\" >0.4780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row3\" class=\"row_heading level0 row3\" >gbc</th>\n",
       "      <td id=\"T_c40b8_row3_col0\" class=\"data row3 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_c40b8_row3_col1\" class=\"data row3 col1\" >0.9668</td>\n",
       "      <td id=\"T_c40b8_row3_col2\" class=\"data row3 col2\" >0.9778</td>\n",
       "      <td id=\"T_c40b8_row3_col3\" class=\"data row3 col3\" >0.8824</td>\n",
       "      <td id=\"T_c40b8_row3_col4\" class=\"data row3 col4\" >0.8884</td>\n",
       "      <td id=\"T_c40b8_row3_col5\" class=\"data row3 col5\" >0.8832</td>\n",
       "      <td id=\"T_c40b8_row3_col6\" class=\"data row3 col6\" >0.8639</td>\n",
       "      <td id=\"T_c40b8_row3_col7\" class=\"data row3 col7\" >0.8653</td>\n",
       "      <td id=\"T_c40b8_row3_col8\" class=\"data row3 col8\" >0.9500</td>\n",
       "      <td id=\"T_c40b8_row3_col9\" class=\"data row3 col9\" >1.2180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_c40b8_row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_c40b8_row4_col1\" class=\"data row4 col1\" >0.9642</td>\n",
       "      <td id=\"T_c40b8_row4_col2\" class=\"data row4 col2\" >0.9739</td>\n",
       "      <td id=\"T_c40b8_row4_col3\" class=\"data row4 col3\" >0.9231</td>\n",
       "      <td id=\"T_c40b8_row4_col4\" class=\"data row4 col4\" >0.8454</td>\n",
       "      <td id=\"T_c40b8_row4_col5\" class=\"data row4 col5\" >0.8805</td>\n",
       "      <td id=\"T_c40b8_row4_col6\" class=\"data row4 col6\" >0.8596</td>\n",
       "      <td id=\"T_c40b8_row4_col7\" class=\"data row4 col7\" >0.8622</td>\n",
       "      <td id=\"T_c40b8_row4_col8\" class=\"data row4 col8\" >0.9482</td>\n",
       "      <td id=\"T_c40b8_row4_col9\" class=\"data row4 col9\" >0.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row5\" class=\"row_heading level0 row5\" >lr</th>\n",
       "      <td id=\"T_c40b8_row5_col0\" class=\"data row5 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_c40b8_row5_col1\" class=\"data row5 col1\" >0.9533</td>\n",
       "      <td id=\"T_c40b8_row5_col2\" class=\"data row5 col2\" >0.9747</td>\n",
       "      <td id=\"T_c40b8_row5_col3\" class=\"data row5 col3\" >0.9142</td>\n",
       "      <td id=\"T_c40b8_row5_col4\" class=\"data row5 col4\" >0.7941</td>\n",
       "      <td id=\"T_c40b8_row5_col5\" class=\"data row5 col5\" >0.8489</td>\n",
       "      <td id=\"T_c40b8_row5_col6\" class=\"data row5 col6\" >0.8216</td>\n",
       "      <td id=\"T_c40b8_row5_col7\" class=\"data row5 col7\" >0.8251</td>\n",
       "      <td id=\"T_c40b8_row5_col8\" class=\"data row5 col8\" >0.9450</td>\n",
       "      <td id=\"T_c40b8_row5_col9\" class=\"data row5 col9\" >0.0770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row6\" class=\"row_heading level0 row6\" >lda</th>\n",
       "      <td id=\"T_c40b8_row6_col0\" class=\"data row6 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_c40b8_row6_col1\" class=\"data row6 col1\" >0.9623</td>\n",
       "      <td id=\"T_c40b8_row6_col2\" class=\"data row6 col2\" >0.9757</td>\n",
       "      <td id=\"T_c40b8_row6_col3\" class=\"data row6 col3\" >0.8913</td>\n",
       "      <td id=\"T_c40b8_row6_col4\" class=\"data row6 col4\" >0.8547</td>\n",
       "      <td id=\"T_c40b8_row6_col5\" class=\"data row6 col5\" >0.8700</td>\n",
       "      <td id=\"T_c40b8_row6_col6\" class=\"data row6 col6\" >0.8481</td>\n",
       "      <td id=\"T_c40b8_row6_col7\" class=\"data row6 col7\" >0.8500</td>\n",
       "      <td id=\"T_c40b8_row6_col8\" class=\"data row6 col8\" >0.9379</td>\n",
       "      <td id=\"T_c40b8_row6_col9\" class=\"data row6 col9\" >0.0280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row7\" class=\"row_heading level0 row7\" >qda</th>\n",
       "      <td id=\"T_c40b8_row7_col0\" class=\"data row7 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_c40b8_row7_col1\" class=\"data row7 col1\" >0.9655</td>\n",
       "      <td id=\"T_c40b8_row7_col2\" class=\"data row7 col2\" >0.9479</td>\n",
       "      <td id=\"T_c40b8_row7_col3\" class=\"data row7 col3\" >0.8599</td>\n",
       "      <td id=\"T_c40b8_row7_col4\" class=\"data row7 col4\" >0.8997</td>\n",
       "      <td id=\"T_c40b8_row7_col5\" class=\"data row7 col5\" >0.8756</td>\n",
       "      <td id=\"T_c40b8_row7_col6\" class=\"data row7 col6\" >0.8557</td>\n",
       "      <td id=\"T_c40b8_row7_col7\" class=\"data row7 col7\" >0.8584</td>\n",
       "      <td id=\"T_c40b8_row7_col8\" class=\"data row7 col8\" >0.8888</td>\n",
       "      <td id=\"T_c40b8_row7_col9\" class=\"data row7 col9\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row8\" class=\"row_heading level0 row8\" >knn</th>\n",
       "      <td id=\"T_c40b8_row8_col0\" class=\"data row8 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_c40b8_row8_col1\" class=\"data row8 col1\" >0.9521</td>\n",
       "      <td id=\"T_c40b8_row8_col2\" class=\"data row8 col2\" >0.9644</td>\n",
       "      <td id=\"T_c40b8_row8_col3\" class=\"data row8 col3\" >0.9095</td>\n",
       "      <td id=\"T_c40b8_row8_col4\" class=\"data row8 col4\" >0.7916</td>\n",
       "      <td id=\"T_c40b8_row8_col5\" class=\"data row8 col5\" >0.8443</td>\n",
       "      <td id=\"T_c40b8_row8_col6\" class=\"data row8 col6\" >0.8162</td>\n",
       "      <td id=\"T_c40b8_row8_col7\" class=\"data row8 col7\" >0.8205</td>\n",
       "      <td id=\"T_c40b8_row8_col8\" class=\"data row8 col8\" >0.8779</td>\n",
       "      <td id=\"T_c40b8_row8_col9\" class=\"data row8 col9\" >0.0670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row9\" class=\"row_heading level0 row9\" >nb</th>\n",
       "      <td id=\"T_c40b8_row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_c40b8_row9_col1\" class=\"data row9 col1\" >0.9655</td>\n",
       "      <td id=\"T_c40b8_row9_col2\" class=\"data row9 col2\" >0.9729</td>\n",
       "      <td id=\"T_c40b8_row9_col3\" class=\"data row9 col3\" >0.8733</td>\n",
       "      <td id=\"T_c40b8_row9_col4\" class=\"data row9 col4\" >0.8841</td>\n",
       "      <td id=\"T_c40b8_row9_col5\" class=\"data row9 col5\" >0.8767</td>\n",
       "      <td id=\"T_c40b8_row9_col6\" class=\"data row9 col6\" >0.8567</td>\n",
       "      <td id=\"T_c40b8_row9_col7\" class=\"data row9 col7\" >0.8580</td>\n",
       "      <td id=\"T_c40b8_row9_col8\" class=\"data row9 col8\" >0.8690</td>\n",
       "      <td id=\"T_c40b8_row9_col9\" class=\"data row9 col9\" >0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_c40b8_row10_col0\" class=\"data row10 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_c40b8_row10_col1\" class=\"data row10 col1\" >0.9489</td>\n",
       "      <td id=\"T_c40b8_row10_col2\" class=\"data row10 col2\" >0.9231</td>\n",
       "      <td id=\"T_c40b8_row10_col3\" class=\"data row10 col3\" >0.8872</td>\n",
       "      <td id=\"T_c40b8_row10_col4\" class=\"data row10 col4\" >0.7905</td>\n",
       "      <td id=\"T_c40b8_row10_col5\" class=\"data row10 col5\" >0.8323</td>\n",
       "      <td id=\"T_c40b8_row10_col6\" class=\"data row10 col6\" >0.8025</td>\n",
       "      <td id=\"T_c40b8_row10_col7\" class=\"data row10 col7\" >0.8068</td>\n",
       "      <td id=\"T_c40b8_row10_col8\" class=\"data row10 col8\" >0.7150</td>\n",
       "      <td id=\"T_c40b8_row10_col9\" class=\"data row10 col9\" >0.0420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row11\" class=\"row_heading level0 row11\" >dummy</th>\n",
       "      <td id=\"T_c40b8_row11_col0\" class=\"data row11 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_c40b8_row11_col1\" class=\"data row11 col1\" >0.8581</td>\n",
       "      <td id=\"T_c40b8_row11_col2\" class=\"data row11 col2\" >0.5000</td>\n",
       "      <td id=\"T_c40b8_row11_col3\" class=\"data row11 col3\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row11_col4\" class=\"data row11 col4\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row11_col5\" class=\"data row11 col5\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row11_col6\" class=\"data row11 col6\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row11_col7\" class=\"data row11 col7\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row11_col8\" class=\"data row11 col8\" >0.1419</td>\n",
       "      <td id=\"T_c40b8_row11_col9\" class=\"data row11 col9\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n",
       "      <td id=\"T_c40b8_row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_c40b8_row12_col1\" class=\"data row12 col1\" >0.9393</td>\n",
       "      <td id=\"T_c40b8_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row12_col3\" class=\"data row12 col3\" >0.8917</td>\n",
       "      <td id=\"T_c40b8_row12_col4\" class=\"data row12 col4\" >0.7510</td>\n",
       "      <td id=\"T_c40b8_row12_col5\" class=\"data row12 col5\" >0.8109</td>\n",
       "      <td id=\"T_c40b8_row12_col6\" class=\"data row12 col6\" >0.7756</td>\n",
       "      <td id=\"T_c40b8_row12_col7\" class=\"data row12 col7\" >0.7826</td>\n",
       "      <td id=\"T_c40b8_row12_col8\" class=\"data row12 col8\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row12_col9\" class=\"data row12 col9\" >0.0230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c40b8_level0_row13\" class=\"row_heading level0 row13\" >ridge</th>\n",
       "      <td id=\"T_c40b8_row13_col0\" class=\"data row13 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_c40b8_row13_col1\" class=\"data row13 col1\" >0.9623</td>\n",
       "      <td id=\"T_c40b8_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row13_col3\" class=\"data row13 col3\" >0.8913</td>\n",
       "      <td id=\"T_c40b8_row13_col4\" class=\"data row13 col4\" >0.8547</td>\n",
       "      <td id=\"T_c40b8_row13_col5\" class=\"data row13 col5\" >0.8700</td>\n",
       "      <td id=\"T_c40b8_row13_col6\" class=\"data row13 col6\" >0.8481</td>\n",
       "      <td id=\"T_c40b8_row13_col7\" class=\"data row13 col7\" >0.8500</td>\n",
       "      <td id=\"T_c40b8_row13_col8\" class=\"data row13 col8\" >0.0000</td>\n",
       "      <td id=\"T_c40b8_row13_col9\" class=\"data row13 col9\" >0.0200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11928dccfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                      criterion='gini', max_depth=None, max_features='auto',\n",
       "                      max_leaf_nodes=None, max_samples=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                      oob_score=False, random_state=1910, verbose=0,\n",
       "                      warm_start=False),\n",
       " LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "                importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "                min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "                n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "                random_state=1910, reg_alpha=0.0, reg_lambda=0.0, silent='warn',\n",
       "                subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       " RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=-1, oob_score=False, random_state=1910, verbose=0,\n",
       "                        warm_start=False)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops= compare_models(n_select = 3, sort=\"APC\")\n",
    "tops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "                     oob_score=False, random_state=1910, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tops[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_81c73_row10_col0, #T_81c73_row10_col1, #T_81c73_row10_col2, #T_81c73_row10_col3, #T_81c73_row10_col4, #T_81c73_row10_col5, #T_81c73_row10_col6, #T_81c73_row10_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_81c73\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_81c73_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_81c73_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_81c73_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_81c73_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_81c73_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_81c73_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_81c73_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_81c73_level0_col7\" class=\"col_heading level0 col7\" >APC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_81c73_row0_col0\" class=\"data row0 col0\" >0.9745</td>\n",
       "      <td id=\"T_81c73_row0_col1\" class=\"data row0 col1\" >0.9929</td>\n",
       "      <td id=\"T_81c73_row0_col2\" class=\"data row0 col2\" >0.8182</td>\n",
       "      <td id=\"T_81c73_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_81c73_row0_col4\" class=\"data row0 col4\" >0.9000</td>\n",
       "      <td id=\"T_81c73_row0_col5\" class=\"data row0 col5\" >0.8856</td>\n",
       "      <td id=\"T_81c73_row0_col6\" class=\"data row0 col6\" >0.8914</td>\n",
       "      <td id=\"T_81c73_row0_col7\" class=\"data row0 col7\" >0.9739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_81c73_row1_col0\" class=\"data row1 col0\" >0.9873</td>\n",
       "      <td id=\"T_81c73_row1_col1\" class=\"data row1 col1\" >0.9966</td>\n",
       "      <td id=\"T_81c73_row1_col2\" class=\"data row1 col2\" >0.9545</td>\n",
       "      <td id=\"T_81c73_row1_col3\" class=\"data row1 col3\" >0.9545</td>\n",
       "      <td id=\"T_81c73_row1_col4\" class=\"data row1 col4\" >0.9545</td>\n",
       "      <td id=\"T_81c73_row1_col5\" class=\"data row1 col5\" >0.9471</td>\n",
       "      <td id=\"T_81c73_row1_col6\" class=\"data row1 col6\" >0.9471</td>\n",
       "      <td id=\"T_81c73_row1_col7\" class=\"data row1 col7\" >0.9858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_81c73_row2_col0\" class=\"data row2 col0\" >0.9682</td>\n",
       "      <td id=\"T_81c73_row2_col1\" class=\"data row2 col1\" >0.9842</td>\n",
       "      <td id=\"T_81c73_row2_col2\" class=\"data row2 col2\" >0.9091</td>\n",
       "      <td id=\"T_81c73_row2_col3\" class=\"data row2 col3\" >0.8696</td>\n",
       "      <td id=\"T_81c73_row2_col4\" class=\"data row2 col4\" >0.8889</td>\n",
       "      <td id=\"T_81c73_row2_col5\" class=\"data row2 col5\" >0.8703</td>\n",
       "      <td id=\"T_81c73_row2_col6\" class=\"data row2 col6\" >0.8706</td>\n",
       "      <td id=\"T_81c73_row2_col7\" class=\"data row2 col7\" >0.9548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_81c73_row3_col0\" class=\"data row3 col0\" >0.9745</td>\n",
       "      <td id=\"T_81c73_row3_col1\" class=\"data row3 col1\" >0.9737</td>\n",
       "      <td id=\"T_81c73_row3_col2\" class=\"data row3 col2\" >0.9130</td>\n",
       "      <td id=\"T_81c73_row3_col3\" class=\"data row3 col3\" >0.9130</td>\n",
       "      <td id=\"T_81c73_row3_col4\" class=\"data row3 col4\" >0.9130</td>\n",
       "      <td id=\"T_81c73_row3_col5\" class=\"data row3 col5\" >0.8981</td>\n",
       "      <td id=\"T_81c73_row3_col6\" class=\"data row3 col6\" >0.8981</td>\n",
       "      <td id=\"T_81c73_row3_col7\" class=\"data row3 col7\" >0.9441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_81c73_row4_col0\" class=\"data row4 col0\" >0.9873</td>\n",
       "      <td id=\"T_81c73_row4_col1\" class=\"data row4 col1\" >0.9997</td>\n",
       "      <td id=\"T_81c73_row4_col2\" class=\"data row4 col2\" >0.9565</td>\n",
       "      <td id=\"T_81c73_row4_col3\" class=\"data row4 col3\" >0.9565</td>\n",
       "      <td id=\"T_81c73_row4_col4\" class=\"data row4 col4\" >0.9565</td>\n",
       "      <td id=\"T_81c73_row4_col5\" class=\"data row4 col5\" >0.9491</td>\n",
       "      <td id=\"T_81c73_row4_col6\" class=\"data row4 col6\" >0.9491</td>\n",
       "      <td id=\"T_81c73_row4_col7\" class=\"data row4 col7\" >0.9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_81c73_row5_col0\" class=\"data row5 col0\" >0.9808</td>\n",
       "      <td id=\"T_81c73_row5_col1\" class=\"data row5 col1\" >0.9695</td>\n",
       "      <td id=\"T_81c73_row5_col2\" class=\"data row5 col2\" >0.9091</td>\n",
       "      <td id=\"T_81c73_row5_col3\" class=\"data row5 col3\" >0.9524</td>\n",
       "      <td id=\"T_81c73_row5_col4\" class=\"data row5 col4\" >0.9302</td>\n",
       "      <td id=\"T_81c73_row5_col5\" class=\"data row5 col5\" >0.9191</td>\n",
       "      <td id=\"T_81c73_row5_col6\" class=\"data row5 col6\" >0.9194</td>\n",
       "      <td id=\"T_81c73_row5_col7\" class=\"data row5 col7\" >0.9560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_81c73_row6_col0\" class=\"data row6 col0\" >0.9615</td>\n",
       "      <td id=\"T_81c73_row6_col1\" class=\"data row6 col1\" >0.9685</td>\n",
       "      <td id=\"T_81c73_row6_col2\" class=\"data row6 col2\" >0.8636</td>\n",
       "      <td id=\"T_81c73_row6_col3\" class=\"data row6 col3\" >0.8636</td>\n",
       "      <td id=\"T_81c73_row6_col4\" class=\"data row6 col4\" >0.8636</td>\n",
       "      <td id=\"T_81c73_row6_col5\" class=\"data row6 col5\" >0.8412</td>\n",
       "      <td id=\"T_81c73_row6_col6\" class=\"data row6 col6\" >0.8412</td>\n",
       "      <td id=\"T_81c73_row6_col7\" class=\"data row6 col7\" >0.9283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_81c73_row7_col0\" class=\"data row7 col0\" >0.9872</td>\n",
       "      <td id=\"T_81c73_row7_col1\" class=\"data row7 col1\" >0.9925</td>\n",
       "      <td id=\"T_81c73_row7_col2\" class=\"data row7 col2\" >0.9091</td>\n",
       "      <td id=\"T_81c73_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_81c73_row7_col4\" class=\"data row7 col4\" >0.9524</td>\n",
       "      <td id=\"T_81c73_row7_col5\" class=\"data row7 col5\" >0.9450</td>\n",
       "      <td id=\"T_81c73_row7_col6\" class=\"data row7 col6\" >0.9464</td>\n",
       "      <td id=\"T_81c73_row7_col7\" class=\"data row7 col7\" >0.9757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_81c73_row8_col0\" class=\"data row8 col0\" >0.9551</td>\n",
       "      <td id=\"T_81c73_row8_col1\" class=\"data row8 col1\" >0.9688</td>\n",
       "      <td id=\"T_81c73_row8_col2\" class=\"data row8 col2\" >0.7727</td>\n",
       "      <td id=\"T_81c73_row8_col3\" class=\"data row8 col3\" >0.8947</td>\n",
       "      <td id=\"T_81c73_row8_col4\" class=\"data row8 col4\" >0.8293</td>\n",
       "      <td id=\"T_81c73_row8_col5\" class=\"data row8 col5\" >0.8036</td>\n",
       "      <td id=\"T_81c73_row8_col6\" class=\"data row8 col6\" >0.8065</td>\n",
       "      <td id=\"T_81c73_row8_col7\" class=\"data row8 col7\" >0.8939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_81c73_row9_col0\" class=\"data row9 col0\" >0.9808</td>\n",
       "      <td id=\"T_81c73_row9_col1\" class=\"data row9 col1\" >0.9803</td>\n",
       "      <td id=\"T_81c73_row9_col2\" class=\"data row9 col2\" >0.8636</td>\n",
       "      <td id=\"T_81c73_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_81c73_row9_col4\" class=\"data row9 col4\" >0.9268</td>\n",
       "      <td id=\"T_81c73_row9_col5\" class=\"data row9 col5\" >0.9158</td>\n",
       "      <td id=\"T_81c73_row9_col6\" class=\"data row9 col6\" >0.9191</td>\n",
       "      <td id=\"T_81c73_row9_col7\" class=\"data row9 col7\" >0.9416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_81c73_row10_col0\" class=\"data row10 col0\" >0.9757</td>\n",
       "      <td id=\"T_81c73_row10_col1\" class=\"data row10 col1\" >0.9827</td>\n",
       "      <td id=\"T_81c73_row10_col2\" class=\"data row10 col2\" >0.8870</td>\n",
       "      <td id=\"T_81c73_row10_col3\" class=\"data row10 col3\" >0.9404</td>\n",
       "      <td id=\"T_81c73_row10_col4\" class=\"data row10 col4\" >0.9115</td>\n",
       "      <td id=\"T_81c73_row10_col5\" class=\"data row10 col5\" >0.8975</td>\n",
       "      <td id=\"T_81c73_row10_col6\" class=\"data row10 col6\" >0.8989</td>\n",
       "      <td id=\"T_81c73_row10_col7\" class=\"data row10 col7\" >0.9552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_81c73_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_81c73_row11_col0\" class=\"data row11 col0\" >0.0106</td>\n",
       "      <td id=\"T_81c73_row11_col1\" class=\"data row11 col1\" >0.0116</td>\n",
       "      <td id=\"T_81c73_row11_col2\" class=\"data row11 col2\" >0.0552</td>\n",
       "      <td id=\"T_81c73_row11_col3\" class=\"data row11 col3\" >0.0500</td>\n",
       "      <td id=\"T_81c73_row11_col4\" class=\"data row11 col4\" >0.0398</td>\n",
       "      <td id=\"T_81c73_row11_col5\" class=\"data row11 col5\" >0.0459</td>\n",
       "      <td id=\"T_81c73_row11_col6\" class=\"data row11 col6\" >0.0454</td>\n",
       "      <td id=\"T_81c73_row11_col7\" class=\"data row11 col7\" >0.0289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x119255ca640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blender_weighted = blend_models([tops[0],tops[1],tops[2]], weights = [0.5,0.3,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_8e9cd_row10_col0, #T_8e9cd_row10_col1, #T_8e9cd_row10_col2, #T_8e9cd_row10_col3, #T_8e9cd_row10_col4, #T_8e9cd_row10_col5, #T_8e9cd_row10_col6, #T_8e9cd_row10_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_8e9cd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8e9cd_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_8e9cd_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_8e9cd_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_8e9cd_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_8e9cd_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_8e9cd_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_8e9cd_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_8e9cd_level0_col7\" class=\"col_heading level0 col7\" >APC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_8e9cd_row0_col0\" class=\"data row0 col0\" >0.9745</td>\n",
       "      <td id=\"T_8e9cd_row0_col1\" class=\"data row0 col1\" >0.9923</td>\n",
       "      <td id=\"T_8e9cd_row0_col2\" class=\"data row0 col2\" >0.8182</td>\n",
       "      <td id=\"T_8e9cd_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row0_col4\" class=\"data row0 col4\" >0.9000</td>\n",
       "      <td id=\"T_8e9cd_row0_col5\" class=\"data row0 col5\" >0.8856</td>\n",
       "      <td id=\"T_8e9cd_row0_col6\" class=\"data row0 col6\" >0.8914</td>\n",
       "      <td id=\"T_8e9cd_row0_col7\" class=\"data row0 col7\" >0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_8e9cd_row1_col0\" class=\"data row1 col0\" >0.9936</td>\n",
       "      <td id=\"T_8e9cd_row1_col1\" class=\"data row1 col1\" >0.9970</td>\n",
       "      <td id=\"T_8e9cd_row1_col2\" class=\"data row1 col2\" >0.9545</td>\n",
       "      <td id=\"T_8e9cd_row1_col3\" class=\"data row1 col3\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row1_col4\" class=\"data row1 col4\" >0.9767</td>\n",
       "      <td id=\"T_8e9cd_row1_col5\" class=\"data row1 col5\" >0.9731</td>\n",
       "      <td id=\"T_8e9cd_row1_col6\" class=\"data row1 col6\" >0.9734</td>\n",
       "      <td id=\"T_8e9cd_row1_col7\" class=\"data row1 col7\" >0.9868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_8e9cd_row2_col0\" class=\"data row2 col0\" >0.9618</td>\n",
       "      <td id=\"T_8e9cd_row2_col1\" class=\"data row2 col1\" >0.9845</td>\n",
       "      <td id=\"T_8e9cd_row2_col2\" class=\"data row2 col2\" >0.9091</td>\n",
       "      <td id=\"T_8e9cd_row2_col3\" class=\"data row2 col3\" >0.8333</td>\n",
       "      <td id=\"T_8e9cd_row2_col4\" class=\"data row2 col4\" >0.8696</td>\n",
       "      <td id=\"T_8e9cd_row2_col5\" class=\"data row2 col5\" >0.8472</td>\n",
       "      <td id=\"T_8e9cd_row2_col6\" class=\"data row2 col6\" >0.8483</td>\n",
       "      <td id=\"T_8e9cd_row2_col7\" class=\"data row2 col7\" >0.9584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_8e9cd_row3_col0\" class=\"data row3 col0\" >0.9682</td>\n",
       "      <td id=\"T_8e9cd_row3_col1\" class=\"data row3 col1\" >0.9729</td>\n",
       "      <td id=\"T_8e9cd_row3_col2\" class=\"data row3 col2\" >0.8696</td>\n",
       "      <td id=\"T_8e9cd_row3_col3\" class=\"data row3 col3\" >0.9091</td>\n",
       "      <td id=\"T_8e9cd_row3_col4\" class=\"data row3 col4\" >0.8889</td>\n",
       "      <td id=\"T_8e9cd_row3_col5\" class=\"data row3 col5\" >0.8703</td>\n",
       "      <td id=\"T_8e9cd_row3_col6\" class=\"data row3 col6\" >0.8706</td>\n",
       "      <td id=\"T_8e9cd_row3_col7\" class=\"data row3 col7\" >0.9434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_8e9cd_row4_col0\" class=\"data row4 col0\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row4_col1\" class=\"data row4 col1\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row4_col2\" class=\"data row4 col2\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row4_col3\" class=\"data row4 col3\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row4_col4\" class=\"data row4 col4\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row4_col5\" class=\"data row4 col5\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row4_col6\" class=\"data row4 col6\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row4_col7\" class=\"data row4 col7\" >1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_8e9cd_row5_col0\" class=\"data row5 col0\" >0.9744</td>\n",
       "      <td id=\"T_8e9cd_row5_col1\" class=\"data row5 col1\" >0.9707</td>\n",
       "      <td id=\"T_8e9cd_row5_col2\" class=\"data row5 col2\" >0.8636</td>\n",
       "      <td id=\"T_8e9cd_row5_col3\" class=\"data row5 col3\" >0.9500</td>\n",
       "      <td id=\"T_8e9cd_row5_col4\" class=\"data row5 col4\" >0.9048</td>\n",
       "      <td id=\"T_8e9cd_row5_col5\" class=\"data row5 col5\" >0.8900</td>\n",
       "      <td id=\"T_8e9cd_row5_col6\" class=\"data row5 col6\" >0.8913</td>\n",
       "      <td id=\"T_8e9cd_row5_col7\" class=\"data row5 col7\" >0.9556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_8e9cd_row6_col0\" class=\"data row6 col0\" >0.9679</td>\n",
       "      <td id=\"T_8e9cd_row6_col1\" class=\"data row6 col1\" >0.9676</td>\n",
       "      <td id=\"T_8e9cd_row6_col2\" class=\"data row6 col2\" >0.8636</td>\n",
       "      <td id=\"T_8e9cd_row6_col3\" class=\"data row6 col3\" >0.9048</td>\n",
       "      <td id=\"T_8e9cd_row6_col4\" class=\"data row6 col4\" >0.8837</td>\n",
       "      <td id=\"T_8e9cd_row6_col5\" class=\"data row6 col5\" >0.8651</td>\n",
       "      <td id=\"T_8e9cd_row6_col6\" class=\"data row6 col6\" >0.8655</td>\n",
       "      <td id=\"T_8e9cd_row6_col7\" class=\"data row6 col7\" >0.9295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_8e9cd_row7_col0\" class=\"data row7 col0\" >0.9808</td>\n",
       "      <td id=\"T_8e9cd_row7_col1\" class=\"data row7 col1\" >0.9929</td>\n",
       "      <td id=\"T_8e9cd_row7_col2\" class=\"data row7 col2\" >0.8636</td>\n",
       "      <td id=\"T_8e9cd_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row7_col4\" class=\"data row7 col4\" >0.9268</td>\n",
       "      <td id=\"T_8e9cd_row7_col5\" class=\"data row7 col5\" >0.9158</td>\n",
       "      <td id=\"T_8e9cd_row7_col6\" class=\"data row7 col6\" >0.9191</td>\n",
       "      <td id=\"T_8e9cd_row7_col7\" class=\"data row7 col7\" >0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_8e9cd_row8_col0\" class=\"data row8 col0\" >0.9679</td>\n",
       "      <td id=\"T_8e9cd_row8_col1\" class=\"data row8 col1\" >0.9673</td>\n",
       "      <td id=\"T_8e9cd_row8_col2\" class=\"data row8 col2\" >0.7727</td>\n",
       "      <td id=\"T_8e9cd_row8_col3\" class=\"data row8 col3\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row8_col4\" class=\"data row8 col4\" >0.8718</td>\n",
       "      <td id=\"T_8e9cd_row8_col5\" class=\"data row8 col5\" >0.8538</td>\n",
       "      <td id=\"T_8e9cd_row8_col6\" class=\"data row8 col6\" >0.8631</td>\n",
       "      <td id=\"T_8e9cd_row8_col7\" class=\"data row8 col7\" >0.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_8e9cd_row9_col0\" class=\"data row9 col0\" >0.9808</td>\n",
       "      <td id=\"T_8e9cd_row9_col1\" class=\"data row9 col1\" >0.9802</td>\n",
       "      <td id=\"T_8e9cd_row9_col2\" class=\"data row9 col2\" >0.8636</td>\n",
       "      <td id=\"T_8e9cd_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_8e9cd_row9_col4\" class=\"data row9 col4\" >0.9268</td>\n",
       "      <td id=\"T_8e9cd_row9_col5\" class=\"data row9 col5\" >0.9158</td>\n",
       "      <td id=\"T_8e9cd_row9_col6\" class=\"data row9 col6\" >0.9191</td>\n",
       "      <td id=\"T_8e9cd_row9_col7\" class=\"data row9 col7\" >0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_8e9cd_row10_col0\" class=\"data row10 col0\" >0.9770</td>\n",
       "      <td id=\"T_8e9cd_row10_col1\" class=\"data row10 col1\" >0.9825</td>\n",
       "      <td id=\"T_8e9cd_row10_col2\" class=\"data row10 col2\" >0.8779</td>\n",
       "      <td id=\"T_8e9cd_row10_col3\" class=\"data row10 col3\" >0.9597</td>\n",
       "      <td id=\"T_8e9cd_row10_col4\" class=\"data row10 col4\" >0.9149</td>\n",
       "      <td id=\"T_8e9cd_row10_col5\" class=\"data row10 col5\" >0.9017</td>\n",
       "      <td id=\"T_8e9cd_row10_col6\" class=\"data row10 col6\" >0.9042</td>\n",
       "      <td id=\"T_8e9cd_row10_col7\" class=\"data row10 col7\" >0.9553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8e9cd_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_8e9cd_row11_col0\" class=\"data row11 col0\" >0.0115</td>\n",
       "      <td id=\"T_8e9cd_row11_col1\" class=\"data row11 col1\" >0.0119</td>\n",
       "      <td id=\"T_8e9cd_row11_col2\" class=\"data row11 col2\" >0.0610</td>\n",
       "      <td id=\"T_8e9cd_row11_col3\" class=\"data row11 col3\" >0.0560</td>\n",
       "      <td id=\"T_8e9cd_row11_col4\" class=\"data row11 col4\" >0.0415</td>\n",
       "      <td id=\"T_8e9cd_row11_col5\" class=\"data row11 col5\" >0.0481</td>\n",
       "      <td id=\"T_8e9cd_row11_col6\" class=\"data row11 col6\" >0.0471</td>\n",
       "      <td id=\"T_8e9cd_row11_col7\" class=\"data row11 col7\" >0.0299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1192413c2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tops= compare_models(n_select = 2)\n",
    "blender = blend_models(tops)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning with scikit-optimize on voting model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyCaret integrates seamlessly with many different libraries for hyperparameter tuning. This gives you access to many different types of search algorithms including random, bayesian, optuna, TPE, and a few others. All of this just by changing a parameter. By default, PyCaret using RandomGridSearch from the sklearn and you can change that by using search_library and search_algorithm parameter in the tune_model function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_25345_row10_col0, #T_25345_row10_col1, #T_25345_row10_col2, #T_25345_row10_col3, #T_25345_row10_col4, #T_25345_row10_col5, #T_25345_row10_col6, #T_25345_row10_col7 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_25345\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_25345_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_25345_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_25345_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_25345_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_25345_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_25345_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_25345_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "      <th id=\"T_25345_level0_col7\" class=\"col_heading level0 col7\" >APC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_25345_row0_col0\" class=\"data row0 col0\" >0.9745</td>\n",
       "      <td id=\"T_25345_row0_col1\" class=\"data row0 col1\" >0.9953</td>\n",
       "      <td id=\"T_25345_row0_col2\" class=\"data row0 col2\" >0.8182</td>\n",
       "      <td id=\"T_25345_row0_col3\" class=\"data row0 col3\" >1.0000</td>\n",
       "      <td id=\"T_25345_row0_col4\" class=\"data row0 col4\" >0.9000</td>\n",
       "      <td id=\"T_25345_row0_col5\" class=\"data row0 col5\" >0.8856</td>\n",
       "      <td id=\"T_25345_row0_col6\" class=\"data row0 col6\" >0.8914</td>\n",
       "      <td id=\"T_25345_row0_col7\" class=\"data row0 col7\" >0.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_25345_row1_col0\" class=\"data row1 col0\" >0.9936</td>\n",
       "      <td id=\"T_25345_row1_col1\" class=\"data row1 col1\" >0.9963</td>\n",
       "      <td id=\"T_25345_row1_col2\" class=\"data row1 col2\" >0.9545</td>\n",
       "      <td id=\"T_25345_row1_col3\" class=\"data row1 col3\" >1.0000</td>\n",
       "      <td id=\"T_25345_row1_col4\" class=\"data row1 col4\" >0.9767</td>\n",
       "      <td id=\"T_25345_row1_col5\" class=\"data row1 col5\" >0.9731</td>\n",
       "      <td id=\"T_25345_row1_col6\" class=\"data row1 col6\" >0.9734</td>\n",
       "      <td id=\"T_25345_row1_col7\" class=\"data row1 col7\" >0.9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_25345_row2_col0\" class=\"data row2 col0\" >0.9682</td>\n",
       "      <td id=\"T_25345_row2_col1\" class=\"data row2 col1\" >0.9916</td>\n",
       "      <td id=\"T_25345_row2_col2\" class=\"data row2 col2\" >0.9091</td>\n",
       "      <td id=\"T_25345_row2_col3\" class=\"data row2 col3\" >0.8696</td>\n",
       "      <td id=\"T_25345_row2_col4\" class=\"data row2 col4\" >0.8889</td>\n",
       "      <td id=\"T_25345_row2_col5\" class=\"data row2 col5\" >0.8703</td>\n",
       "      <td id=\"T_25345_row2_col6\" class=\"data row2 col6\" >0.8706</td>\n",
       "      <td id=\"T_25345_row2_col7\" class=\"data row2 col7\" >0.9688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_25345_row3_col0\" class=\"data row3 col0\" >0.9745</td>\n",
       "      <td id=\"T_25345_row3_col1\" class=\"data row3 col1\" >0.9776</td>\n",
       "      <td id=\"T_25345_row3_col2\" class=\"data row3 col2\" >0.9130</td>\n",
       "      <td id=\"T_25345_row3_col3\" class=\"data row3 col3\" >0.9130</td>\n",
       "      <td id=\"T_25345_row3_col4\" class=\"data row3 col4\" >0.9130</td>\n",
       "      <td id=\"T_25345_row3_col5\" class=\"data row3 col5\" >0.8981</td>\n",
       "      <td id=\"T_25345_row3_col6\" class=\"data row3 col6\" >0.8981</td>\n",
       "      <td id=\"T_25345_row3_col7\" class=\"data row3 col7\" >0.9497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_25345_row4_col0\" class=\"data row4 col0\" >0.9873</td>\n",
       "      <td id=\"T_25345_row4_col1\" class=\"data row4 col1\" >0.9997</td>\n",
       "      <td id=\"T_25345_row4_col2\" class=\"data row4 col2\" >0.9565</td>\n",
       "      <td id=\"T_25345_row4_col3\" class=\"data row4 col3\" >0.9565</td>\n",
       "      <td id=\"T_25345_row4_col4\" class=\"data row4 col4\" >0.9565</td>\n",
       "      <td id=\"T_25345_row4_col5\" class=\"data row4 col5\" >0.9491</td>\n",
       "      <td id=\"T_25345_row4_col6\" class=\"data row4 col6\" >0.9491</td>\n",
       "      <td id=\"T_25345_row4_col7\" class=\"data row4 col7\" >0.9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_25345_row5_col0\" class=\"data row5 col0\" >0.9744</td>\n",
       "      <td id=\"T_25345_row5_col1\" class=\"data row5 col1\" >0.9688</td>\n",
       "      <td id=\"T_25345_row5_col2\" class=\"data row5 col2\" >0.8636</td>\n",
       "      <td id=\"T_25345_row5_col3\" class=\"data row5 col3\" >0.9500</td>\n",
       "      <td id=\"T_25345_row5_col4\" class=\"data row5 col4\" >0.9048</td>\n",
       "      <td id=\"T_25345_row5_col5\" class=\"data row5 col5\" >0.8900</td>\n",
       "      <td id=\"T_25345_row5_col6\" class=\"data row5 col6\" >0.8913</td>\n",
       "      <td id=\"T_25345_row5_col7\" class=\"data row5 col7\" >0.9543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_25345_row6_col0\" class=\"data row6 col0\" >0.9615</td>\n",
       "      <td id=\"T_25345_row6_col1\" class=\"data row6 col1\" >0.9695</td>\n",
       "      <td id=\"T_25345_row6_col2\" class=\"data row6 col2\" >0.8636</td>\n",
       "      <td id=\"T_25345_row6_col3\" class=\"data row6 col3\" >0.8636</td>\n",
       "      <td id=\"T_25345_row6_col4\" class=\"data row6 col4\" >0.8636</td>\n",
       "      <td id=\"T_25345_row6_col5\" class=\"data row6 col5\" >0.8412</td>\n",
       "      <td id=\"T_25345_row6_col6\" class=\"data row6 col6\" >0.8412</td>\n",
       "      <td id=\"T_25345_row6_col7\" class=\"data row6 col7\" >0.9256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_25345_row7_col0\" class=\"data row7 col0\" >0.9808</td>\n",
       "      <td id=\"T_25345_row7_col1\" class=\"data row7 col1\" >0.9932</td>\n",
       "      <td id=\"T_25345_row7_col2\" class=\"data row7 col2\" >0.8636</td>\n",
       "      <td id=\"T_25345_row7_col3\" class=\"data row7 col3\" >1.0000</td>\n",
       "      <td id=\"T_25345_row7_col4\" class=\"data row7 col4\" >0.9268</td>\n",
       "      <td id=\"T_25345_row7_col5\" class=\"data row7 col5\" >0.9158</td>\n",
       "      <td id=\"T_25345_row7_col6\" class=\"data row7 col6\" >0.9191</td>\n",
       "      <td id=\"T_25345_row7_col7\" class=\"data row7 col7\" >0.9784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_25345_row8_col0\" class=\"data row8 col0\" >0.9615</td>\n",
       "      <td id=\"T_25345_row8_col1\" class=\"data row8 col1\" >0.9732</td>\n",
       "      <td id=\"T_25345_row8_col2\" class=\"data row8 col2\" >0.7727</td>\n",
       "      <td id=\"T_25345_row8_col3\" class=\"data row8 col3\" >0.9444</td>\n",
       "      <td id=\"T_25345_row8_col4\" class=\"data row8 col4\" >0.8500</td>\n",
       "      <td id=\"T_25345_row8_col5\" class=\"data row8 col5\" >0.8282</td>\n",
       "      <td id=\"T_25345_row8_col6\" class=\"data row8 col6\" >0.8337</td>\n",
       "      <td id=\"T_25345_row8_col7\" class=\"data row8 col7\" >0.9040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_25345_row9_col0\" class=\"data row9 col0\" >0.9808</td>\n",
       "      <td id=\"T_25345_row9_col1\" class=\"data row9 col1\" >0.9796</td>\n",
       "      <td id=\"T_25345_row9_col2\" class=\"data row9 col2\" >0.8636</td>\n",
       "      <td id=\"T_25345_row9_col3\" class=\"data row9 col3\" >1.0000</td>\n",
       "      <td id=\"T_25345_row9_col4\" class=\"data row9 col4\" >0.9268</td>\n",
       "      <td id=\"T_25345_row9_col5\" class=\"data row9 col5\" >0.9158</td>\n",
       "      <td id=\"T_25345_row9_col6\" class=\"data row9 col6\" >0.9191</td>\n",
       "      <td id=\"T_25345_row9_col7\" class=\"data row9 col7\" >0.9388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_25345_row10_col0\" class=\"data row10 col0\" >0.9757</td>\n",
       "      <td id=\"T_25345_row10_col1\" class=\"data row10 col1\" >0.9845</td>\n",
       "      <td id=\"T_25345_row10_col2\" class=\"data row10 col2\" >0.8779</td>\n",
       "      <td id=\"T_25345_row10_col3\" class=\"data row10 col3\" >0.9497</td>\n",
       "      <td id=\"T_25345_row10_col4\" class=\"data row10 col4\" >0.9107</td>\n",
       "      <td id=\"T_25345_row10_col5\" class=\"data row10 col5\" >0.8967</td>\n",
       "      <td id=\"T_25345_row10_col6\" class=\"data row10 col6\" >0.8987</td>\n",
       "      <td id=\"T_25345_row10_col7\" class=\"data row10 col7\" >0.9583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_25345_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_25345_row11_col0\" class=\"data row11 col0\" >0.0098</td>\n",
       "      <td id=\"T_25345_row11_col1\" class=\"data row11 col1\" >0.0113</td>\n",
       "      <td id=\"T_25345_row11_col2\" class=\"data row11 col2\" >0.0545</td>\n",
       "      <td id=\"T_25345_row11_col3\" class=\"data row11 col3\" >0.0504</td>\n",
       "      <td id=\"T_25345_row11_col4\" class=\"data row11 col4\" >0.0368</td>\n",
       "      <td id=\"T_25345_row11_col5\" class=\"data row11 col5\" >0.0424</td>\n",
       "      <td id=\"T_25345_row11_col6\" class=\"data row11 col6\" >0.0417</td>\n",
       "      <td id=\"T_25345_row11_col7\" class=\"data row11 col7\" >0.0279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11928cfb1c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tuned_dt = tune_model(blender_weighted, search_library = 'scikit-optimize', optimize=\"APC\", n_iter = 50) # https://pycaret.readthedocs.io/en/stable/api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_56f1e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_56f1e_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_56f1e_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_56f1e_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_56f1e_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_56f1e_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_56f1e_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_56f1e_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_56f1e_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_56f1e_level0_col8\" class=\"col_heading level0 col8\" >APC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_56f1e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_56f1e_row0_col0\" class=\"data row0 col0\" >Voting Classifier</td>\n",
       "      <td id=\"T_56f1e_row0_col1\" class=\"data row0 col1\" >0.9773</td>\n",
       "      <td id=\"T_56f1e_row0_col2\" class=\"data row0 col2\" >0.9807</td>\n",
       "      <td id=\"T_56f1e_row0_col3\" class=\"data row0 col3\" >0.8947</td>\n",
       "      <td id=\"T_56f1e_row0_col4\" class=\"data row0 col4\" >0.9562</td>\n",
       "      <td id=\"T_56f1e_row0_col5\" class=\"data row0 col5\" >0.9245</td>\n",
       "      <td id=\"T_56f1e_row0_col6\" class=\"data row0 col6\" >0.9112</td>\n",
       "      <td id=\"T_56f1e_row0_col7\" class=\"data row0 col7\" >0.9119</td>\n",
       "      <td id=\"T_56f1e_row0_col8\" class=\"data row0 col8\" >0.9605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1192425fc70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = predict_model(tuned_dt, raw_score=True, data=df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(memory=None,\n",
       "          steps=[('dtypes',\n",
       "                  DataTypes_Auto_infer(categorical_features=[],\n",
       "                                       display_types=False, features_todrop=[],\n",
       "                                       id_columns=[],\n",
       "                                       ml_usecase='classification',\n",
       "                                       numerical_features=['Time', 'V1', 'V2',\n",
       "                                                           'V3', 'V4', 'V5',\n",
       "                                                           'V6', 'V7', 'V8',\n",
       "                                                           'V9', 'V10', 'V11',\n",
       "                                                           'V12', 'V13', 'V14',\n",
       "                                                           'V15', 'V16', 'V17',\n",
       "                                                           'V18', 'V19', 'V20',\n",
       "                                                           'V21', 'V22', 'V23',\n",
       "                                                           'V24', 'V25', 'V26',\n",
       "                                                           'V27', 'V28',...\n",
       "                                                                       min_impurity_decrease=0.0,\n",
       "                                                                       min_impurity_split=None,\n",
       "                                                                       min_samples_leaf=1,\n",
       "                                                                       min_samples_split=2,\n",
       "                                                                       min_weight_fraction_leaf=0.0,\n",
       "                                                                       n_estimators=100,\n",
       "                                                                       n_jobs=-1,\n",
       "                                                                       oob_score=False,\n",
       "                                                                       random_state=1910,\n",
       "                                                                       verbose=0,\n",
       "                                                                       warm_start=False))],\n",
       "                                   flatten_transform=True, n_jobs=-1,\n",
       "                                   verbose=False, voting='soft',\n",
       "                                   weights=[0.9811812821083754,\n",
       "                                            0.40422721485692253,\n",
       "                                            0.0007382076894596559])]],\n",
       "          verbose=False),\n",
       " 'tuned_dt.pkl')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_model(tuned_dt, 'tuned_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e72929a067045d087b855a73718bdf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Hyperparameters', 'param"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(tuned_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(tuned_dt, plot = 'pr')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install fastapi\n",
    "# %pip install uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "API sucessfully created. This function only creates a POST API, it doesn't run it automatically.\n",
      "\n",
      "To run your API, please run this command --> !python fraud_voting_model_api.py\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "create_api(tuned_dt, 'fraud_voting_model_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# run the API\n",
    "!python fraud_voting_model_api.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      41991.000000\n",
       "V1           -4.566342\n",
       "V2            3.353451\n",
       "V3           -4.572028\n",
       "V4            3.616119\n",
       "V5           -2.493138\n",
       "V6           -1.090000\n",
       "V7           -5.551433\n",
       "V8            0.447783\n",
       "V9           -2.424414\n",
       "V10          -5.699922\n",
       "V11           3.586824\n",
       "V12          -6.636229\n",
       "V13          -1.128176\n",
       "V14          -7.245550\n",
       "V15           0.638326\n",
       "V16          -6.856810\n",
       "V17          -8.851879\n",
       "V18          -4.591883\n",
       "V19           0.936940\n",
       "V20          -0.249128\n",
       "V21           2.674466\n",
       "V22          -0.020880\n",
       "V23          -0.302447\n",
       "V24          -0.086396\n",
       "V25          -0.516060\n",
       "V26          -0.295102\n",
       "V27           0.195985\n",
       "V28           0.141115\n",
       "Amount        1.000000\n",
       "target        1.000000\n",
       "Name: 44556, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.iloc[-1].to_dict()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n",
      "Writing Dockerfile\n",
      "Dockerfile and requirements.txt successfully created.\n",
      "To build image you have to run --> !docker image build -f \"Dockerfile\" -t IMAGE_NAME:IMAGE_TAG .\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "create_docker('fraud_voting_model_api')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 sha256:752698380b6c52a095d1b1c921ffead9cacd4aaa74c6ff997fef4ad1760a5b4e\n",
      "#1 transferring dockerfile: 257B 0.1s done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [internal] load .dockerignore\n",
      "#2 sha256:b73c4a17d0600d238eee13d5e75cd3dd5369e77e6104083c1945587da491786a\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/library/python:3.8-slim\n",
      "#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065\n",
      "#3 ...\n",
      "\n",
      "#4 [auth] library/python:pull token for registry-1.docker.io\n",
      "#4 sha256:5cba492fb01746c3dc45d5cabca61d6fe9bcb472e3c686e7dee90534df5e90e7\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/library/python:3.8-slim\n",
      "#3 sha256:a94c831f6b826f8ffd4325edd7e9f6408caa85fd7f03e2b107cc6a9d249f7065\n",
      "#3 DONE 3.8s\n",
      "\n",
      "#10 [1/5] FROM docker.io/library/python:3.8-slim@sha256:1222aecd5ea9214a0ca4761e21f9f36d119c55a5a3721cd06da58e7199e79f2e\n",
      "#10 sha256:7a2ab8c8bb7b2edf5e64b18c26918875d8baf851f9ffeb85421198067ec59878\n",
      "#10 DONE 0.0s\n",
      "\n",
      "#6 [internal] load build context\n",
      "#6 sha256:2f1b7d82adec4770b979b03e88d39e736bee144a9752863b775f445889ff165b\n",
      "#6 transferring context: 181.34kB 1.1s\n",
      "#6 transferring context: 35.61MB 6.1s\n",
      "#6 transferring context: 47.59MB 10.7s done\n",
      "#6 DONE 11.2s\n",
      "\n",
      "#5 [2/5] WORKDIR /app\n",
      "#5 sha256:aebedd72848d369b2d6f7156ecd6a5f1925b20a6ad4c08f63147e682174fb3d3\n",
      "#5 CACHED\n",
      "\n",
      "#7 [3/5] ADD . /app\n",
      "#7 sha256:b8bdb1c5e4c1e0fa17d824a2e73cff9973f779863a4b2be8903f3c3336365b63\n",
      "#7 DONE 42.3s\n",
      "\n",
      "#8 [4/5] RUN apt-get update && apt-get install -y libgomp1\n",
      "#8 sha256:1104c2e076c5974abc331cd34ef76d27353da32da31a03b968b6e72683546009\n",
      "#8 2.542 Get:1 http://deb.debian.org/debian bullseye InRelease [116 kB]\n",
      "#8 3.062 Get:2 http://deb.debian.org/debian-security bullseye-security InRelease [48.4 kB]\n",
      "#8 3.498 Get:3 http://deb.debian.org/debian bullseye-updates InRelease [44.1 kB]\n",
      "#8 3.932 Get:4 http://deb.debian.org/debian bullseye/main amd64 Packages [8183 kB]\n",
      "#8 11.45 Get:5 http://deb.debian.org/debian-security bullseye-security/main amd64 Packages [236 kB]\n",
      "#8 12.16 Get:6 http://deb.debian.org/debian bullseye-updates/main amd64 Packages [14.6 kB]\n",
      "#8 13.24 Fetched 8642 kB in 11s (756 kB/s)\n",
      "#8 13.24 Reading package lists...\n",
      "#8 14.52 Reading package lists...\n",
      "#8 15.50 Building dependency tree...\n",
      "#8 15.76 Reading state information...\n",
      "#8 16.16 The following NEW packages will be installed:\n",
      "#8 16.17   libgomp1\n",
      "#8 16.51 0 upgraded, 1 newly installed, 0 to remove and 1 not upgraded.\n",
      "#8 16.51 Need to get 99.9 kB of archives.\n",
      "#8 16.51 After this operation, 285 kB of additional disk space will be used.\n",
      "#8 16.51 Get:1 http://deb.debian.org/debian bullseye/main amd64 libgomp1 amd64 10.2.1-6 [99.9 kB]\n",
      "#8 17.01 debconf: delaying package configuration, since apt-utils is not installed\n",
      "#8 17.06 Fetched 99.9 kB in 1s (190 kB/s)\n",
      "#8 17.11 Selecting previously unselected package libgomp1:amd64.\n",
      "#8 17.11 (Reading database ... \n",
      "(Reading database ... 5%\n",
      "(Reading database ... 10%\n",
      "(Reading database ... 15%\n",
      "(Reading database ... 20%\n",
      "(Reading database ... 25%\n",
      "(Reading database ... 30%\n",
      "(Reading database ... 35%\n",
      "(Reading database ... 40%\n",
      "(Reading database ... 45%\n",
      "(Reading database ... 50%\n",
      "(Reading database ... 55%\n",
      "(Reading database ... 60%\n",
      "(Reading database ... 65%\n",
      "(Reading database ... 70%\n",
      "(Reading database ... 75%\n",
      "(Reading database ... 80%\n",
      "(Reading database ... 85%\n",
      "(Reading database ... 90%\n",
      "(Reading database ... 95%\n",
      "(Reading database ... 100%\n",
      "(Reading database ... 7031 files and directories currently installed.)\n",
      "#8 17.14 Preparing to unpack .../libgomp1_10.2.1-6_amd64.deb ...\n",
      "#8 17.15 Unpacking libgomp1:amd64 (10.2.1-6) ...\n",
      "#8 17.23 Setting up libgomp1:amd64 (10.2.1-6) ...\n",
      "#8 17.26 Processing triggers for libc-bin (2.31-13+deb11u5) ...\n",
      "#8 DONE 17.4s\n",
      "\n",
      "#9 [5/5] RUN pip install -r requirements.txt\n",
      "#9 sha256:cddc7896e46b2575b80119dd90a90e7127de9bf865861b4fb01f2c5df44a44d2\n",
      "#9 6.046 Collecting pycaret\n",
      "#9 6.342   Downloading pycaret-3.0.0-py3-none-any.whl (481 kB)\n",
      "#9 6.778       481.8/481.8 KB 1.1 MB/s eta 0:00:00\n",
      "#9 7.396 Collecting fastapi\n",
      "#9 7.447   Downloading fastapi-0.95.0-py3-none-any.whl (57 kB)\n",
      "#9 7.508       57.1/57.1 KB 1.0 MB/s eta 0:00:00\n",
      "#9 7.975 Collecting uvicorn\n",
      "#9 8.023   Downloading uvicorn-0.21.1-py3-none-any.whl (57 kB)\n",
      "#9 8.101       57.8/57.8 KB 783.1 kB/s eta 0:00:00\n",
      "#9 8.859 Collecting lightgbm>=3.0.0\n",
      "#9 8.912   Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "#9 10.63       2.0/2.0 MB 1.2 MB/s eta 0:00:00\n",
      "#9 11.66 Collecting numba>=0.55.0\n",
      "#9 11.71   Downloading numba-0.56.4-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "#9 14.73       3.5/3.5 MB 1.2 MB/s eta 0:00:00\n",
      "#9 14.86 Collecting category-encoders>=2.4.0\n",
      "#9 14.91   Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
      "#9 15.01       81.2/81.2 KB 903.2 kB/s eta 0:00:00\n",
      "#9 15.52 Collecting markupsafe>=2.0.1\n",
      "#9 15.57   Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "#9 15.73 Collecting schemdraw>=0.14\n",
      "#9 15.77   Downloading schemdraw-0.16-py3-none-any.whl (105 kB)\n",
      "#9 15.88       105.8/105.8 KB 1.1 MB/s eta 0:00:00\n",
      "#9 16.12 Collecting requests>=2.27.1\n",
      "#9 16.17   Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "#9 16.24       62.8/62.8 KB 944.5 kB/s eta 0:00:00\n",
      "#9 16.35 Collecting pyod>=1.0.8\n",
      "#9 16.41   Downloading pyod-1.0.9.tar.gz (149 kB)\n",
      "#9 16.56       150.0/150.0 KB 1.0 MB/s eta 0:00:00\n",
      "#9 16.68   Preparing metadata (setup.py): started\n",
      "#9 17.65   Preparing metadata (setup.py): finished with status 'done'\n",
      "#9 18.30 Collecting plotly>=5.0.0\n",
      "#9 18.36   Downloading plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)\n",
      "#9 31.51       15.2/15.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 33.10 Collecting importlib-metadata>=4.12.0\n",
      "#9 33.18   Downloading importlib_metadata-6.1.0-py3-none-any.whl (21 kB)\n",
      "#9 33.84 Collecting plotly-resampler>=0.8.3.1\n",
      "#9 33.90   Downloading plotly_resampler-0.8.3.2.tar.gz (46 kB)\n",
      "#9 33.96       46.4/46.4 KB 661.9 kB/s eta 0:00:00\n",
      "#9 34.52   Installing build dependencies: started\n",
      "#9 69.44   Installing build dependencies: finished with status 'done'\n",
      "#9 69.45   Getting requirements to build wheel: started\n",
      "#9 69.62   Getting requirements to build wheel: finished with status 'done'\n",
      "#9 69.63   Preparing metadata (pyproject.toml): started\n",
      "#9 70.27   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "#9 70.62 Collecting wurlitzer\n",
      "#9 70.67   Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
      "#9 70.81 Collecting nbformat>=4.2.0\n",
      "#9 70.86   Downloading nbformat-5.8.0-py3-none-any.whl (77 kB)\n",
      "#9 70.93       77.4/77.4 KB 1.0 MB/s eta 0:00:00\n",
      "#9 71.48 Collecting xxhash\n",
      "#9 71.53   Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
      "#9 71.74       213.0/213.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 72.09 Collecting ipywidgets>=7.6.5\n",
      "#9 72.14   Downloading ipywidgets-8.0.6-py3-none-any.whl (138 kB)\n",
      "#9 72.27       138.3/138.3 KB 1.1 MB/s eta 0:00:00\n",
      "#9 72.68 Collecting cloudpickle\n",
      "#9 72.73   Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "#9 72.98 Collecting sktime>=0.16.1\n",
      "#9 73.04   Downloading sktime-0.16.1-py3-none-any.whl (16.0 MB)\n",
      "#9 86.82       16.0/16.0 MB 1.2 MB/s eta 0:00:00\n",
      "#9 87.35 Collecting tbats>=1.1.0\n",
      "#9 87.40   Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
      "#9 87.45       43.8/43.8 KB 1.0 MB/s eta 0:00:00\n",
      "#9 88.44 Collecting pandas<1.6.0,>=1.3.0\n",
      "#9 88.49   Downloading pandas-1.5.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
      "#9 98.96       12.2/12.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 99.27 Collecting deprecation>=2.1.0\n",
      "#9 99.32   Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 99.70 Collecting ipython>=5.5.0\n",
      "#9 99.75   Downloading ipython-8.11.0-py3-none-any.whl (793 kB)\n",
      "#9 100.4       793.3/793.3 KB 1.2 MB/s eta 0:00:00\n",
      "#9 101.4 Collecting matplotlib>=3.3.0\n",
      "#9 101.5   Downloading matplotlib-3.7.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\n",
      "#9 109.4       9.2/9.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 109.8 Collecting imbalanced-learn>=0.8.1\n",
      "#9 109.9   Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "#9 110.1       226.0/226.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 110.3 Collecting jinja2>=1.2\n",
      "#9 110.3   Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "#9 110.4       133.1/133.1 KB 1.1 MB/s eta 0:00:00\n",
      "#9 111.8 Collecting numpy<1.25,>=1.21\n",
      "#9 111.8   Downloading numpy-1.24.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "#9 126.7       17.3/17.3 MB 1.2 MB/s eta 0:00:00\n",
      "#9 127.5 Collecting psutil>=5.9.0\n",
      "#9 127.6   Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
      "#9 127.8       280.2/280.2 KB 1.1 MB/s eta 0:00:00\n",
      "#9 128.3 Collecting joblib>=1.2.0\n",
      "#9 128.4   Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "#9 128.6       298.0/298.0 KB 1.2 MB/s eta 0:00:00\n",
      "#9 128.8 Collecting kaleido>=0.2.1\n",
      "#9 128.8   Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
      "#9 197.2       79.9/79.9 MB 1.1 MB/s eta 0:00:00\n",
      "#9 197.7 Collecting yellowbrick>=1.4\n",
      "#9 197.8   Downloading yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
      "#9 198.0       282.6/282.6 KB 1.1 MB/s eta 0:00:00\n",
      "#9 198.7 Collecting scikit-learn>=1.0\n",
      "#9 198.8   Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
      "#9 207.2       9.8/9.8 MB 1.2 MB/s eta 0:00:00\n",
      "#9 207.9 Collecting tqdm>=4.62.0\n",
      "#9 207.9   Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "#9 208.0       77.1/77.1 KB 956.6 kB/s eta 0:00:00\n",
      "#9 208.6 Collecting pmdarima!=1.8.1,<3.0.0,>=1.8.0\n",
      "#9 208.7   Downloading pmdarima-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "#9 210.3       1.9/1.9 MB 1.1 MB/s eta 0:00:00\n",
      "#9 210.7 Collecting scikit-plot>=0.3.7\n",
      "#9 210.7   Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "#9 211.6 Collecting scipy<2.0.0\n",
      "#9 211.7   Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "#9 244.2       34.5/34.5 MB 854.5 kB/s eta 0:00:00\n",
      "#9 244.8 Collecting statsmodels>=0.12.1\n",
      "#9 244.9   Downloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "#9 253.4       9.9/9.9 MB 1.2 MB/s eta 0:00:00\n",
      "#9 255.4 Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
      "#9 255.5   Downloading pydantic-1.10.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "#9 258.3       3.2/3.2 MB 1.1 MB/s eta 0:00:00\n",
      "#9 258.9 Collecting starlette<0.27.0,>=0.26.1\n",
      "#9 259.0   Downloading starlette-0.26.1-py3-none-any.whl (66 kB)\n",
      "#9 259.0       66.9/66.9 KB 809.8 kB/s eta 0:00:00\n",
      "#9 259.4 Collecting click>=7.0\n",
      "#9 259.5   Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "#9 259.6       96.6/96.6 KB 1.1 MB/s eta 0:00:00\n",
      "#9 259.7 Collecting h11>=0.8\n",
      "#9 259.7   Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "#9 259.8       58.3/58.3 KB 879.5 kB/s eta 0:00:00\n",
      "#9 260.1 Collecting patsy>=0.5.1\n",
      "#9 260.1   Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "#9 260.3       233.8/233.8 KB 1.1 MB/s eta 0:00:00\n",
      "#9 260.6 Collecting packaging\n",
      "#9 260.7   Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "#9 260.8       42.7/42.7 KB 818.2 kB/s eta 0:00:00\n",
      "#9 261.0 Collecting threadpoolctl>=2.0.0\n",
      "#9 261.1   Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "#9 261.4 Collecting zipp>=0.5\n",
      "#9 261.5   Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "#9 262.3 Collecting matplotlib-inline\n",
      "#9 262.3   Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
      "#9 262.8 Collecting stack-data\n",
      "#9 262.9   Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
      "#9 263.5 Collecting pygments>=2.4.0\n",
      "#9 263.5   Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "#9 264.5       1.1/1.1 MB 1.2 MB/s eta 0:00:00\n",
      "#9 264.7 Collecting decorator\n",
      "#9 264.7   Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "#9 265.0 Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
      "#9 265.0   Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
      "#9 265.4       385.8/385.8 KB 1.1 MB/s eta 0:00:00\n",
      "#9 265.5 Collecting backcall\n",
      "#9 265.5   Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 265.9 Collecting traitlets>=5\n",
      "#9 265.9   Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
      "#9 266.1       117.4/117.4 KB 1.0 MB/s eta 0:00:00\n",
      "#9 266.1 Collecting pickleshare\n",
      "#9 266.2   Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "#9 266.3 Collecting pexpect>4.3\n",
      "#9 266.3   Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
      "#9 266.4       59.0/59.0 KB 885.2 kB/s eta 0:00:00\n",
      "#9 266.6 Collecting jedi>=0.16\n",
      "#9 266.6   Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
      "#9 268.0       1.6/1.6 MB 1.1 MB/s eta 0:00:00\n",
      "#9 268.7 Collecting ipykernel>=4.5.1\n",
      "#9 268.7   Downloading ipykernel-6.22.0-py3-none-any.whl (149 kB)\n",
      "#9 268.8       150.0/150.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 269.0 Collecting jupyterlab-widgets~=3.0.7\n",
      "#9 269.0   Downloading jupyterlab_widgets-3.0.7-py3-none-any.whl (198 kB)\n",
      "#9 269.2       198.2/198.2 KB 1.1 MB/s eta 0:00:00\n",
      "#9 269.5 Collecting widgetsnbextension~=4.0.7\n",
      "#9 269.5   Downloading widgetsnbextension-4.0.7-py3-none-any.whl (2.1 MB)\n",
      "#9 271.4       2.1/2.1 MB 1.2 MB/s eta 0:00:00\n",
      "#9 271.5 Requirement already satisfied: wheel in /usr/local/lib/python3.8/site-packages (from lightgbm>=3.0.0->pycaret->-r requirements.txt (line 2)) (0.40.0)\n",
      "#9 271.8 Collecting importlib-resources>=3.2.0\n",
      "#9 271.9   Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "#9 272.0 Collecting python-dateutil>=2.7\n",
      "#9 272.1   Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "#9 272.3       247.7/247.7 KB 1.1 MB/s eta 0:00:00\n",
      "#9 272.6 Collecting kiwisolver>=1.0.1\n",
      "#9 272.7   Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "#9 273.7       1.2/1.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 274.1 Collecting contourpy>=1.0.1\n",
      "#9 274.1   Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
      "#9 274.4       300.0/300.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 274.7 Collecting pyparsing>=2.3.1\n",
      "#9 274.7   Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "#9 274.8       98.3/98.3 KB 1.2 MB/s eta 0:00:00\n",
      "#9 274.9 Collecting cycler>=0.10\n",
      "#9 274.9   Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "#9 275.3 Collecting fonttools>=4.22.0\n",
      "#9 275.3   Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
      "#9 276.2       1.0/1.0 MB 1.2 MB/s eta 0:00:00\n",
      "#9 277.7 Collecting pillow>=6.2.0\n",
      "#9 277.7   Downloading Pillow-9.4.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "#9 280.6       3.4/3.4 MB 1.2 MB/s eta 0:00:00\n",
      "#9 280.8 Collecting fastjsonschema\n",
      "#9 280.8   Downloading fastjsonschema-2.16.3-py3-none-any.whl (23 kB)\n",
      "#9 281.0 Collecting jsonschema>=2.6\n",
      "#9 281.1   Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
      "#9 281.2       90.4/90.4 KB 989.8 kB/s eta 0:00:00\n",
      "#9 281.4 Collecting jupyter-core\n",
      "#9 281.4   Downloading jupyter_core-5.3.0-py3-none-any.whl (93 kB)\n",
      "#9 281.5       93.2/93.2 KB 905.4 kB/s eta 0:00:00\n",
      "#9 281.6 Requirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from numba>=0.55.0->pycaret->-r requirements.txt (line 2)) (57.5.0)\n",
      "#9 281.7 Collecting numpy<1.25,>=1.21\n",
      "#9 281.7   Downloading numpy-1.23.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "#9 296.5       17.1/17.1 MB 1.2 MB/s eta 0:00:00\n",
      "#9 297.7 Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "#9 297.7   Downloading llvmlite-0.39.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "#9 327.5       34.6/34.6 MB 1.2 MB/s eta 0:00:00\n",
      "#9 328.0 Collecting pytz>=2020.1\n",
      "#9 328.1   Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "#9 328.5       502.3/502.3 KB 1.1 MB/s eta 0:00:00\n",
      "#9 328.8 Collecting tenacity>=6.2.0\n",
      "#9 328.8   Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "#9 329.3 Collecting dash<3.0.0,>=2.2.0\n",
      "#9 329.3   Downloading dash-2.9.1-py3-none-any.whl (10.2 MB)\n",
      "#9 338.1       10.2/10.2 MB 1.2 MB/s eta 0:00:00\n",
      "#9 340.1 Collecting orjson<4.0.0,>=3.8.0\n",
      "#9 340.1   Downloading orjson-3.8.9-cp38-cp38-manylinux_2_28_x86_64.whl (143 kB)\n",
      "#9 340.2       143.9/143.9 KB 1.1 MB/s eta 0:00:00\n",
      "#9 340.3 Collecting trace-updater>=0.0.8\n",
      "#9 340.4   Downloading trace_updater-0.0.9-py3-none-any.whl (185 kB)\n",
      "#9 340.5       185.1/185.1 KB 1.1 MB/s eta 0:00:00\n",
      "#9 340.7 Collecting jupyter-dash>=0.4.2\n",
      "#9 340.8   Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
      "#9 341.1 Collecting urllib3\n",
      "#9 341.1   Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "#9 341.3       140.9/140.9 KB 1.0 MB/s eta 0:00:00\n",
      "#9 343.1 Collecting Cython!=0.29.18,!=0.29.31,>=0.29\n",
      "#9 343.2   Downloading Cython-0.29.33-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "#9 344.9       1.9/1.9 MB 1.2 MB/s eta 0:00:00\n",
      "#9 345.3 Collecting typing-extensions>=4.2.0\n",
      "#9 345.3   Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "#9 345.6 Collecting six\n",
      "#9 345.6   Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "#9 345.8 Collecting certifi>=2017.4.17\n",
      "#9 345.9   Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "#9 346.0       155.3/155.3 KB 1.2 MB/s eta 0:00:00\n",
      "#9 346.2 Collecting idna<4,>=2.5\n",
      "#9 346.2   Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "#9 346.3       61.5/61.5 KB 1.1 MB/s eta 0:00:00\n",
      "#9 347.8 Collecting charset-normalizer<4,>=2\n",
      "#9 347.8   Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
      "#9 348.2       195.9/195.9 KB 561.0 kB/s eta 0:00:00\n",
      "#9 349.9 Collecting deprecated>=1.2.13\n",
      "#9 349.9   Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "#9 350.3 Collecting anyio<5,>=3.4.0\n",
      "#9 350.3   Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
      "#9 350.4       80.6/80.6 KB 859.4 kB/s eta 0:00:00\n",
      "#9 351.1 Collecting sniffio>=1.1\n",
      "#9 351.2   Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "#9 351.9 Collecting Flask>=1.0.4\n",
      "#9 351.9   Downloading Flask-2.2.3-py3-none-any.whl (101 kB)\n",
      "#9 352.0       101.8/101.8 KB 1.0 MB/s eta 0:00:00\n",
      "#9 352.4 Collecting dash-html-components==2.0.0\n",
      "#9 352.4   Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "#9 352.9 Collecting dash-core-components==2.0.0\n",
      "#9 352.9   Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "#9 353.3 Collecting dash-table==5.0.0\n",
      "#9 353.3   Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "#9 354.0 Collecting wrapt<2,>=1.10\n",
      "#9 354.0   Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "#9 354.1       81.5/81.5 KB 1.0 MB/s eta 0:00:00\n",
      "#9 354.7 Collecting jupyter-client>=6.1.12\n",
      "#9 354.8   Downloading jupyter_client-8.1.0-py3-none-any.whl (102 kB)\n",
      "#9 354.9       102.9/102.9 KB 1.2 MB/s eta 0:00:00\n",
      "#9 355.4 Collecting tornado>=6.1\n",
      "#9 355.4   Downloading tornado-6.2-cp37-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (423 kB)\n",
      "#9 355.8       424.0/424.0 KB 1.1 MB/s eta 0:00:00\n",
      "#9 358.3 Collecting pyzmq>=20\n",
      "#9 358.4   Downloading pyzmq-25.0.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "#9 359.4       1.1/1.1 MB 1.1 MB/s eta 0:00:00\n",
      "#9 359.7 Collecting comm>=0.1.1\n",
      "#9 359.8   Downloading comm-0.1.3-py3-none-any.whl (6.6 kB)\n",
      "#9 360.3 Collecting nest-asyncio\n",
      "#9 360.3   Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
      "#9 361.4 Collecting debugpy>=1.6.5\n",
      "#9 361.5   Downloading debugpy-1.6.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "#9 364.2       3.1/3.1 MB 1.2 MB/s eta 0:00:00\n",
      "#9 364.7 Collecting parso<0.9.0,>=0.8.0\n",
      "#9 364.8   Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
      "#9 364.9       100.8/100.8 KB 1.0 MB/s eta 0:00:00\n",
      "#9 365.1 Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
      "#9 365.2   Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
      "#9 365.3       57.5/57.5 KB 939.1 kB/s eta 0:00:00\n",
      "#9 365.4 Collecting attrs>=17.4.0\n",
      "#9 365.5   Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
      "#9 365.5       60.0/60.0 KB 970.1 kB/s eta 0:00:00\n",
      "#9 365.9 Collecting pkgutil-resolve-name>=1.3.10\n",
      "#9 365.9   Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
      "#9 366.3 Collecting platformdirs>=2.5\n",
      "#9 366.4   Downloading platformdirs-3.2.0-py3-none-any.whl (14 kB)\n",
      "#9 366.7 Collecting ansi2html\n",
      "#9 366.8   Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
      "#9 367.1 Collecting retrying\n",
      "#9 367.2   Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "#9 367.6 Collecting ptyprocess>=0.5\n",
      "#9 367.6   Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "#9 367.8 Collecting wcwidth\n",
      "#9 367.9   Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
      "#9 369.0 Collecting asttokens>=2.1.0\n",
      "#9 369.1   Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
      "#9 369.5 Collecting pure-eval\n",
      "#9 369.5   Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
      "#9 369.9 Collecting executing>=1.2.0\n",
      "#9 370.0   Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "#9 370.5 Collecting Werkzeug>=2.2.2\n",
      "#9 370.6   Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "#9 370.8       233.6/233.6 KB 1.1 MB/s eta 0:00:00\n",
      "#9 371.2 Collecting itsdangerous>=2.0\n",
      "#9 371.2   Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "#9 372.8 Building wheels for collected packages: plotly-resampler, pyod\n",
      "#9 372.8   Building wheel for plotly-resampler (pyproject.toml): started\n",
      "#9 374.7   Building wheel for plotly-resampler (pyproject.toml): finished with status 'done'\n",
      "#9 374.7   Created wheel for plotly-resampler: filename=plotly_resampler-0.8.3.2-cp38-cp38-manylinux_2_31_x86_64.whl size=47922 sha256=54ef491f129a6442f131d7866bd942d398dad699f3aea33107d18ffa70d099a0\n",
      "#9 374.7   Stored in directory: /root/.cache/pip/wheels/63/17/b1/4bc002808e0370594fa673f71ecba27516bed8a83a334170e8\n",
      "#9 374.7   Building wheel for pyod (setup.py): started\n",
      "#9 376.0   Building wheel for pyod (setup.py): finished with status 'done'\n",
      "#9 376.0   Created wheel for pyod: filename=pyod-1.0.9-py3-none-any.whl size=184113 sha256=f7218342da5b310b7737c0e47bf4a1cf8c7d1b6bf7a481af8e25053b80efa59a\n",
      "#9 376.0   Stored in directory: /root/.cache/pip/wheels/1a/ec/04/08882538e197056f24532d6b7a00fd18e9c34d7c44faf3cd0c\n",
      "#9 376.0 Successfully built plotly-resampler pyod\n",
      "#9 379.5 Installing collected packages: wcwidth, trace-updater, pytz, pure-eval, ptyprocess, pickleshare, kaleido, fastjsonschema, executing, dash-table, dash-html-components, dash-core-components, backcall, zipp, xxhash, wurlitzer, wrapt, widgetsnbextension, urllib3, typing-extensions, traitlets, tqdm, tornado, threadpoolctl, tenacity, sniffio, six, schemdraw, pyzmq, pyrsistent, pyparsing, pygments, psutil, prompt-toolkit, platformdirs, pkgutil-resolve-name, pillow, pexpect, parso, packaging, orjson, numpy, nest-asyncio, markupsafe, llvmlite, kiwisolver, jupyterlab-widgets, joblib, itsdangerous, idna, h11, fonttools, decorator, debugpy, Cython, cycler, cloudpickle, click, charset-normalizer, certifi, attrs, ansi2html, Werkzeug, uvicorn, scipy, retrying, requests, python-dateutil, pydantic, plotly, patsy, matplotlib-inline, jupyter-core, jinja2, jedi, importlib-resources, importlib-metadata, deprecation, deprecated, contourpy, comm, asttokens, anyio, starlette, stack-data, scikit-learn, pandas, numba, matplotlib, jupyter-client, jsonschema, Flask, yellowbrick, statsmodels, sktime, scikit-plot, pyod, nbformat, lightgbm, ipython, imbalanced-learn, fastapi, dash, pmdarima, ipykernel, category-encoders, tbats, jupyter-dash, ipywidgets, plotly-resampler, pycaret\n",
      "#9 474.6 Successfully installed Cython-0.29.33 Flask-2.2.3 Werkzeug-2.2.3 ansi2html-1.8.0 anyio-3.6.2 asttokens-2.2.1 attrs-22.2.0 backcall-0.2.0 category-encoders-2.6.0 certifi-2022.12.7 charset-normalizer-3.1.0 click-8.1.3 cloudpickle-2.2.1 comm-0.1.3 contourpy-1.0.7 cycler-0.11.0 dash-2.9.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 debugpy-1.6.6 decorator-5.1.1 deprecated-1.2.13 deprecation-2.1.0 executing-1.2.0 fastapi-0.95.0 fastjsonschema-2.16.3 fonttools-4.39.3 h11-0.14.0 idna-3.4 imbalanced-learn-0.10.1 importlib-metadata-6.1.0 importlib-resources-5.12.0 ipykernel-6.22.0 ipython-8.11.0 ipywidgets-8.0.6 itsdangerous-2.1.2 jedi-0.18.2 jinja2-3.1.2 joblib-1.2.0 jsonschema-4.17.3 jupyter-client-8.1.0 jupyter-core-5.3.0 jupyter-dash-0.4.2 jupyterlab-widgets-3.0.7 kaleido-0.2.1 kiwisolver-1.4.4 lightgbm-3.3.5 llvmlite-0.39.1 markupsafe-2.1.2 matplotlib-3.7.1 matplotlib-inline-0.1.6 nbformat-5.8.0 nest-asyncio-1.5.6 numba-0.56.4 numpy-1.23.5 orjson-3.8.9 packaging-23.0 pandas-1.5.3 parso-0.8.3 patsy-0.5.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.4.0 pkgutil-resolve-name-1.3.10 platformdirs-3.2.0 plotly-5.13.1 plotly-resampler-0.8.3.2 pmdarima-2.0.3 prompt-toolkit-3.0.38 psutil-5.9.4 ptyprocess-0.7.0 pure-eval-0.2.2 pycaret-3.0.0 pydantic-1.10.7 pygments-2.14.0 pyod-1.0.9 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 pytz-2023.3 pyzmq-25.0.2 requests-2.28.2 retrying-1.3.4 schemdraw-0.16 scikit-learn-1.2.2 scikit-plot-0.3.7 scipy-1.10.1 six-1.16.0 sktime-0.16.1 sniffio-1.3.0 stack-data-0.6.2 starlette-0.26.1 statsmodels-0.13.5 tbats-1.1.2 tenacity-8.2.2 threadpoolctl-3.1.0 tornado-6.2 tqdm-4.65.0 trace-updater-0.0.9 traitlets-5.9.0 typing-extensions-4.5.0 urllib3-1.26.15 uvicorn-0.21.1 wcwidth-0.2.6 widgetsnbextension-4.0.7 wrapt-1.15.0 wurlitzer-3.0.3 xxhash-3.2.0 yellowbrick-1.5 zipp-3.15.0\n",
      "#9 474.6 WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "#9 474.6 WARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "#9 474.6 You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "#9 DONE 476.6s\n",
      "\n",
      "#11 exporting to image\n",
      "#11 sha256:e8c613e07b0b7ff33893b694f7759a10d42e180f2b4dc349fb57dc6b71dcab00\n",
      "#11 exporting layers\n",
      "#11 exporting layers 23.0s done\n",
      "#11 writing image sha256:a36def49a37e46ce98b3373d9166f9067a20df8f3481e34e3c85591e00cc5182 done\n",
      "#11 naming to docker.io/library/fraud_voting_model_api:latest 0.0s done\n",
      "#11 DONE 23.1s\n"
     ]
    }
   ],
   "source": [
    "# !docker image build -f Dockerfile -t fraud_voting_model_api:latest .\n",
    "!docker image build -f \"Dockerfile\" -t fraud_voting_model_api:latest ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140b98eb6e96c9c9bdbd3e83cb4dd6488d32afa0e1f4aba5d6f82510098f9b7\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "This command is running the docker image that we just built. \n",
    "The `-d` flag means that the container will run in the background. \n",
    "The `-p` flag means that we are mapping the port 8000 on the host machine to port 8000 on the container. \n",
    "The `--name` flag means that we are naming the container `fraud_voting_model_api`. \n",
    "The last argument is the name of the image that we want to run.\n",
    "'''\n",
    "!docker run -d -p 8000:8000 --name fraud_voting_model_api fraud_voting_model_api:latest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
